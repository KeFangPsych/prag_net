{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac7555ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ('informative', 0): ['most,successful', 'no,unsuccessful', 'all,successful', 'no,unsuccessful', 'all,successful']\n",
      "  Literal done\n",
      "  credulous_T... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kangke/projects/prag_net/data/prag_net_listener_n1/rsa_optimal_exp_core.py:382: UserWarning: theta values above precision is rounded to 10 decimals\n",
      "  warnings.warn(\"theta values above precision is rounded to 10 decimals\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done (1.3s)\n",
      "  credulous_F... done (0.5s)\n",
      "  vigilant_T... done (2.9s)\n",
      "  vigilant_F... done (0.8s)\n",
      "\n",
      "Processing ('informative', 1): ['most,unsuccessful', 'all,unsuccessful', 'no,successful', 'all,unsuccessful', 'no,successful']\n",
      "  Literal done\n",
      "  credulous_T... done (1.3s)\n",
      "  credulous_F... done (0.5s)\n",
      "  vigilant_T... done (2.4s)\n",
      "  vigilant_F... done (0.7s)\n",
      "\n",
      "Total time: 10.4s\n",
      "\n",
      "Processing ('pers_plus', 0): ['some,successful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,successful']\n",
      "  Literal done\n",
      "  credulous_T... done (1.3s)\n",
      "  credulous_F... done (0.5s)\n",
      "  vigilant_T... done (2.4s)\n",
      "  vigilant_F... done (0.8s)\n",
      "\n",
      "Processing ('pers_plus', 1): ['most,successful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful']\n",
      "  Literal done\n",
      "  credulous_T... done (1.2s)\n",
      "  credulous_F... done (0.5s)\n",
      "  vigilant_T... done (2.3s)\n",
      "  vigilant_F... done (0.7s)\n",
      "\n",
      "Processing ('pers_plus', 2): ['most,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful']\n",
      "  Literal done\n",
      "  credulous_T... done (1.1s)\n",
      "  credulous_F... done (0.5s)\n",
      "  vigilant_T... done (2.3s)\n",
      "  vigilant_F... done (0.7s)\n",
      "\n",
      "Total time: 24.7s\n",
      "\n",
      "Processing ('pers_minus', 0): ['some,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful']\n",
      "  Literal done\n",
      "  credulous_T... done (1.2s)\n",
      "  credulous_F... done (0.5s)\n",
      "  vigilant_T... done (2.4s)\n",
      "  vigilant_F... done (0.8s)\n",
      "\n",
      "Processing ('pers_minus', 1): ['most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful']\n",
      "  Literal done\n",
      "  credulous_T... done (1.3s)\n",
      "  credulous_F... done (0.5s)\n",
      "  vigilant_T... done (2.6s)\n",
      "  vigilant_F... done (0.9s)\n",
      "\n",
      "Processing ('pers_minus', 2): ['most,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful']\n",
      "  Literal done\n",
      "  credulous_T... done (1.6s)\n",
      "  credulous_F... done (0.5s)\n",
      "  vigilant_T... done (2.4s)\n",
      "  vigilant_F... done (0.8s)\n",
      "\n",
      "Total time: 40.1s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from time import time\n",
    "from rsa_optimal_exp_core import World, LiteralListener, PragmaticListener_obs_n\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "UTTERANCE_SEQUENCES = {\n",
    "    \"informative\": [\n",
    "        [\"most,successful\", \"no,unsuccessful\", \"all,successful\", \"no,unsuccessful\", \"all,successful\"],\n",
    "        [\"most,unsuccessful\", \"all,unsuccessful\", \"no,successful\", \"all,unsuccessful\", \"no,successful\"],\n",
    "    ],\n",
    "    \"pers_plus\": [\n",
    "        [\"some,successful\", \"some,successful\", \"some,unsuccessful\", \"some,successful\", \"some,successful\"],\n",
    "        [\"most,successful\", \"some,successful\", \"some,unsuccessful\", \"some,successful\", \"some,unsuccessful\"],\n",
    "        [\"most,successful\", \"some,unsuccessful\", \"some,successful\", \"some,unsuccessful\", \"some,successful\"],\n",
    "    ],\n",
    "    \"pers_minus\": [\n",
    "        [\"some,unsuccessful\", \"some,unsuccessful\", \"some,successful\", \"some,unsuccessful\", \"some,unsuccessful\"],\n",
    "        [\"most,unsuccessful\", \"some,unsuccessful\", \"some,successful\", \"some,unsuccessful\", \"some,successful\"],\n",
    "        [\"most,unsuccessful\", \"some,successful\", \"some,unsuccessful\", \"some,successful\", \"some,unsuccessful\"],\n",
    "    ],\n",
    "}\n",
    "\n",
    "THETA_VALUES = np.linspace(0, 1, 21)  # 0%, 5%, ..., 100%\n",
    "ALPHA_GRID = np.logspace(np.log10(1), np.log10(50), 100)\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN COMPUTATION\n",
    "# ============================================================================\n",
    "    \n",
    "world = World(n=1, m=5, theta_values=THETA_VALUES)\n",
    "\n",
    "lookup = {}\n",
    "start_time = time()\n",
    "\n",
    "# Iterate over all sequences\n",
    "for speaker_cond, sequences in UTTERANCE_SEQUENCES.items():\n",
    "    for seq_idx, utterances in enumerate(sequences):\n",
    "        key = (speaker_cond, seq_idx)\n",
    "        print(f\"\\nProcessing {key}: {utterances}\")\n",
    "        \n",
    "        lookup[key] = {\n",
    "            \"utterances\": utterances,\n",
    "            \"literal\": None,\n",
    "            \"credulous_T\": {},\n",
    "            \"credulous_F\": {},\n",
    "            \"vigilant_T\": {},\n",
    "            \"vigilant_F\": {},\n",
    "        }\n",
    "        \n",
    "        # --- Literal Listener ---\n",
    "        listener = LiteralListener(world)\n",
    "        posteriors = []\n",
    "        for u in utterances:\n",
    "            listener.listen_and_update(u)\n",
    "            posteriors.append(listener.current_belief_theta.copy())\n",
    "        lookup[key][\"literal\"] = np.array(posteriors)\n",
    "        print(f\"  Literal done\")\n",
    "        \n",
    "        # --- Pragmatic Listeners ---\n",
    "        configs = [\n",
    "            (\"credulous_T\", \"coop\", True),\n",
    "            (\"credulous_F\", \"coop\", False),\n",
    "            (\"vigilant_T\", \"strat\", True),\n",
    "            (\"vigilant_F\", \"strat\", False),\n",
    "        ]\n",
    "        \n",
    "        for model_name, omega, update_internal in configs:\n",
    "            print(f\"  {model_name}...\", end=\" \", flush=True)\n",
    "            t0 = time()\n",
    "            \n",
    "            for alpha in ALPHA_GRID:\n",
    "                listener = PragmaticListener_obs_n(\n",
    "                    world=world,\n",
    "                    level=1,\n",
    "                    omega=omega,\n",
    "                    update_internal=update_internal,\n",
    "                    alpha=alpha,\n",
    "                    beta=0.0,\n",
    "                )\n",
    "                posteriors = []\n",
    "                for u in utterances:\n",
    "                    listener.listen_and_update(u)\n",
    "                    posteriors.append(listener.current_belief_theta.copy())\n",
    "                lookup[key][model_name][alpha] = np.array(posteriors)\n",
    "            \n",
    "            print(f\"done ({time() - t0:.1f}s)\")\n",
    "    \n",
    "    print(f\"\\nTotal time: {time() - start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46fb4d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying epsilon smoothing with ε = 0.01\n",
      "Uniform floor: 0.000476\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "EPSILON = 0.01\n",
    "\n",
    "theta_values = THETA_VALUES\n",
    "alpha_grid = ALPHA_GRID\n",
    "n_theta = len(THETA_VALUES)\n",
    "\n",
    "print(f\"Applying epsilon smoothing with ε = {EPSILON}\")\n",
    "print(f\"Uniform floor: {EPSILON / n_theta:.6f}\")\n",
    "\n",
    "smoothed_lookup = copy.deepcopy(lookup)\n",
    "# Apply smoothing to all predictions\n",
    "for key in smoothed_lookup:\n",
    "    # Literal\n",
    "    smoothed_lookup[key][\"literal\"] = (1 - EPSILON) * smoothed_lookup[key][\"literal\"] + EPSILON / n_theta\n",
    "    \n",
    "    # Pragmatic models\n",
    "    for model_name in [\"credulous_T\", \"credulous_F\", \"vigilant_T\", \"vigilant_F\"]:\n",
    "        for alpha in alpha_grid:\n",
    "            smoothed_lookup[key][model_name][alpha] = (1 - EPSILON) * smoothed_lookup[key][model_name][alpha] + EPSILON / n_theta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43152e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: 614 rows\n",
      "Comprehension check distribution:\n",
      "n_comp_correct\n",
      "0     12\n",
      "1     83\n",
      "2    121\n",
      "3    127\n",
      "4    144\n",
      "5    127\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original: 614 participants\n",
      "Pass last two: 269 participants\n",
      "Pass at least 3: 398 participants\n",
      "\n",
      "Cross-tab (last_two x at_least_3):\n",
      "pass_at_least_3  False  True \n",
      "pass_last_two                \n",
      "False              213    132\n",
      "True                 3    266\n",
      "\n",
      "Filtered sample by condition:\n",
      "listener_belief_condition  speaker_condition\n",
      "credulous                  informative          66\n",
      "                           pers_minus           53\n",
      "                           pers_plus            76\n",
      "naturalistic               informative          71\n",
      "                           pers_minus           64\n",
      "                           pers_plus            80\n",
      "vigilant                   informative          61\n",
      "                           pers_minus           67\n",
      "                           pers_plus            76\n",
      "dtype: int64\n",
      "Loaded data: 614 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./processed_listener_n1_anonymized.csv\")\n",
    "print(f\"Loaded data: {len(df)} rows\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPREHENSION CHECK FILTERING\n",
    "# ============================================================================\n",
    "\n",
    "comp_cols = [\"comp1_some_correct\", \"comp1_most_correct\", \"comp2_correct\", \n",
    "             \"comp_multi_correct\", \"comp3_correct\"]\n",
    "\n",
    "# Count correct per participant\n",
    "df[\"n_comp_correct\"] = df[comp_cols].sum(axis=1)\n",
    "\n",
    "print(\"Comprehension check distribution:\")\n",
    "print(df[\"n_comp_correct\"].value_counts().sort_index())\n",
    "\n",
    "# Option A: Did not fail on last two (most important)\n",
    "df[\"pass_last_two\"] = df[\"comp_multi_correct\"] & df[\"comp3_correct\"]\n",
    "\n",
    "# Option B: Did not fail 4 out of 5 (passed at least 2)\n",
    "df[\"pass_at_least_3\"] = df[\"n_comp_correct\"] >= 3\n",
    "\n",
    "print(f\"\\nOriginal: {len(df)} participants\")\n",
    "print(f\"Pass last two: {df['pass_last_two'].sum()} participants\")\n",
    "print(f\"Pass at least 3: {df['pass_at_least_3'].sum()} participants\")\n",
    "# Cross-tabulation\n",
    "print(\"\\nCross-tab (last_two x at_least_3):\")\n",
    "print(pd.crosstab(df[\"pass_last_two\"], df[\"pass_at_least_3\"]))\n",
    "\n",
    "# Choose filter (can switch between them)\n",
    "#df = df[df[\"pass_last_two\"]]\n",
    "#df = df[df[\"pass_at_least_3\"]]\n",
    "\n",
    "# Check balance across conditions\n",
    "print(\"\\nFiltered sample by condition:\")\n",
    "print(df.groupby([\"listener_belief_condition\", \"speaker_condition\"]).size())\n",
    "\n",
    "print(f\"Loaded data: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab924ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: 588 participants\n",
      "After dropping NaN: 588 participants\n",
      "Response matrix shape: (588, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CLEAN DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Filter to completed participants who passed attention check\n",
    "df = df[df[\"completed_all_rounds\"] == True]\n",
    "df = df[df[\"attention_check_passed\"] == True]\n",
    "print(f\"After filtering: {len(df)} participants\")\n",
    "\n",
    "# Extract relevant columns\n",
    "# Responses are in r1_effectiveness, ..., r5_effectiveness (0-100 scale)\n",
    "response_cols = [f\"r{i}_effectiveness\" for i in range(1, 6)]\n",
    "\n",
    "# Check for missing values in key columns\n",
    "key_cols = [\"speaker_condition\", \"listener_belief_condition\", \"sequence_idx\"] + response_cols\n",
    "df = df.dropna(subset=key_cols)\n",
    "print(f\"After dropping NaN: {len(df)} participants\")\n",
    "\n",
    "# Convert sequence_idx to int\n",
    "df[\"sequence_idx\"] = df[\"sequence_idx\"].astype(int)\n",
    "\n",
    "# Convert responses to theta indices (0-100 → 0-20)\n",
    "# Response of 0% → index 0, 5% → index 1, ..., 100% → index 20\n",
    "for col in response_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "    \n",
    "# Create response matrix (n_participants x 5 rounds)\n",
    "responses = df[response_cols].values  # shape (n_participants, 5), values 0-100\n",
    "\n",
    "# Convert to theta indices (divide by 5)\n",
    "response_indices = (responses / 5).astype(int)  # values 0-20\n",
    "\n",
    "# Clamp to valid range (in case of any edge cases)\n",
    "response_indices = np.clip(response_indices, 0, n_theta - 1)\n",
    "\n",
    "print(f\"Response matrix shape: {response_indices.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283063a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50/588 participants\n",
      "Processed 100/588 participants\n",
      "Processed 150/588 participants\n",
      "Processed 200/588 participants\n",
      "Processed 250/588 participants\n",
      "Processed 300/588 participants\n",
      "Processed 350/588 participants\n",
      "Processed 400/588 participants\n",
      "Processed 450/588 participants\n",
      "Processed 500/588 participants\n",
      "Processed 550/588 participants\n",
      "Processed all 588 participants\n",
      "\n",
      "============================================================\n",
      "RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "CREDULOUS (n=187):\n",
      "  ll_literal: mean=-12.23\n",
      "  ll_credulous_T: mean=-12.63\n",
      "  ll_credulous_F: mean=-12.22\n",
      "  ll_vigilant_T: mean=-11.39\n",
      "  ll_vigilant_F: mean=-11.49\n",
      "  Best fitting: ll_vigilant_T\n",
      "\n",
      "VIGILANT (n=197):\n",
      "  ll_literal: mean=-13.28\n",
      "  ll_credulous_T: mean=-13.50\n",
      "  ll_credulous_F: mean=-13.10\n",
      "  ll_vigilant_T: mean=-12.47\n",
      "  ll_vigilant_F: mean=-12.57\n",
      "  Best fitting: ll_vigilant_T\n",
      "\n",
      "NATURALISTIC (n=204):\n",
      "  ll_literal: mean=-12.47\n",
      "  ll_credulous_T: mean=-12.92\n",
      "  ll_credulous_F: mean=-12.44\n",
      "  ll_vigilant_T: mean=-11.70\n",
      "  ll_vigilant_F: mean=-11.82\n",
      "  Best fitting: ll_vigilant_T\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPUTE LOG-LIKELIHOODS (alpha optimized at per participant level)\n",
    "# ============================================================================\n",
    "\n",
    "# Get sequence keys for each participant\n",
    "sequence_keys = list(zip(df[\"speaker_condition\"], df[\"sequence_idx\"]))\n",
    "\n",
    "# Model names\n",
    "model_names = [\"literal\", \"credulous_T\", \"credulous_F\", \"vigilant_T\", \"vigilant_F\"]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for i, (idx, row) in enumerate(df.iterrows()):\n",
    "    key = (row[\"speaker_condition\"], int(row[\"sequence_idx\"]))\n",
    "    resp_idx = response_indices[i]  # shape (5,), values 0-20\n",
    "    \n",
    "    participant_result = {\n",
    "        \"participant_idx\": idx,\n",
    "        \"speaker_condition\": row[\"speaker_condition\"],\n",
    "        \"listener_belief_condition\": row[\"listener_belief_condition\"],\n",
    "        \"sequence_idx\": int(row[\"sequence_idx\"]),\n",
    "    }\n",
    "    \n",
    "    # --- Literal model (no alpha) ---\n",
    "    posteriors = smoothed_lookup[key][\"literal\"]  # shape (5, 21)\n",
    "    # Get probability of each response\n",
    "    probs = posteriors[np.arange(5), resp_idx]  # shape (5,)\n",
    "    ll = np.sum(np.log(probs))\n",
    "    participant_result[\"ll_literal\"] = ll\n",
    "    \n",
    "    # --- Pragmatic models (for each alpha) ---\n",
    "    for model_name in [\"credulous_T\", \"credulous_F\", \"vigilant_T\", \"vigilant_F\"]:\n",
    "        best_ll = -np.inf\n",
    "        best_alpha = None\n",
    "        \n",
    "        for alpha in alpha_grid:\n",
    "            posteriors = smoothed_lookup[key][model_name][alpha]  # shape (5, 21)\n",
    "            probs = posteriors[np.arange(5), resp_idx]\n",
    "            ll = np.sum(np.log(probs))\n",
    "            \n",
    "            if ll > best_ll:\n",
    "                best_ll = ll\n",
    "                best_alpha = alpha\n",
    "        \n",
    "        participant_result[f\"ll_{model_name}\"] = best_ll\n",
    "        participant_result[f\"alpha_{model_name}\"] = best_alpha\n",
    "    \n",
    "    results.append(participant_result)\n",
    "    \n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(df)} participants\")\n",
    "\n",
    "print(f\"Processed all {len(df)} participants\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE RESULTS DATAFRAME\n",
    "# ============================================================================\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Add responses for reference\n",
    "for r in range(1, 6):\n",
    "    results_df[f\"r{r}_effectiveness\"] = df[f\"r{r}_effectiveness\"].values\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Summary by listener condition\n",
    "for listener_cond in [\"credulous\", \"vigilant\", \"naturalistic\"]:\n",
    "    subset = results_df[results_df[\"listener_belief_condition\"] == listener_cond]\n",
    "    print(f\"\\n{listener_cond.upper()} (n={len(subset)}):\")\n",
    "    \n",
    "    ll_cols = [\"ll_literal\", \"ll_credulous_T\", \"ll_credulous_F\", \"ll_vigilant_T\", \"ll_vigilant_F\"]\n",
    "    for col in ll_cols:\n",
    "        mean_ll = subset[col].mean()\n",
    "        print(f\"  {col}: mean={mean_ll:.2f}\")\n",
    "    \n",
    "    # Which model fits best (highest mean LL)?\n",
    "    mean_lls = {col: subset[col].mean() for col in ll_cols}\n",
    "    best_model = max(mean_lls, key=mean_lls.get)\n",
    "    print(f\"  Best fitting: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04359d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS (alpha optimized per listener condition)\n",
      "============================================================\n",
      "\n",
      "CREDULOUS (n=187):\n",
      "  literal: mean_ll=-12.229\n",
      "  credulous_T: mean_ll=-12.802, alpha=1.000\n",
      "  credulous_F: mean_ll=-12.384, alpha=1.000\n",
      "  vigilant_T: mean_ll=-12.481, alpha=1.000\n",
      "  vigilant_F: mean_ll=-12.406, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "VIGILANT (n=197):\n",
      "  literal: mean_ll=-13.278\n",
      "  credulous_T: mean_ll=-13.704, alpha=1.000\n",
      "  credulous_F: mean_ll=-13.296, alpha=1.000\n",
      "  vigilant_T: mean_ll=-13.484, alpha=1.000\n",
      "  vigilant_F: mean_ll=-13.412, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "NATURALISTIC (n=204):\n",
      "  literal: mean_ll=-12.474\n",
      "  credulous_T: mean_ll=-13.033, alpha=1.000\n",
      "  credulous_F: mean_ll=-12.591, alpha=1.000\n",
      "  vigilant_T: mean_ll=-12.715, alpha=1.000\n",
      "  vigilant_F: mean_ll=-12.635, alpha=1.000\n",
      "  --> Best: literal\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPUTE LOG-LIKELIHOODS (alpha optimized at listener condition level)\n",
    "# ============================================================================\n",
    "\n",
    "ll_cols = [\"ll_literal\", \"ll_credulous_T\", \"ll_credulous_F\", \"ll_vigilant_T\", \"ll_vigilant_F\"]\n",
    "listener_conditions = [\"credulous\", \"vigilant\", \"naturalistic\"]\n",
    "pragmatic_models = [\"credulous_T\", \"credulous_F\", \"vigilant_T\", \"vigilant_F\"]\n",
    "\n",
    "# Store per-participant log-likelihoods for each model x alpha\n",
    "# Structure: {listener_cond: {model: {alpha: [ll_per_participant]}}}\n",
    "ll_by_condition = {cond: {} for cond in listener_conditions}\n",
    "\n",
    "for listener_cond in listener_conditions:\n",
    "    subset = df[df[\"listener_belief_condition\"] == listener_cond]\n",
    "    subset_indices = subset.index.tolist()\n",
    "    \n",
    "    # Literal (no alpha)\n",
    "    lls = []\n",
    "    for i, idx in enumerate(subset_indices):\n",
    "        row = df.loc[idx]\n",
    "        key = (row[\"speaker_condition\"], int(row[\"sequence_idx\"]))\n",
    "        resp_idx = response_indices[df.index.get_loc(idx)]\n",
    "        \n",
    "        posteriors = smoothed_lookup[key][\"literal\"]\n",
    "        probs = posteriors[np.arange(5), resp_idx]\n",
    "        lls.append(np.sum(np.log(probs)))\n",
    "    ll_by_condition[listener_cond][\"literal\"] = {\"none\": lls}\n",
    "    \n",
    "    # Pragmatic models\n",
    "    for model_name in pragmatic_models:\n",
    "        ll_by_condition[listener_cond][model_name] = {}\n",
    "        \n",
    "        for alpha in alpha_grid:\n",
    "            lls = []\n",
    "            for i, idx in enumerate(subset_indices):\n",
    "                row = df.loc[idx]\n",
    "                key = (row[\"speaker_condition\"], int(row[\"sequence_idx\"]))\n",
    "                resp_idx = response_indices[df.index.get_loc(idx)]\n",
    "                \n",
    "                posteriors = smoothed_lookup[key][model_name][alpha]\n",
    "                probs = posteriors[np.arange(5), resp_idx]\n",
    "                lls.append(np.sum(np.log(probs)))\n",
    "            \n",
    "            ll_by_condition[listener_cond][model_name][alpha] = lls\n",
    "\n",
    "# Find best alpha for each listener_cond x model (using mean LL)\n",
    "best_alphas = {cond: {} for cond in listener_conditions}\n",
    "mean_lls = {cond: {} for cond in listener_conditions}\n",
    "\n",
    "for listener_cond in listener_conditions:\n",
    "    # Literal\n",
    "    mean_lls[listener_cond][\"literal\"] = np.mean(ll_by_condition[listener_cond][\"literal\"][\"none\"])\n",
    "    best_alphas[listener_cond][\"literal\"] = None\n",
    "    \n",
    "    # Pragmatic\n",
    "    for model_name in pragmatic_models:\n",
    "        best_mean_ll = -np.inf\n",
    "        best_alpha = None\n",
    "        \n",
    "        for alpha in alpha_grid:\n",
    "            m = np.mean(ll_by_condition[listener_cond][model_name][alpha])\n",
    "            if m > best_mean_ll:\n",
    "                best_mean_ll = m\n",
    "                best_alpha = alpha\n",
    "        \n",
    "        mean_lls[listener_cond][model_name] = best_mean_ll\n",
    "        best_alphas[listener_cond][model_name] = best_alpha\n",
    "\n",
    "# ============================================================================\n",
    "# RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTS (alpha optimized per listener condition)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for listener_cond in listener_conditions:\n",
    "    n = len(df[df[\"listener_belief_condition\"] == listener_cond])\n",
    "    print(f\"\\n{listener_cond.upper()} (n={n}):\")\n",
    "    \n",
    "    for model_name in [\"literal\"] + pragmatic_models:\n",
    "        m = mean_lls[listener_cond][model_name]\n",
    "        a = best_alphas[listener_cond][model_name]\n",
    "        if a is None:\n",
    "            print(f\"  {model_name}: mean_ll={m:.3f}\")\n",
    "        else:\n",
    "            print(f\"  {model_name}: mean_ll={m:.3f}, alpha={a:.3f}\")\n",
    "    \n",
    "    # Best model\n",
    "    best_model = max(mean_lls[listener_cond], key=mean_lls[listener_cond].get)\n",
    "    print(f\"  --> Best: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dcf7513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS (alpha optimized per speaker x listener condition)\n",
      "============================================================\n",
      "\n",
      "INFORMATIVE x CREDULOUS (n=65):\n",
      "  literal: mean_ll=-7.960\n",
      "  credulous_T: mean_ll=-9.078, alpha=1.000\n",
      "  credulous_F: mean_ll=-9.078, alpha=1.000\n",
      "  vigilant_T: mean_ll=-8.456, alpha=1.000\n",
      "  vigilant_F: mean_ll=-8.568, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "INFORMATIVE x VIGILANT (n=58):\n",
      "  literal: mean_ll=-9.964\n",
      "  credulous_T: mean_ll=-10.945, alpha=1.000\n",
      "  credulous_F: mean_ll=-10.945, alpha=1.000\n",
      "  vigilant_T: mean_ll=-10.397, alpha=1.000\n",
      "  vigilant_F: mean_ll=-10.496, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "INFORMATIVE x NATURALISTIC (n=69):\n",
      "  literal: mean_ll=-8.484\n",
      "  credulous_T: mean_ll=-9.522, alpha=1.000\n",
      "  credulous_F: mean_ll=-9.522, alpha=1.000\n",
      "  vigilant_T: mean_ll=-8.950, alpha=1.000\n",
      "  vigilant_F: mean_ll=-9.055, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "PERS_PLUS x CREDULOUS (n=74):\n",
      "  literal: mean_ll=-14.686\n",
      "  credulous_T: mean_ll=-15.003, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.165, alpha=50.000\n",
      "  vigilant_T: mean_ll=-14.441, alpha=6.933\n",
      "  vigilant_F: mean_ll=-14.475, alpha=4.148\n",
      "  --> Best: credulous_F\n",
      "\n",
      "PERS_PLUS x VIGILANT (n=74):\n",
      "  literal: mean_ll=-14.616\n",
      "  credulous_T: mean_ll=-14.774, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.057, alpha=48.063\n",
      "  vigilant_T: mean_ll=-14.719, alpha=4.858\n",
      "  vigilant_F: mean_ll=-14.602, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "PERS_PLUS x NATURALISTIC (n=73):\n",
      "  literal: mean_ll=-14.864\n",
      "  credulous_T: mean_ll=-15.291, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.457, alpha=2.385\n",
      "  vigilant_T: mean_ll=-14.640, alpha=6.406\n",
      "  vigilant_F: mean_ll=-14.671, alpha=3.833\n",
      "  --> Best: credulous_F\n",
      "\n",
      "PERS_MINUS x CREDULOUS (n=48):\n",
      "  literal: mean_ll=-14.223\n",
      "  credulous_T: mean_ll=-14.452, alpha=1.000\n",
      "  credulous_F: mean_ll=-13.802, alpha=50.000\n",
      "  vigilant_T: mean_ll=-14.295, alpha=4.670\n",
      "  vigilant_F: mean_ll=-14.200, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "PERS_MINUS x VIGILANT (n=65):\n",
      "  literal: mean_ll=-14.711\n",
      "  credulous_T: mean_ll=-14.948, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.231, alpha=44.411\n",
      "  vigilant_T: mean_ll=-14.681, alpha=5.054\n",
      "  vigilant_F: mean_ll=-14.657, alpha=1.268\n",
      "  --> Best: credulous_F\n",
      "\n",
      "PERS_MINUS x NATURALISTIC (n=62):\n",
      "  literal: mean_ll=-14.101\n",
      "  credulous_T: mean_ll=-14.282, alpha=1.000\n",
      "  credulous_F: mean_ll=-13.595, alpha=50.000\n",
      "  vigilant_T: mean_ll=-14.095, alpha=5.257\n",
      "  vigilant_F: mean_ll=-14.081, alpha=1.000\n",
      "  --> Best: credulous_F\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPUTE LOG-LIKELIHOODS (alpha optimized at speaker x listener condition level)\n",
    "# ============================================================================\n",
    "\n",
    "ll_cols = [\"ll_literal\", \"ll_credulous_T\", \"ll_credulous_F\", \"ll_vigilant_T\", \"ll_vigilant_F\"]\n",
    "listener_conditions = [\"credulous\", \"vigilant\", \"naturalistic\"]\n",
    "speaker_conditions = [\"informative\", \"pers_plus\", \"pers_minus\"]\n",
    "pragmatic_models = [\"credulous_T\", \"credulous_F\", \"vigilant_T\", \"vigilant_F\"]\n",
    "\n",
    "# Store per-participant log-likelihoods for each model x alpha\n",
    "# Structure: {(speaker_cond, listener_cond): {model: {alpha: [ll_per_participant]}}}\n",
    "ll_by_condition = {}\n",
    "\n",
    "for speaker_cond in speaker_conditions:\n",
    "    for listener_cond in listener_conditions:\n",
    "        cell = (speaker_cond, listener_cond)\n",
    "        ll_by_condition[cell] = {}\n",
    "        \n",
    "        subset = df[(df[\"speaker_condition\"] == speaker_cond) & \n",
    "                    (df[\"listener_belief_condition\"] == listener_cond)]\n",
    "        subset_indices = subset.index.tolist()\n",
    "        \n",
    "        if len(subset_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Literal (no alpha)\n",
    "        lls = []\n",
    "        for idx in subset_indices:\n",
    "            row = df.loc[idx]\n",
    "            key = (row[\"speaker_condition\"], int(row[\"sequence_idx\"]))\n",
    "            resp_idx = response_indices[df.index.get_loc(idx)]\n",
    "            \n",
    "            posteriors = smoothed_lookup[key][\"literal\"]\n",
    "            probs = posteriors[np.arange(5), resp_idx]\n",
    "            lls.append(np.sum(np.log(probs)))\n",
    "        ll_by_condition[cell][\"literal\"] = {\"none\": lls}\n",
    "        \n",
    "        # Pragmatic models\n",
    "        for model_name in pragmatic_models:\n",
    "            ll_by_condition[cell][model_name] = {}\n",
    "            \n",
    "            for alpha in alpha_grid:\n",
    "                lls = []\n",
    "                for idx in subset_indices:\n",
    "                    row = df.loc[idx]\n",
    "                    key = (row[\"speaker_condition\"], int(row[\"sequence_idx\"]))\n",
    "                    resp_idx = response_indices[df.index.get_loc(idx)]\n",
    "                    \n",
    "                    posteriors = smoothed_lookup[key][model_name][alpha]\n",
    "                    probs = posteriors[np.arange(5), resp_idx]\n",
    "                    lls.append(np.sum(np.log(probs)))\n",
    "                \n",
    "                ll_by_condition[cell][model_name][alpha] = lls\n",
    "\n",
    "# Find best alpha for each cell x model (using mean LL)\n",
    "best_alphas = {}\n",
    "mean_lls = {}\n",
    "\n",
    "for speaker_cond in speaker_conditions:\n",
    "    for listener_cond in listener_conditions:\n",
    "        cell = (speaker_cond, listener_cond)\n",
    "        best_alphas[cell] = {}\n",
    "        mean_lls[cell] = {}\n",
    "        \n",
    "        if cell not in ll_by_condition or len(ll_by_condition[cell]) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Literal\n",
    "        mean_lls[cell][\"literal\"] = np.mean(ll_by_condition[cell][\"literal\"][\"none\"])\n",
    "        best_alphas[cell][\"literal\"] = None\n",
    "        \n",
    "        # Pragmatic\n",
    "        for model_name in pragmatic_models:\n",
    "            best_mean_ll = -np.inf\n",
    "            best_alpha = None\n",
    "            \n",
    "            for alpha in alpha_grid:\n",
    "                m = np.mean(ll_by_condition[cell][model_name][alpha])\n",
    "                if m > best_mean_ll:\n",
    "                    best_mean_ll = m\n",
    "                    best_alpha = alpha\n",
    "            \n",
    "            mean_lls[cell][model_name] = best_mean_ll\n",
    "            best_alphas[cell][model_name] = best_alpha\n",
    "\n",
    "# ============================================================================\n",
    "# RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTS (alpha optimized per speaker x listener condition)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for speaker_cond in speaker_conditions:\n",
    "    for listener_cond in listener_conditions:\n",
    "        cell = (speaker_cond, listener_cond)\n",
    "        subset = df[(df[\"speaker_condition\"] == speaker_cond) & \n",
    "                    (df[\"listener_belief_condition\"] == listener_cond)]\n",
    "        n = len(subset)\n",
    "        \n",
    "        print(f\"\\n{speaker_cond.upper()} x {listener_cond.upper()} (n={n}):\")\n",
    "        \n",
    "        for model_name in [\"literal\"] + pragmatic_models:\n",
    "            m = mean_lls[cell][model_name]\n",
    "            a = best_alphas[cell][model_name]\n",
    "            if a is None:\n",
    "                print(f\"  {model_name}: mean_ll={m:.3f}\")\n",
    "            else:\n",
    "                print(f\"  {model_name}: mean_ll={m:.3f}, alpha={a:.3f}\")\n",
    "        \n",
    "        # Best model\n",
    "        best_model = max(mean_lls[cell], key=mean_lls[cell].get)\n",
    "        print(f\"  --> Best: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "461886ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS (alpha optimized per sequence x listener condition)\n",
      "============================================================\n",
      "\n",
      "informative[0] x CREDULOUS (n=29):\n",
      "  literal: mean_ll=-9.145\n",
      "  credulous_T: mean_ll=-10.241, alpha=1.000\n",
      "  credulous_F: mean_ll=-10.241, alpha=1.000\n",
      "  vigilant_T: mean_ll=-9.641, alpha=1.000\n",
      "  vigilant_F: mean_ll=-9.757, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "informative[0] x VIGILANT (n=26):\n",
      "  literal: mean_ll=-10.911\n",
      "  credulous_T: mean_ll=-11.696, alpha=1.000\n",
      "  credulous_F: mean_ll=-11.696, alpha=1.000\n",
      "  vigilant_T: mean_ll=-11.244, alpha=1.000\n",
      "  vigilant_F: mean_ll=-11.323, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "informative[0] x NATURALISTIC (n=36):\n",
      "  literal: mean_ll=-8.544\n",
      "  credulous_T: mean_ll=-9.635, alpha=1.000\n",
      "  credulous_F: mean_ll=-9.635, alpha=1.000\n",
      "  vigilant_T: mean_ll=-9.033, alpha=1.000\n",
      "  vigilant_F: mean_ll=-9.142, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "informative[1] x CREDULOUS (n=36):\n",
      "  literal: mean_ll=-7.005\n",
      "  credulous_T: mean_ll=-8.141, alpha=1.000\n",
      "  credulous_F: mean_ll=-8.141, alpha=1.000\n",
      "  vigilant_T: mean_ll=-7.502, alpha=1.000\n",
      "  vigilant_F: mean_ll=-7.611, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "informative[1] x VIGILANT (n=32):\n",
      "  literal: mean_ll=-9.194\n",
      "  credulous_T: mean_ll=-10.334, alpha=1.000\n",
      "  credulous_F: mean_ll=-10.334, alpha=1.000\n",
      "  vigilant_T: mean_ll=-9.710, alpha=1.000\n",
      "  vigilant_F: mean_ll=-9.825, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "informative[1] x NATURALISTIC (n=33):\n",
      "  literal: mean_ll=-8.420\n",
      "  credulous_T: mean_ll=-9.398, alpha=1.000\n",
      "  credulous_F: mean_ll=-9.398, alpha=1.000\n",
      "  vigilant_T: mean_ll=-8.860, alpha=1.000\n",
      "  vigilant_F: mean_ll=-8.961, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "pers_plus[0] x CREDULOUS (n=27):\n",
      "  literal: mean_ll=-14.067\n",
      "  credulous_T: mean_ll=-13.825, alpha=1.082\n",
      "  credulous_F: mean_ll=-13.702, alpha=42.690\n",
      "  vigilant_T: mean_ll=-14.153, alpha=1.000\n",
      "  vigilant_F: mean_ll=-14.145, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_plus[0] x VIGILANT (n=26):\n",
      "  literal: mean_ll=-14.040\n",
      "  credulous_T: mean_ll=-13.823, alpha=1.218\n",
      "  credulous_F: mean_ll=-13.786, alpha=1.372\n",
      "  vigilant_T: mean_ll=-14.154, alpha=1.000\n",
      "  vigilant_F: mean_ll=-14.202, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_plus[0] x NATURALISTIC (n=27):\n",
      "  literal: mean_ll=-14.008\n",
      "  credulous_T: mean_ll=-13.853, alpha=1.000\n",
      "  credulous_F: mean_ll=-13.774, alpha=1.268\n",
      "  vigilant_T: mean_ll=-14.103, alpha=1.000\n",
      "  vigilant_F: mean_ll=-14.115, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_plus[1] x CREDULOUS (n=26):\n",
      "  literal: mean_ll=-14.997\n",
      "  credulous_T: mean_ll=-15.488, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.133, alpha=28.755\n",
      "  vigilant_T: mean_ll=-13.423, alpha=10.707\n",
      "  vigilant_F: mean_ll=-13.877, alpha=5.690\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_plus[1] x VIGILANT (n=27):\n",
      "  literal: mean_ll=-14.998\n",
      "  credulous_T: mean_ll=-15.385, alpha=1.000\n",
      "  credulous_F: mean_ll=-13.988, alpha=29.914\n",
      "  vigilant_T: mean_ll=-13.474, alpha=10.292\n",
      "  vigilant_F: mean_ll=-14.010, alpha=5.690\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_plus[1] x NATURALISTIC (n=27):\n",
      "  literal: mean_ll=-15.813\n",
      "  credulous_T: mean_ll=-16.586, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.999, alpha=44.411\n",
      "  vigilant_T: mean_ll=-13.602, alpha=12.541\n",
      "  vigilant_F: mean_ll=-13.754, alpha=7.212\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_plus[2] x CREDULOUS (n=21):\n",
      "  literal: mean_ll=-15.098\n",
      "  credulous_T: mean_ll=-15.916, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.799, alpha=27.641\n",
      "  vigilant_T: mean_ll=-13.727, alpha=10.292\n",
      "  vigilant_F: mean_ll=-13.672, alpha=6.664\n",
      "  --> Best: vigilant_F\n",
      "\n",
      "pers_plus[2] x VIGILANT (n=21):\n",
      "  literal: mean_ll=-14.839\n",
      "  credulous_T: mean_ll=-15.160, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.452, alpha=48.063\n",
      "  vigilant_T: mean_ll=-14.412, alpha=6.933\n",
      "  vigilant_F: mean_ll=-14.630, alpha=3.833\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_plus[2] x NATURALISTIC (n=19):\n",
      "  literal: mean_ll=-14.733\n",
      "  credulous_T: mean_ll=-15.494, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.547, alpha=1.485\n",
      "  vigilant_T: mean_ll=-13.724, alpha=8.788\n",
      "  vigilant_F: mean_ll=-13.869, alpha=5.257\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[0] x CREDULOUS (n=16):\n",
      "  literal: mean_ll=-14.021\n",
      "  credulous_T: mean_ll=-13.686, alpha=1.607\n",
      "  credulous_F: mean_ll=-13.613, alpha=42.690\n",
      "  vigilant_T: mean_ll=-14.110, alpha=1.000\n",
      "  vigilant_F: mean_ll=-14.123, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_minus[0] x VIGILANT (n=19):\n",
      "  literal: mean_ll=-13.695\n",
      "  credulous_T: mean_ll=-13.266, alpha=2.581\n",
      "  credulous_F: mean_ll=-13.431, alpha=42.690\n",
      "  vigilant_T: mean_ll=-13.800, alpha=1.000\n",
      "  vigilant_F: mean_ll=-13.879, alpha=1.000\n",
      "  --> Best: credulous_T\n",
      "\n",
      "pers_minus[0] x NATURALISTIC (n=20):\n",
      "  literal: mean_ll=-13.995\n",
      "  credulous_T: mean_ll=-13.775, alpha=1.126\n",
      "  credulous_F: mean_ll=-13.592, alpha=42.690\n",
      "  vigilant_T: mean_ll=-14.089, alpha=1.000\n",
      "  vigilant_F: mean_ll=-14.074, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_minus[1] x CREDULOUS (n=9):\n",
      "  literal: mean_ll=-15.346\n",
      "  credulous_T: mean_ll=-15.905, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.525, alpha=28.755\n",
      "  vigilant_T: mean_ll=-13.569, alpha=12.055\n",
      "  vigilant_F: mean_ll=-14.414, alpha=5.919\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[1] x VIGILANT (n=24):\n",
      "  literal: mean_ll=-15.711\n",
      "  credulous_T: mean_ll=-16.106, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.914, alpha=44.411\n",
      "  vigilant_T: mean_ll=-14.202, alpha=10.292\n",
      "  vigilant_F: mean_ll=-14.666, alpha=5.690\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[1] x NATURALISTIC (n=23):\n",
      "  literal: mean_ll=-14.421\n",
      "  credulous_T: mean_ll=-14.762, alpha=1.000\n",
      "  credulous_F: mean_ll=-13.722, alpha=44.411\n",
      "  vigilant_T: mean_ll=-13.437, alpha=8.788\n",
      "  vigilant_F: mean_ll=-14.098, alpha=4.315\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[2] x CREDULOUS (n=23):\n",
      "  literal: mean_ll=-13.925\n",
      "  credulous_T: mean_ll=-14.391, alpha=1.000\n",
      "  credulous_F: mean_ll=-13.651, alpha=50.000\n",
      "  vigilant_T: mean_ll=-13.298, alpha=7.503\n",
      "  vigilant_F: mean_ll=-13.686, alpha=3.541\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[2] x VIGILANT (n=22):\n",
      "  literal: mean_ll=-14.498\n",
      "  credulous_T: mean_ll=-15.020, alpha=1.000\n",
      "  credulous_F: mean_ll=-14.175, alpha=44.411\n",
      "  vigilant_T: mean_ll=-13.592, alpha=8.120\n",
      "  vigilant_F: mean_ll=-13.776, alpha=4.670\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[2] x NATURALISTIC (n=19):\n",
      "  literal: mean_ll=-13.825\n",
      "  credulous_T: mean_ll=-14.233, alpha=1.000\n",
      "  credulous_F: mean_ll=-13.443, alpha=50.000\n",
      "  vigilant_T: mean_ll=-13.260, alpha=7.805\n",
      "  vigilant_F: mean_ll=-13.714, alpha=2.906\n",
      "  --> Best: vigilant_T\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPUTE LOG-LIKELIHOODS (alpha optimized at sequence x listener condition level)\n",
    "# ============================================================================\n",
    "\n",
    "listener_conditions = [\"credulous\", \"vigilant\", \"naturalistic\"]\n",
    "pragmatic_models = [\"credulous_T\", \"credulous_F\", \"vigilant_T\", \"vigilant_F\"]\n",
    "\n",
    "# Get all unique sequences\n",
    "sequences = [\n",
    "    (\"informative\", 0), (\"informative\", 1),\n",
    "    (\"pers_plus\", 0), (\"pers_plus\", 1), (\"pers_plus\", 2),\n",
    "    (\"pers_minus\", 0), (\"pers_minus\", 1), (\"pers_minus\", 2),\n",
    "]\n",
    "\n",
    "# Store per-participant log-likelihoods for each model x alpha\n",
    "# Structure: {(seq, listener_cond): {model: {alpha: [ll_per_participant]}}}\n",
    "ll_by_condition = {}\n",
    "\n",
    "for seq in sequences:\n",
    "    speaker_cond, seq_idx = seq\n",
    "    for listener_cond in listener_conditions:\n",
    "        cell = (seq, listener_cond)\n",
    "        ll_by_condition[cell] = {}\n",
    "        \n",
    "        subset = df[(df[\"speaker_condition\"] == speaker_cond) & \n",
    "                    (df[\"sequence_idx\"] == seq_idx) &\n",
    "                    (df[\"listener_belief_condition\"] == listener_cond)]\n",
    "        subset_indices = subset.index.tolist()\n",
    "        \n",
    "        if len(subset_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Literal (no alpha)\n",
    "        lls = []\n",
    "        for idx in subset_indices:\n",
    "            row = df.loc[idx]\n",
    "            key = (row[\"speaker_condition\"], int(row[\"sequence_idx\"]))\n",
    "            resp_idx = response_indices[df.index.get_loc(idx)]\n",
    "            \n",
    "            posteriors = smoothed_lookup[key][\"literal\"]\n",
    "            probs = posteriors[np.arange(5), resp_idx]\n",
    "            lls.append(np.sum(np.log(probs)))\n",
    "        ll_by_condition[cell][\"literal\"] = {\"none\": lls}\n",
    "        \n",
    "        # Pragmatic models\n",
    "        for model_name in pragmatic_models:\n",
    "            ll_by_condition[cell][model_name] = {}\n",
    "            \n",
    "            for alpha in alpha_grid:\n",
    "                lls = []\n",
    "                for idx in subset_indices:\n",
    "                    row = df.loc[idx]\n",
    "                    key = (row[\"speaker_condition\"], int(row[\"sequence_idx\"]))\n",
    "                    resp_idx = response_indices[df.index.get_loc(idx)]\n",
    "                    \n",
    "                    posteriors = smoothed_lookup[key][model_name][alpha]\n",
    "                    probs = posteriors[np.arange(5), resp_idx]\n",
    "                    lls.append(np.sum(np.log(probs)))\n",
    "                \n",
    "                ll_by_condition[cell][model_name][alpha] = lls\n",
    "\n",
    "# Find best alpha for each cell x model (using mean LL)\n",
    "best_alphas = {}\n",
    "mean_lls = {}\n",
    "\n",
    "for seq in sequences:\n",
    "    for listener_cond in listener_conditions:\n",
    "        cell = (seq, listener_cond)\n",
    "        best_alphas[cell] = {}\n",
    "        mean_lls[cell] = {}\n",
    "        \n",
    "        if cell not in ll_by_condition or len(ll_by_condition[cell]) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Literal\n",
    "        mean_lls[cell][\"literal\"] = np.mean(ll_by_condition[cell][\"literal\"][\"none\"])\n",
    "        best_alphas[cell][\"literal\"] = None\n",
    "        \n",
    "        # Pragmatic\n",
    "        for model_name in pragmatic_models:\n",
    "            best_mean_ll = -np.inf\n",
    "            best_alpha = None\n",
    "            \n",
    "            for alpha in alpha_grid:\n",
    "                m = np.mean(ll_by_condition[cell][model_name][alpha])\n",
    "                if m > best_mean_ll:\n",
    "                    best_mean_ll = m\n",
    "                    best_alpha = alpha\n",
    "            \n",
    "            mean_lls[cell][model_name] = best_mean_ll\n",
    "            best_alphas[cell][model_name] = best_alpha\n",
    "\n",
    "# ============================================================================\n",
    "# RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTS (alpha optimized per sequence x listener condition)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for seq in sequences:\n",
    "    speaker_cond, seq_idx = seq\n",
    "    for listener_cond in listener_conditions:\n",
    "        cell = (seq, listener_cond)\n",
    "        subset = df[(df[\"speaker_condition\"] == speaker_cond) & \n",
    "                    (df[\"sequence_idx\"] == seq_idx) &\n",
    "                    (df[\"listener_belief_condition\"] == listener_cond)]\n",
    "        n = len(subset)\n",
    "        \n",
    "        if n == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{speaker_cond}[{seq_idx}] x {listener_cond.upper()} (n={n}):\")\n",
    "        \n",
    "        for model_name in [\"literal\"] + pragmatic_models:\n",
    "            m = mean_lls[cell][model_name]\n",
    "            a = best_alphas[cell][model_name]\n",
    "            if a is None:\n",
    "                print(f\"  {model_name}: mean_ll={m:.3f}\")\n",
    "            else:\n",
    "                print(f\"  {model_name}: mean_ll={m:.3f}, alpha={a:.3f}\")\n",
    "        \n",
    "        # Best model\n",
    "        best_model = max(mean_lls[cell], key=mean_lls[cell].get)\n",
    "        print(f\"  --> Best: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "407a91c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed empirical distributions for 24 cells\n",
      "\n",
      "============================================================\n",
      "RESULTS: JS DISTANCE (lower = better)\n",
      "============================================================\n",
      "\n",
      "informative[0] x CREDULOUS (n=29):\n",
      "  literal: JS=0.4621\n",
      "  credulous_T: JS=0.5135, alpha=1.000\n",
      "  credulous_F: JS=0.5135, alpha=1.000\n",
      "  vigilant_T: JS=0.4883, alpha=1.000\n",
      "  vigilant_F: JS=0.4943, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "informative[0] x VIGILANT (n=26):\n",
      "  literal: JS=0.4233\n",
      "  credulous_T: JS=0.4693, alpha=1.000\n",
      "  credulous_F: JS=0.4693, alpha=1.000\n",
      "  vigilant_T: JS=0.4459, alpha=1.000\n",
      "  vigilant_F: JS=0.4512, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "informative[0] x NATURALISTIC (n=36):\n",
      "  literal: JS=0.4260\n",
      "  credulous_T: JS=0.4836, alpha=1.000\n",
      "  credulous_F: JS=0.4836, alpha=1.000\n",
      "  vigilant_T: JS=0.4559, alpha=1.000\n",
      "  vigilant_F: JS=0.4626, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "informative[1] x CREDULOUS (n=36):\n",
      "  literal: JS=0.3699\n",
      "  credulous_T: JS=0.4336, alpha=1.000\n",
      "  credulous_F: JS=0.4336, alpha=1.000\n",
      "  vigilant_T: JS=0.4021, alpha=1.000\n",
      "  vigilant_F: JS=0.4092, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "informative[1] x VIGILANT (n=32):\n",
      "  literal: JS=0.4624\n",
      "  credulous_T: JS=0.5124, alpha=1.000\n",
      "  credulous_F: JS=0.5124, alpha=1.000\n",
      "  vigilant_T: JS=0.4886, alpha=1.000\n",
      "  vigilant_F: JS=0.4946, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "informative[1] x NATURALISTIC (n=33):\n",
      "  literal: JS=0.3841\n",
      "  credulous_T: JS=0.4408, alpha=1.000\n",
      "  credulous_F: JS=0.4408, alpha=1.000\n",
      "  vigilant_T: JS=0.4137, alpha=1.000\n",
      "  vigilant_F: JS=0.4205, alpha=1.000\n",
      "  --> Best: literal\n",
      "\n",
      "pers_plus[0] x CREDULOUS (n=27):\n",
      "  literal: JS=0.4191\n",
      "  credulous_T: JS=0.4018, alpha=1.372\n",
      "  credulous_F: JS=0.3923, alpha=42.690\n",
      "  vigilant_T: JS=0.4252, alpha=1.000\n",
      "  vigilant_F: JS=0.4262, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_plus[0] x VIGILANT (n=26):\n",
      "  literal: JS=0.3951\n",
      "  credulous_T: JS=0.3708, alpha=1.958\n",
      "  credulous_F: JS=0.3673, alpha=44.411\n",
      "  vigilant_T: JS=0.4036, alpha=1.000\n",
      "  vigilant_F: JS=0.4076, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_plus[0] x NATURALISTIC (n=27):\n",
      "  literal: JS=0.4169\n",
      "  credulous_T: JS=0.4051, alpha=1.218\n",
      "  credulous_F: JS=0.3976, alpha=42.690\n",
      "  vigilant_T: JS=0.4232, alpha=1.000\n",
      "  vigilant_F: JS=0.4249, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_plus[1] x CREDULOUS (n=26):\n",
      "  literal: JS=0.4802\n",
      "  credulous_T: JS=0.4901, alpha=1.000\n",
      "  credulous_F: JS=0.4386, alpha=28.755\n",
      "  vigilant_T: JS=0.4042, alpha=12.055\n",
      "  vigilant_F: JS=0.4373, alpha=7.503\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_plus[1] x VIGILANT (n=27):\n",
      "  literal: JS=0.4892\n",
      "  credulous_T: JS=0.4954, alpha=1.000\n",
      "  credulous_F: JS=0.4431, alpha=28.755\n",
      "  vigilant_T: JS=0.4239, alpha=10.707\n",
      "  vigilant_F: JS=0.4617, alpha=6.406\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_plus[1] x NATURALISTIC (n=27):\n",
      "  literal: JS=0.4994\n",
      "  credulous_T: JS=0.5103, alpha=1.000\n",
      "  credulous_F: JS=0.4617, alpha=28.755\n",
      "  vigilant_T: JS=0.4091, alpha=14.119\n",
      "  vigilant_F: JS=0.4226, alpha=8.120\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_plus[2] x CREDULOUS (n=21):\n",
      "  literal: JS=0.4930\n",
      "  credulous_T: JS=0.5092, alpha=1.000\n",
      "  credulous_F: JS=0.4740, alpha=28.755\n",
      "  vigilant_T: JS=0.4260, alpha=13.046\n",
      "  vigilant_F: JS=0.4250, alpha=8.447\n",
      "  --> Best: vigilant_F\n",
      "\n",
      "pers_plus[2] x VIGILANT (n=21):\n",
      "  literal: JS=0.4656\n",
      "  credulous_T: JS=0.4661, alpha=1.000\n",
      "  credulous_F: JS=0.4410, alpha=28.755\n",
      "  vigilant_T: JS=0.4540, alpha=6.664\n",
      "  vigilant_F: JS=0.4652, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_plus[2] x NATURALISTIC (n=19):\n",
      "  literal: JS=0.4494\n",
      "  credulous_T: JS=0.4616, alpha=1.000\n",
      "  credulous_F: JS=0.4364, alpha=1.882\n",
      "  vigilant_T: JS=0.4119, alpha=10.292\n",
      "  vigilant_F: JS=0.4273, alpha=6.406\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[0] x CREDULOUS (n=16):\n",
      "  literal: JS=0.4272\n",
      "  credulous_T: JS=0.3996, alpha=2.119\n",
      "  credulous_F: JS=0.3989, alpha=42.690\n",
      "  vigilant_T: JS=0.4340, alpha=1.000\n",
      "  vigilant_F: JS=0.4365, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_minus[0] x VIGILANT (n=19):\n",
      "  literal: JS=0.3932\n",
      "  credulous_T: JS=0.3583, alpha=3.024\n",
      "  credulous_F: JS=0.3717, alpha=42.690\n",
      "  vigilant_T: JS=0.4009, alpha=1.000\n",
      "  vigilant_F: JS=0.4067, alpha=1.000\n",
      "  --> Best: credulous_T\n",
      "\n",
      "pers_minus[0] x NATURALISTIC (n=20):\n",
      "  literal: JS=0.4241\n",
      "  credulous_T: JS=0.4053, alpha=1.485\n",
      "  credulous_F: JS=0.3951, alpha=42.690\n",
      "  vigilant_T: JS=0.4308, alpha=1.000\n",
      "  vigilant_F: JS=0.4319, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "pers_minus[1] x CREDULOUS (n=9):\n",
      "  literal: JS=0.5835\n",
      "  credulous_T: JS=0.5877, alpha=1.000\n",
      "  credulous_F: JS=0.5521, alpha=28.755\n",
      "  vigilant_T: JS=0.5213, alpha=14.688\n",
      "  vigilant_F: JS=0.5470, alpha=9.894\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[1] x VIGILANT (n=24):\n",
      "  literal: JS=0.4438\n",
      "  credulous_T: JS=0.4488, alpha=1.000\n",
      "  credulous_F: JS=0.3965, alpha=28.755\n",
      "  vigilant_T: JS=0.3745, alpha=10.292\n",
      "  vigilant_F: JS=0.4125, alpha=6.158\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[1] x NATURALISTIC (n=23):\n",
      "  literal: JS=0.4299\n",
      "  credulous_T: JS=0.4269, alpha=1.000\n",
      "  credulous_F: JS=0.3792, alpha=44.411\n",
      "  vigilant_T: JS=0.3716, alpha=10.292\n",
      "  vigilant_F: JS=0.4129, alpha=6.158\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[2] x CREDULOUS (n=23):\n",
      "  literal: JS=0.4641\n",
      "  credulous_T: JS=0.4692, alpha=1.000\n",
      "  credulous_F: JS=0.4469, alpha=28.755\n",
      "  vigilant_T: JS=0.4437, alpha=7.805\n",
      "  vigilant_F: JS=0.4633, alpha=1.000\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[2] x VIGILANT (n=22):\n",
      "  literal: JS=0.4333\n",
      "  credulous_T: JS=0.4407, alpha=1.000\n",
      "  credulous_F: JS=0.4094, alpha=28.755\n",
      "  vigilant_T: JS=0.4012, alpha=7.805\n",
      "  vigilant_F: JS=0.4202, alpha=4.670\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "pers_minus[2] x NATURALISTIC (n=19):\n",
      "  literal: JS=0.4191\n",
      "  credulous_T: JS=0.4265, alpha=1.000\n",
      "  credulous_F: JS=0.3916, alpha=50.000\n",
      "  vigilant_T: JS=0.3954, alpha=7.503\n",
      "  vigilant_F: JS=0.4192, alpha=1.000\n",
      "  --> Best: credulous_F\n",
      "\n",
      "============================================================\n",
      "AGGREGATE BY LISTENER CONDITION (mean JS distance)\n",
      "============================================================\n",
      "\n",
      "CREDULOUS (8 cells):\n",
      "  literal: 0.4624\n",
      "  credulous_T: 0.4756\n",
      "  credulous_F: 0.4562\n",
      "  vigilant_T: 0.4431\n",
      "  vigilant_F: 0.4549\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "VIGILANT (8 cells):\n",
      "  literal: 0.4382\n",
      "  credulous_T: 0.4452\n",
      "  credulous_F: 0.4263\n",
      "  vigilant_T: 0.4241\n",
      "  vigilant_F: 0.4400\n",
      "  --> Best: vigilant_T\n",
      "\n",
      "NATURALISTIC (8 cells):\n",
      "  literal: 0.4311\n",
      "  credulous_T: 0.4450\n",
      "  credulous_F: 0.4233\n",
      "  vigilant_T: 0.4140\n",
      "  vigilant_F: 0.4277\n",
      "  --> Best: vigilant_T\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DISTRIBUTION DISTANCE APPROACH\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "listener_conditions = [\"credulous\", \"vigilant\", \"naturalistic\"]\n",
    "pragmatic_models = [\"credulous_T\", \"credulous_F\", \"vigilant_T\", \"vigilant_F\"]\n",
    "all_models = [\"literal\"] + pragmatic_models\n",
    "\n",
    "sequences = [\n",
    "    (\"informative\", 0), (\"informative\", 1),\n",
    "    (\"pers_plus\", 0), (\"pers_plus\", 1), (\"pers_plus\", 2),\n",
    "    (\"pers_minus\", 0), (\"pers_minus\", 1), (\"pers_minus\", 2),\n",
    "]\n",
    "\n",
    "n_theta = 21\n",
    "n_rounds = 5\n",
    "\n",
    "# ============================================================================\n",
    "# COMPUTE EMPIRICAL DISTRIBUTIONS\n",
    "# ============================================================================\n",
    "\n",
    "# Structure: {(seq, listener_cond): np.array of shape (5, 21)}\n",
    "empirical_dists = {}\n",
    "\n",
    "for seq in sequences:\n",
    "    speaker_cond, seq_idx = seq\n",
    "    for listener_cond in listener_conditions:\n",
    "        cell = (seq, listener_cond)\n",
    "        \n",
    "        subset = df[(df[\"speaker_condition\"] == speaker_cond) & \n",
    "                    (df[\"sequence_idx\"] == seq_idx) &\n",
    "                    (df[\"listener_belief_condition\"] == listener_cond)]\n",
    "        \n",
    "        if len(subset) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get responses for each round\n",
    "        dist = np.zeros((n_rounds, n_theta))\n",
    "        for r in range(n_rounds):\n",
    "            responses = subset[f\"r{r+1}_effectiveness\"].values  # 0-100\n",
    "            indices = (responses / 5).astype(int)\n",
    "            indices = np.clip(indices, 0, n_theta - 1)\n",
    "            \n",
    "            # Count histogram\n",
    "            for idx in indices:\n",
    "                dist[r, idx] += 1\n",
    "            \n",
    "            # Normalize to probability\n",
    "            dist[r] /= dist[r].sum()\n",
    "        \n",
    "        empirical_dists[cell] = dist\n",
    "\n",
    "print(f\"Computed empirical distributions for {len(empirical_dists)} cells\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPUTE DISTANCES FOR EACH MODEL x ALPHA\n",
    "# ============================================================================\n",
    "\n",
    "def compute_distance(empirical, predicted, metric=\"js\"):\n",
    "    \"\"\"Compute distance between two distributions.\"\"\"\n",
    "    if metric == \"js\":\n",
    "        return jensenshannon(empirical, predicted)\n",
    "    elif metric == \"correlation\":\n",
    "        r, _ = pearsonr(empirical, predicted)\n",
    "        return 1 - r  # Convert to distance (0 = perfect match)\n",
    "    elif metric == \"mse\":\n",
    "        return np.mean((empirical - predicted) ** 2)\n",
    "\n",
    "# Structure: {(seq, listener_cond): {model: {alpha: mean_distance_across_rounds}}}\n",
    "distances = {}\n",
    "\n",
    "for cell in empirical_dists:\n",
    "    seq, listener_cond = cell\n",
    "    distances[cell] = {}\n",
    "    \n",
    "    emp = empirical_dists[cell]  # shape (5, 21)\n",
    "    \n",
    "    # Literal (no alpha)\n",
    "    pred = smoothed_lookup[seq][\"literal\"]  # shape (5, 21)\n",
    "    round_dists = [compute_distance(emp[r], pred[r]) for r in range(n_rounds)]\n",
    "    distances[cell][\"literal\"] = {\"none\": np.mean(round_dists)}\n",
    "    \n",
    "    # Pragmatic models\n",
    "    for model_name in pragmatic_models:\n",
    "        distances[cell][model_name] = {}\n",
    "        \n",
    "        for alpha in alpha_grid:\n",
    "            pred = smoothed_lookup[seq][model_name][alpha]\n",
    "            round_dists = [compute_distance(emp[r], pred[r]) for r in range(n_rounds)]\n",
    "            distances[cell][model_name][alpha] = np.mean(round_dists)\n",
    "\n",
    "# ============================================================================\n",
    "# FIND BEST ALPHA AND SUMMARIZE\n",
    "# ============================================================================\n",
    "\n",
    "best_alphas = {}\n",
    "best_distances = {}\n",
    "\n",
    "for cell in distances:\n",
    "    best_alphas[cell] = {}\n",
    "    best_distances[cell] = {}\n",
    "    \n",
    "    # Literal\n",
    "    best_distances[cell][\"literal\"] = distances[cell][\"literal\"][\"none\"]\n",
    "    best_alphas[cell][\"literal\"] = None\n",
    "    \n",
    "    # Pragmatic\n",
    "    for model_name in pragmatic_models:\n",
    "        best_dist = np.inf\n",
    "        best_alpha = None\n",
    "        \n",
    "        for alpha in alpha_grid:\n",
    "            d = distances[cell][model_name][alpha]\n",
    "            if d < best_dist:\n",
    "                best_dist = d\n",
    "                best_alpha = alpha\n",
    "        \n",
    "        best_distances[cell][model_name] = best_dist\n",
    "        best_alphas[cell][model_name] = best_alpha\n",
    "\n",
    "# ============================================================================\n",
    "# RESULTS BY CELL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTS: JS DISTANCE (lower = better)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for seq in sequences:\n",
    "    speaker_cond, seq_idx = seq\n",
    "    for listener_cond in listener_conditions:\n",
    "        cell = (seq, listener_cond)\n",
    "        \n",
    "        if cell not in best_distances:\n",
    "            continue\n",
    "        \n",
    "        subset = df[(df[\"speaker_condition\"] == speaker_cond) & \n",
    "                    (df[\"sequence_idx\"] == seq_idx) &\n",
    "                    (df[\"listener_belief_condition\"] == listener_cond)]\n",
    "        n = len(subset)\n",
    "        \n",
    "        print(f\"\\n{speaker_cond}[{seq_idx}] x {listener_cond.upper()} (n={n}):\")\n",
    "        \n",
    "        for model_name in all_models:\n",
    "            d = best_distances[cell][model_name]\n",
    "            a = best_alphas[cell][model_name]\n",
    "            if a is None:\n",
    "                print(f\"  {model_name}: JS={d:.4f}\")\n",
    "            else:\n",
    "                print(f\"  {model_name}: JS={d:.4f}, alpha={a:.3f}\")\n",
    "        \n",
    "        best_model = min(best_distances[cell], key=best_distances[cell].get)\n",
    "        print(f\"  --> Best: {best_model}\")\n",
    "\n",
    "# ============================================================================\n",
    "# AGGREGATE BY LISTENER CONDITION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"AGGREGATE BY LISTENER CONDITION (mean JS distance)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for listener_cond in listener_conditions:\n",
    "    cells = [c for c in best_distances if c[1] == listener_cond]\n",
    "    \n",
    "    print(f\"\\n{listener_cond.upper()} ({len(cells)} cells):\")\n",
    "    \n",
    "    for model_name in all_models:\n",
    "        mean_dist = np.mean([best_distances[c][model_name] for c in cells])\n",
    "        print(f\"  {model_name}: {mean_dist:.4f}\")\n",
    "    \n",
    "    # Best model\n",
    "    mean_dists = {m: np.mean([best_distances[c][m] for c in cells]) for m in all_models}\n",
    "    best_model = min(mean_dists, key=mean_dists.get)\n",
    "    print(f\"  --> Best: {best_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programming-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
