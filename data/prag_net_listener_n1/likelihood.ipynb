{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60248f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2049: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2062: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2072: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2049: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2062: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2072: SyntaxWarning: invalid escape sequence '\\p'\n",
      "/var/folders/36/q2gvk7yn00z7g9blzrx_jf_h0000gn/T/ipykernel_77346/1074566095.py:2049: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  Returns P(theta) \\propto exp( sum_{psi, alpha} log_joint(theta,psi,alpha) ).\n",
      "/var/folders/36/q2gvk7yn00z7g9blzrx_jf_h0000gn/T/ipykernel_77346/1074566095.py:2062: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  Returns P(psi) \\propto exp( sum_{theta, alpha} log_joint(theta,psi,alpha) ).\n",
      "/var/folders/36/q2gvk7yn00z7g9blzrx_jf_h0000gn/T/ipykernel_77346/1074566095.py:2072: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  Returns P(alpha) \\propto exp( sum_{theta, psi} log_joint(theta,psi,alpha)).\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3dc12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 1: Setting up the world\n",
      "======================================================================\n",
      "Utterances (8): ['all,successful', 'all,unsuccessful', 'most,successful', 'most,unsuccessful', 'some,successful', 'some,unsuccessful', 'no,successful', 'no,unsuccessful']\n",
      "Theta values (11): [np.float64(0.0), np.float64(0.1), np.float64(0.2), np.float64(0.3), np.float64(0.4), np.float64(0.5), np.float64(0.6), np.float64(0.7), np.float64(0.8), np.float64(0.9), np.float64(1.0)]\n",
      "Rounds: 5\n",
      "Total sequences: 32768\n",
      "Alpha values: 20 values from 1.0 to 100.0\n",
      "\n",
      "======================================================================\n",
      "STEP 2: Defining helper functions\n",
      "======================================================================\n",
      "Helper functions defined.\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Computing for LITERAL SPEAKER\n",
      "======================================================================\n",
      "Sum P(seq) for literal: 1.0000000000\n",
      "\n",
      "======================================================================\n",
      "STEP 4: Computing for PRAGMATIC SPEAKERS (update_internal=False)\n",
      "======================================================================\n",
      "\n",
      "  Processing psi='inf' (omega='coop')...\n",
      "    alpha=1.00: Sum P(seq) = 1.0000000000\n",
      "    alpha=100.00: Sum P(seq) = 1.0000000000\n",
      "\n",
      "  Processing psi='pers+' (omega='strat')...\n",
      "    alpha=1.00: Sum P(seq) = 1.0000000000\n",
      "    alpha=100.00: Sum P(seq) = 1.0000000000\n",
      "\n",
      "  Processing psi='pers-' (omega='strat')...\n",
      "    alpha=1.00: Sum P(seq) = 1.0000000000\n",
      "    alpha=100.00: Sum P(seq) = 1.0000000000\n",
      "\n",
      "Completed update_internal=False speakers.\n",
      "\n",
      "======================================================================\n",
      "STEP 5: Computing for PRAGMATIC SPEAKERS (update_internal=True)\n",
      "======================================================================\n",
      "\n",
      "  Processing psi='inf' (omega='coop')...\n",
      "    alpha=1.00: Sum P(seq) = 1.0000000000\n",
      "    alpha=3.37: Sum P(seq) = 1.0000000000\n",
      "    alpha=11.36: Sum P(seq) = 1.0000000000\n",
      "    alpha=38.28: Sum P(seq) = 1.0000000000\n",
      "    alpha=100.00: Sum P(seq) = 1.0000000000\n",
      "\n",
      "  Processing psi='pers+' (omega='strat')...\n",
      "    alpha=1.00: Sum P(seq) = 1.0000000000\n",
      "    alpha=3.37: Sum P(seq) = 1.0000000000\n",
      "    alpha=11.36: Sum P(seq) = 1.0000000000\n",
      "    alpha=38.28: Sum P(seq) = 1.0000000000\n",
      "    alpha=100.00: Sum P(seq) = 1.0000000000\n",
      "\n",
      "  Processing psi='pers-' (omega='strat')...\n",
      "    alpha=1.00: Sum P(seq) = 1.0000000000\n",
      "    alpha=3.37: Sum P(seq) = 1.0000000000\n",
      "    alpha=11.36: Sum P(seq) = 1.0000000000\n",
      "    alpha=38.28: Sum P(seq) = 1.0000000000\n",
      "    alpha=100.00: Sum P(seq) = 1.0000000000\n",
      "\n",
      "Completed update_internal=True speakers.\n",
      "\n",
      "======================================================================\n",
      "STEP 6: Organizing results into DataFrame\n",
      "======================================================================\n",
      "DataFrame shape: (32768, 123)\n",
      "Columns: 123\n",
      "\n",
      "======================================================================\n",
      "STEP 7: Verification - All probability columns should sum to 1\n",
      "======================================================================\n",
      "\n",
      "Column sums (should all be 1.0):\n",
      "  literal: 1.0000000000\n",
      "  pragmatic_inf_F: min=1.0000000000, max=1.0000000000\n",
      "  pragmatic_persp_F: min=1.0000000000, max=1.0000000000\n",
      "  pragmatic_persm_F: min=1.0000000000, max=1.0000000000\n",
      "  pragmatic_inf_T: min=1.0000000000, max=1.0000000000\n",
      "  pragmatic_persp_T: min=1.0000000000, max=1.0000000000\n",
      "  pragmatic_persm_T: min=1.0000000000, max=1.0000000000\n",
      "\n",
      "======================================================================\n",
      "STEP 8: Summary statistics - Entropy and concentration\n",
      "======================================================================\n",
      "Max possible entropy (uniform): 10.3972\n",
      "\n",
      "Literal speaker:\n",
      "speaker_type update_internal psi alpha  entropy  top1_prob  top10_prob\n",
      "     literal               -   -     - 8.436536   0.001877    0.016872\n",
      "\n",
      "Pragmatic speakers - entropy by alpha (selected alphas):\n",
      "\n",
      "  psi='inf':\n",
      "update_internal  alpha  entropy  top1_prob  top10_prob\n",
      "          False    1.0 8.751125   0.000984    0.009430\n",
      "          False  2.073 8.547790   0.002512    0.022480\n",
      "          False  5.482 7.301982   0.017317    0.079707\n",
      "          False  14.48 6.244046   0.030552    0.140720\n",
      "          False  38.28 6.214868   0.030742    0.141595\n",
      "          False  100.0 6.214868   0.030742    0.141595\n",
      "           True    1.0 9.002740   0.000483    0.004804\n",
      "           True  2.073 8.930556   0.001009    0.009905\n",
      "           True  5.482 8.002770   0.005156    0.048217\n",
      "           True  14.48 6.927275   0.009709    0.086137\n",
      "           True  38.28 6.432339   0.019072    0.116517\n",
      "           True  100.0 6.250073   0.027899    0.135897\n",
      "\n",
      "  psi='pers+':\n",
      "update_internal  alpha  entropy  top1_prob  top10_prob\n",
      "          False    1.0 8.054888   0.004618    0.030154\n",
      "          False  2.073 7.519558   0.015683    0.067735\n",
      "          False  5.482 6.416142   0.064333    0.154216\n",
      "          False  14.48 5.606676   0.096972    0.225194\n",
      "          False  38.28 5.519429   0.097791    0.229370\n",
      "          False  100.0 5.519121   0.097791    0.229373\n",
      "           True    1.0 8.244485   0.003737    0.024224\n",
      "           True  2.073 7.927457   0.010440    0.046909\n",
      "           True  5.482 7.137328   0.046378    0.117099\n",
      "           True  14.48 6.293486   0.092705    0.184371\n",
      "           True  38.28 5.868928   0.097819    0.212681\n",
      "           True  100.0 5.740359   0.097791    0.227562\n",
      "\n",
      "  psi='pers-':\n",
      "update_internal  alpha  entropy  top1_prob  top10_prob\n",
      "          False    1.0 8.054888   0.004618    0.030154\n",
      "          False  2.073 7.519558   0.015683    0.067735\n",
      "          False  5.482 6.416142   0.064333    0.154216\n",
      "          False  14.48 5.606676   0.096972    0.225194\n",
      "          False  38.28 5.519429   0.097791    0.229370\n",
      "          False  100.0 5.519121   0.097791    0.229373\n",
      "           True    1.0 8.244485   0.003737    0.024224\n",
      "           True  2.073 7.927457   0.010440    0.046909\n",
      "           True  5.482 7.137328   0.046378    0.117099\n",
      "           True  14.48 6.293486   0.092705    0.184371\n",
      "           True  38.28 5.868928   0.097819    0.212681\n",
      "           True  100.0 5.740359   0.097791    0.227562\n",
      "\n",
      "======================================================================\n",
      "STEP 9: Top 10 sequences for each speaker type (alpha=5.48)\n",
      "======================================================================\n",
      "\n",
      "--- LITERAL ---\n",
      "                                                                                       sequence  literal\n",
      "          (some,successful, some,successful, some,successful, some,successful, some,successful) 0.001877\n",
      "(some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful) 0.001877\n",
      "        (some,successful, some,successful, some,unsuccessful, some,successful, some,successful) 0.001640\n",
      "        (some,successful, some,unsuccessful, some,successful, some,successful, some,successful) 0.001640\n",
      "  (some,successful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful) 0.001640\n",
      "        (some,unsuccessful, some,successful, some,successful, some,successful, some,successful) 0.001640\n",
      "  (some,unsuccessful, some,successful, some,unsuccessful, some,unsuccessful, some,unsuccessful) 0.001640\n",
      "  (some,unsuccessful, some,unsuccessful, some,successful, some,unsuccessful, some,unsuccessful) 0.001640\n",
      "  (some,unsuccessful, some,unsuccessful, some,unsuccessful, some,successful, some,unsuccessful) 0.001640\n",
      "        (some,successful, some,successful, some,successful, some,successful, some,unsuccessful) 0.001640\n",
      "\n",
      "--- PRAGMATIC psi='inf' update_internal=False ---\n",
      "                                                                                       sequence  pragmatic_inf_F_alpha=5.48\n",
      "          (most,successful, most,successful, most,successful, most,successful, most,successful)                    0.017317\n",
      "(most,unsuccessful, most,unsuccessful, most,unsuccessful, most,unsuccessful, most,unsuccessful)                    0.017317\n",
      "        (most,successful, most,successful, most,successful, most,successful, most,unsuccessful)                    0.005634\n",
      "        (most,successful, most,successful, most,successful, most,unsuccessful, most,successful)                    0.005634\n",
      "        (most,successful, most,successful, most,unsuccessful, most,successful, most,successful)                    0.005634\n",
      "        (most,successful, most,unsuccessful, most,successful, most,successful, most,successful)                    0.005634\n",
      "        (most,unsuccessful, most,successful, most,successful, most,successful, most,successful)                    0.005634\n",
      "  (most,successful, most,unsuccessful, most,unsuccessful, most,unsuccessful, most,unsuccessful)                    0.005634\n",
      "  (most,unsuccessful, most,successful, most,unsuccessful, most,unsuccessful, most,unsuccessful)                    0.005634\n",
      "  (most,unsuccessful, most,unsuccessful, most,successful, most,unsuccessful, most,unsuccessful)                    0.005634\n",
      "\n",
      "--- PRAGMATIC psi='inf' update_internal=True ---\n",
      "                                                                                     sequence  pragmatic_inf_T_alpha=5.48\n",
      "      (most,successful, most,unsuccessful, most,successful, most,successful, most,successful)                    0.005156\n",
      "(most,unsuccessful, most,successful, most,unsuccessful, most,unsuccessful, most,unsuccessful)                    0.005156\n",
      "(most,successful, most,unsuccessful, most,unsuccessful, most,unsuccessful, most,unsuccessful)                    0.005155\n",
      "      (most,unsuccessful, most,successful, most,successful, most,successful, most,successful)                    0.005155\n",
      "    (most,successful, most,unsuccessful, most,successful, most,unsuccessful, most,successful)                    0.004599\n",
      "  (most,unsuccessful, most,successful, most,unsuccessful, most,successful, most,unsuccessful)                    0.004599\n",
      "    (most,successful, most,unsuccessful, most,unsuccessful, most,successful, most,successful)                    0.004599\n",
      "  (most,unsuccessful, most,successful, most,successful, most,unsuccessful, most,unsuccessful)                    0.004599\n",
      "  (most,successful, most,unsuccessful, most,unsuccessful, most,successful, most,unsuccessful)                    0.004599\n",
      "    (most,unsuccessful, most,successful, most,successful, most,unsuccessful, most,successful)                    0.004599\n",
      "\n",
      "--- PRAGMATIC psi='pers+' update_internal=False ---\n",
      "                                                                                       sequence  pragmatic_persp_F_alpha=5.48\n",
      "(some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.064333\n",
      "          (some,successful, some,successful, some,successful, some,successful, some,successful)                      0.020750\n",
      "          (most,successful, most,successful, most,successful, most,successful, most,successful)                      0.009360\n",
      "        (some,successful, some,successful, some,successful, some,successful, some,unsuccessful)                      0.009003\n",
      "        (some,successful, some,successful, some,successful, some,unsuccessful, some,successful)                      0.009003\n",
      "        (some,successful, some,successful, some,unsuccessful, some,successful, some,successful)                      0.009003\n",
      "        (some,successful, some,unsuccessful, some,successful, some,successful, some,successful)                      0.009003\n",
      "        (some,unsuccessful, some,successful, some,successful, some,successful, some,successful)                      0.009003\n",
      "          (most,successful, some,successful, some,successful, some,successful, some,successful)                      0.007379\n",
      "          (some,successful, most,successful, some,successful, some,successful, some,successful)                      0.007379\n",
      "\n",
      "--- PRAGMATIC psi='pers+' update_internal=True ---\n",
      "                                                                                       sequence  pragmatic_persp_T_alpha=5.48\n",
      "(some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.046378\n",
      "(some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful, most,unsuccessful)                      0.012562\n",
      "(some,unsuccessful, some,unsuccessful, some,unsuccessful, most,unsuccessful, some,unsuccessful)                      0.009786\n",
      "          (some,successful, some,successful, some,successful, some,successful, some,successful)                      0.008298\n",
      "  (some,successful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.007414\n",
      "(some,unsuccessful, some,unsuccessful, most,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.007205\n",
      "        (some,successful, some,successful, some,successful, some,successful, some,unsuccessful)                      0.006853\n",
      "    (some,successful, some,successful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.006372\n",
      "      (some,successful, some,successful, some,successful, some,unsuccessful, some,unsuccessful)                      0.006324\n",
      "  (some,unsuccessful, some,successful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.005907\n",
      "\n",
      "--- PRAGMATIC psi='pers-' update_internal=False ---\n",
      "                                                                                       sequence  pragmatic_persm_F_alpha=5.48\n",
      "          (some,successful, some,successful, some,successful, some,successful, some,successful)                      0.064333\n",
      "(some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.020750\n",
      "(most,unsuccessful, most,unsuccessful, most,unsuccessful, most,unsuccessful, most,unsuccessful)                      0.009360\n",
      "  (some,successful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.009003\n",
      "  (some,unsuccessful, some,successful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.009003\n",
      "  (some,unsuccessful, some,unsuccessful, some,successful, some,unsuccessful, some,unsuccessful)                      0.009003\n",
      "  (some,unsuccessful, some,unsuccessful, some,unsuccessful, some,successful, some,unsuccessful)                      0.009003\n",
      "  (some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,successful)                      0.009003\n",
      "(most,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.007379\n",
      "(some,unsuccessful, most,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.007379\n",
      "\n",
      "--- PRAGMATIC psi='pers-' update_internal=True ---\n",
      "                                                                                       sequence  pragmatic_persm_T_alpha=5.48\n",
      "          (some,successful, some,successful, some,successful, some,successful, some,successful)                      0.046378\n",
      "          (some,successful, some,successful, some,successful, some,successful, most,successful)                      0.012562\n",
      "          (some,successful, some,successful, some,successful, most,successful, some,successful)                      0.009786\n",
      "(some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful)                      0.008298\n",
      "        (some,unsuccessful, some,successful, some,successful, some,successful, some,successful)                      0.007414\n",
      "          (some,successful, some,successful, most,successful, some,successful, some,successful)                      0.007205\n",
      "  (some,unsuccessful, some,unsuccessful, some,unsuccessful, some,unsuccessful, some,successful)                      0.006853\n",
      "      (some,unsuccessful, some,unsuccessful, some,successful, some,successful, some,successful)                      0.006372\n",
      "    (some,unsuccessful, some,unsuccessful, some,unsuccessful, some,successful, some,successful)                      0.006324\n",
      "        (some,successful, some,unsuccessful, some,successful, some,successful, some,successful)                      0.005907\n",
      "\n",
      "======================================================================\n",
      "STEP 10: Saving results\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/home/claude'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 447\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# Save main results\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[43mresults_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/claude/sequence_probabilities.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSaved: /home/claude/sequence_probabilities.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# Save summary\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/core/generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/io/common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/io/common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '/home/claude'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from scipy.special import logsumexp\n",
    "import copy\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Set up the world and basic quantities\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: Setting up the world\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "world = World(n=1, m=5)\n",
    "\n",
    "utterances = world.utterances\n",
    "theta_values = world.theta_values\n",
    "n_utterances = len(utterances)\n",
    "n_theta = len(theta_values)\n",
    "n_rounds = 5\n",
    "n_sequences = n_utterances ** n_rounds\n",
    "\n",
    "# Flat prior over theta\n",
    "log_prior_theta = np.full(n_theta, -np.log(n_theta))\n",
    "\n",
    "# P(O|θ) matrix for marginalizing\n",
    "log_P_O_given_theta = world.obs_log_likelihood_theta.values  # (n_obs, n_theta)\n",
    "\n",
    "# All sequences as tuples of indices\n",
    "all_sequences = list(itertools.product(range(n_utterances), repeat=n_rounds))\n",
    "sequence_labels = [tuple(utterances[i] for i in seq) for seq in all_sequences]\n",
    "\n",
    "# Alpha values\n",
    "alpha_values = [1.000, 1.275, 1.626, 2.073, 2.643, 3.371, 4.299, 5.482, \n",
    "                6.988, 8.909, 11.36, 14.48, 18.46, 23.54, 30.02, 38.28, \n",
    "                48.80, 62.23, 79.32, 100.0]\n",
    "n_alpha = len(alpha_values)\n",
    "\n",
    "print(f\"Utterances ({n_utterances}): {utterances}\")\n",
    "print(f\"Theta values ({n_theta}): {list(theta_values)}\")\n",
    "print(f\"Rounds: {n_rounds}\")\n",
    "print(f\"Total sequences: {n_sequences}\")\n",
    "print(f\"Alpha values: {n_alpha} values from {alpha_values[0]} to {alpha_values[-1]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Define helper functions\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: Defining helper functions\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def get_log_P_u_given_theta_from_speaker(speaker, log_P_O_given_theta):\n",
    "    \"\"\"\n",
    "    Compute log P(u|θ) = log Σ_O P(u|O) · P(O|θ) for a speaker.\n",
    "    Returns shape (n_utterances, n_theta).\n",
    "    \"\"\"\n",
    "    log_P_u_given_O = speaker.utterance_log_prob_obs.values  # (n_utt, n_obs)\n",
    "    log_P_u_given_theta = log_M_product(\n",
    "        log_P_u_given_O,\n",
    "        log_P_O_given_theta,\n",
    "        precise=USE_PRECISE_LOGSPACE\n",
    "    )\n",
    "    return log_P_u_given_theta\n",
    "\n",
    "\n",
    "def compute_log_P_seq_given_theta_independent(log_P_u_given_theta, all_sequences, n_rounds):\n",
    "    \"\"\"\n",
    "    Compute log P(seq | θ) when utterances are conditionally independent given θ.\n",
    "    Used for: Literal speaker, and Pragmatic speakers with update_internal=False.\n",
    "    \n",
    "    log P(seq | θ) = Σᵢ log P(uᵢ | θ)\n",
    "    \n",
    "    Returns shape (n_sequences, n_theta).\n",
    "    \"\"\"\n",
    "    n_sequences = len(all_sequences)\n",
    "    n_theta = log_P_u_given_theta.shape[1]\n",
    "    \n",
    "    log_P_seq_given_theta = np.zeros((n_sequences, n_theta))\n",
    "    \n",
    "    for seq_idx, seq in enumerate(all_sequences):\n",
    "        for round_idx in range(n_rounds):\n",
    "            u_idx = seq[round_idx]\n",
    "            log_P_seq_given_theta[seq_idx, :] += log_P_u_given_theta[u_idx, :]\n",
    "    \n",
    "    return log_P_seq_given_theta\n",
    "\n",
    "\n",
    "def marginalize_over_theta(log_P_seq_given_theta, log_prior_theta):\n",
    "    \"\"\"\n",
    "    Compute log P(seq) = log Σ_θ P(seq | θ) · P(θ).\n",
    "    Returns shape (n_sequences,).\n",
    "    \"\"\"\n",
    "    log_P_seq_and_theta = log_P_seq_given_theta + log_prior_theta  # broadcast\n",
    "    log_P_seq = logsumexp(log_P_seq_and_theta, axis=1)\n",
    "    return log_P_seq\n",
    "\n",
    "print(\"Helper functions defined.\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3: Compute for LITERAL SPEAKER (no alpha dependence)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: Computing for LITERAL SPEAKER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "literal_listener = LiteralListener(world)\n",
    "literal_speaker = literal_listener.literal_speaker\n",
    "\n",
    "# Get P(u|θ) - this is already computed in literal_listener\n",
    "log_P_u_given_theta_literal = literal_listener.utterance_log_likelihood_theta.values\n",
    "\n",
    "# Compute P(seq|θ) - utterances are conditionally independent\n",
    "log_P_seq_given_theta_literal = compute_log_P_seq_given_theta_independent(\n",
    "    log_P_u_given_theta_literal, all_sequences, n_rounds\n",
    ")\n",
    "\n",
    "# Marginalize over θ\n",
    "log_P_seq_literal = marginalize_over_theta(log_P_seq_given_theta_literal, log_prior_theta)\n",
    "\n",
    "print(f\"Sum P(seq) for literal: {np.exp(logsumexp(log_P_seq_literal)):.10f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4: Compute for PRAGMATIC SPEAKERS with update_internal=FALSE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: Computing for PRAGMATIC SPEAKERS (update_internal=False)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# These are conditionally independent given θ, so we use the simple approach.\n",
    "# We need to compute for each (psi, alpha) combination.\n",
    "\n",
    "# Storage: dict[psi] -> array of shape (n_sequences, n_alpha)\n",
    "log_P_seq_pragmatic_F = {\n",
    "    \"inf\": np.zeros((n_sequences, n_alpha)),\n",
    "    \"pers+\": np.zeros((n_sequences, n_alpha)),\n",
    "    \"pers-\": np.zeros((n_sequences, n_alpha))\n",
    "}\n",
    "\n",
    "for psi in [\"inf\", \"pers+\", \"pers-\"]:\n",
    "    omega = \"coop\" if psi == \"inf\" else \"strat\"\n",
    "    print(f\"\\n  Processing psi='{psi}' (omega='{omega}')...\")\n",
    "    \n",
    "    for alpha_idx, alpha in enumerate(alpha_values):\n",
    "        # Create pragmatic speaker with update_internal=False\n",
    "        speaker = PragmaticSpeaker_obs(\n",
    "            world=world,\n",
    "            omega=omega,\n",
    "            psi=psi,\n",
    "            update_internal=False,\n",
    "            alpha=alpha,\n",
    "            beta=0.0\n",
    "        )\n",
    "        \n",
    "        # Get P(u|θ)\n",
    "        log_P_u_given_theta = get_log_P_u_given_theta_from_speaker(speaker, log_P_O_given_theta)\n",
    "        \n",
    "        # Compute P(seq|θ) - conditionally independent\n",
    "        log_P_seq_given_theta = compute_log_P_seq_given_theta_independent(\n",
    "            log_P_u_given_theta, all_sequences, n_rounds\n",
    "        )\n",
    "        \n",
    "        # Marginalize over θ\n",
    "        log_P_seq = marginalize_over_theta(log_P_seq_given_theta, log_prior_theta)\n",
    "        \n",
    "        log_P_seq_pragmatic_F[psi][:, alpha_idx] = log_P_seq\n",
    "        \n",
    "        if alpha_idx == 0 or alpha_idx == n_alpha - 1:\n",
    "            print(f\"    alpha={alpha:.2f}: Sum P(seq) = {np.exp(logsumexp(log_P_seq)):.10f}\")\n",
    "\n",
    "print(\"\\nCompleted update_internal=False speakers.\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5: Compute for PRAGMATIC SPEAKERS with update_internal=TRUE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: Computing for PRAGMATIC SPEAKERS (update_internal=True)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# This requires computing P(u|θ) for each history prefix.\n",
    "# Total histories: 1 + 8 + 64 + 512 + 4096 = 4681\n",
    "\n",
    "def create_speaker_with_history(world, omega, psi, alpha, history_utterances):\n",
    "    \"\"\"\n",
    "    Create a pragmatic speaker and apply utterance history to its internal listener.\n",
    "    \"\"\"\n",
    "    speaker = PragmaticSpeaker_obs(\n",
    "        world=world,\n",
    "        omega=omega,\n",
    "        psi=psi,\n",
    "        update_internal=True,\n",
    "        alpha=alpha,\n",
    "        beta=0.0\n",
    "    )\n",
    "    \n",
    "    # Apply each utterance in the history\n",
    "    for u in history_utterances:\n",
    "        speaker.literal_listener.listen_and_update(u)\n",
    "        speaker.utterance_log_prob_obs = speaker._compute_utterance_log_prob_obs(alpha)\n",
    "    \n",
    "    return speaker\n",
    "\n",
    "\n",
    "def compute_log_P_seq_given_theta_history_dependent(\n",
    "    world, omega, psi, alpha, all_sequences, n_rounds, log_P_O_given_theta, utterances\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute log P(seq | θ) when utterances depend on history (update_internal=True).\n",
    "    \n",
    "    log P(seq | θ) = Σᵢ log P^{h_i}(uᵢ | θ)\n",
    "    \n",
    "    where h_i = (u_0, ..., u_{i-1}) is the history before round i.\n",
    "    \n",
    "    Returns shape (n_sequences, n_theta).\n",
    "    \"\"\"\n",
    "    n_sequences = len(all_sequences)\n",
    "    n_theta = len(world.theta_values)\n",
    "    n_utterances = len(utterances)\n",
    "    \n",
    "    # Precompute P(u|θ) for all histories\n",
    "    # Key: history tuple (indices), Value: log P(u|θ) matrix of shape (n_utt, n_theta)\n",
    "    history_log_P_u_given_theta = {}\n",
    "    \n",
    "    for history_length in range(n_rounds):\n",
    "        if history_length == 0:\n",
    "            # Empty history\n",
    "            speaker = create_speaker_with_history(world, omega, psi, alpha, [])\n",
    "            history_log_P_u_given_theta[()] = get_log_P_u_given_theta_from_speaker(\n",
    "                speaker, log_P_O_given_theta\n",
    "            )\n",
    "        else:\n",
    "            # All histories of this length\n",
    "            for history in itertools.product(range(n_utterances), repeat=history_length):\n",
    "                history_utterances = [utterances[idx] for idx in history]\n",
    "                speaker = create_speaker_with_history(world, omega, psi, alpha, history_utterances)\n",
    "                history_log_P_u_given_theta[history] = get_log_P_u_given_theta_from_speaker(\n",
    "                    speaker, log_P_O_given_theta\n",
    "                )\n",
    "    \n",
    "    # Now compute P(seq|θ) for each sequence\n",
    "    log_P_seq_given_theta = np.zeros((n_sequences, n_theta))\n",
    "    \n",
    "    for seq_idx, seq in enumerate(all_sequences):\n",
    "        log_prob = np.zeros(n_theta)\n",
    "        for round_idx in range(n_rounds):\n",
    "            history = seq[:round_idx]\n",
    "            u_idx = seq[round_idx]\n",
    "            log_prob += history_log_P_u_given_theta[history][u_idx, :]\n",
    "        log_P_seq_given_theta[seq_idx, :] = log_prob\n",
    "    \n",
    "    return log_P_seq_given_theta\n",
    "\n",
    "\n",
    "# Storage: dict[psi] -> array of shape (n_sequences, n_alpha)\n",
    "log_P_seq_pragmatic_T = {\n",
    "    \"inf\": np.zeros((n_sequences, n_alpha)),\n",
    "    \"pers+\": np.zeros((n_sequences, n_alpha)),\n",
    "    \"pers-\": np.zeros((n_sequences, n_alpha))\n",
    "}\n",
    "\n",
    "for psi in [\"inf\", \"pers+\", \"pers-\"]:\n",
    "    omega = \"coop\" if psi == \"inf\" else \"strat\"\n",
    "    print(f\"\\n  Processing psi='{psi}' (omega='{omega}')...\")\n",
    "    \n",
    "    for alpha_idx, alpha in enumerate(alpha_values):\n",
    "        # Compute P(seq|θ) with history dependence\n",
    "        log_P_seq_given_theta = compute_log_P_seq_given_theta_history_dependent(\n",
    "            world, omega, psi, alpha, all_sequences, n_rounds, \n",
    "            log_P_O_given_theta, utterances\n",
    "        )\n",
    "        \n",
    "        # Marginalize over θ\n",
    "        log_P_seq = marginalize_over_theta(log_P_seq_given_theta, log_prior_theta)\n",
    "        \n",
    "        log_P_seq_pragmatic_T[psi][:, alpha_idx] = log_P_seq\n",
    "        \n",
    "        if alpha_idx % 5 == 0 or alpha_idx == n_alpha - 1:\n",
    "            print(f\"    alpha={alpha:.2f}: Sum P(seq) = {np.exp(logsumexp(log_P_seq)):.10f}\")\n",
    "\n",
    "print(\"\\nCompleted update_internal=True speakers.\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 6: Organize all results into a single DataFrame\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: Organizing results into DataFrame\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# We'll create a DataFrame with columns:\n",
    "# - sequence (tuple of utterances)\n",
    "# - sequence_idx (tuple of indices)\n",
    "# - literal (single column, no alpha dependence)\n",
    "# - pragmatic_inf_F_alpha=X (one column per alpha)\n",
    "# - pragmatic_persp_F_alpha=X\n",
    "# - pragmatic_persm_F_alpha=X\n",
    "# - pragmatic_inf_T_alpha=X\n",
    "# - pragmatic_persp_T_alpha=X\n",
    "# - pragmatic_persm_T_alpha=X\n",
    "\n",
    "results = {\n",
    "    'sequence': sequence_labels,\n",
    "    'sequence_idx': all_sequences,\n",
    "    'literal': np.exp(log_P_seq_literal)\n",
    "}\n",
    "\n",
    "# Add pragmatic F columns\n",
    "for psi, short_name in [(\"inf\", \"inf\"), (\"pers+\", \"persp\"), (\"pers-\", \"persm\")]:\n",
    "    for alpha_idx, alpha in enumerate(alpha_values):\n",
    "        col_name = f\"pragmatic_{short_name}_F_alpha={alpha:.2f}\"\n",
    "        results[col_name] = np.exp(log_P_seq_pragmatic_F[psi][:, alpha_idx])\n",
    "\n",
    "# Add pragmatic T columns\n",
    "for psi, short_name in [(\"inf\", \"inf\"), (\"pers+\", \"persp\"), (\"pers-\", \"persm\")]:\n",
    "    for alpha_idx, alpha in enumerate(alpha_values):\n",
    "        col_name = f\"pragmatic_{short_name}_T_alpha={alpha:.2f}\"\n",
    "        results[col_name] = np.exp(log_P_seq_pragmatic_T[psi][:, alpha_idx])\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"DataFrame shape: {results_df.shape}\")\n",
    "print(f\"Columns: {len(results_df.columns)}\")\n",
    "# Expected: 2 (sequence info) + 1 (literal) + 3*20 (F) + 3*20 (T) = 123 columns\n",
    "\n",
    "# =============================================================================\n",
    "# Step 7: Verify all probabilities sum to 1\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 7: Verification - All probability columns should sum to 1\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "prob_cols = [c for c in results_df.columns if c not in ['sequence', 'sequence_idx']]\n",
    "sums = results_df[prob_cols].sum()\n",
    "\n",
    "print(\"\\nColumn sums (should all be 1.0):\")\n",
    "print(f\"  literal: {sums['literal']:.10f}\")\n",
    "\n",
    "for speaker_type in ['inf_F', 'persp_F', 'persm_F', 'inf_T', 'persp_T', 'persm_T']:\n",
    "    cols = [c for c in prob_cols if speaker_type in c]\n",
    "    col_sums = sums[cols]\n",
    "    print(f\"  pragmatic_{speaker_type}: min={col_sums.min():.10f}, max={col_sums.max():.10f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 8: Summary statistics - entropy and concentration\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 8: Summary statistics - Entropy and concentration\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def compute_entropy(P):\n",
    "    \"\"\"Compute entropy -Σ P log P.\"\"\"\n",
    "    P_safe = P[P > 0]\n",
    "    return -np.sum(P_safe * np.log(P_safe))\n",
    "\n",
    "max_entropy = np.log(n_sequences)\n",
    "print(f\"Max possible entropy (uniform): {max_entropy:.4f}\")\n",
    "\n",
    "# Compute entropy for each speaker type and alpha\n",
    "summary_rows = []\n",
    "\n",
    "# Literal\n",
    "P_literal = np.exp(log_P_seq_literal)\n",
    "summary_rows.append({\n",
    "    'speaker_type': 'literal',\n",
    "    'update_internal': '-',\n",
    "    'psi': '-',\n",
    "    'alpha': '-',\n",
    "    'entropy': compute_entropy(P_literal),\n",
    "    'top1_prob': np.max(P_literal),\n",
    "    'top10_prob': np.sort(P_literal)[-10:].sum()\n",
    "})\n",
    "\n",
    "# Pragmatic\n",
    "for update_internal, log_P_dict, label in [\n",
    "    (False, log_P_seq_pragmatic_F, 'F'),\n",
    "    (True, log_P_seq_pragmatic_T, 'T')\n",
    "]:\n",
    "    for psi in [\"inf\", \"pers+\", \"pers-\"]:\n",
    "        for alpha_idx, alpha in enumerate(alpha_values):\n",
    "            P = np.exp(log_P_dict[psi][:, alpha_idx])\n",
    "            summary_rows.append({\n",
    "                'speaker_type': f'pragmatic_{label}',\n",
    "                'update_internal': update_internal,\n",
    "                'psi': psi,\n",
    "                'alpha': alpha,\n",
    "                'entropy': compute_entropy(P),\n",
    "                'top1_prob': np.max(P),\n",
    "                'top10_prob': np.sort(P)[-10:].sum()\n",
    "            })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "print(\"\\nLiteral speaker:\")\n",
    "print(summary_df[summary_df['speaker_type'] == 'literal'].to_string(index=False))\n",
    "\n",
    "print(\"\\nPragmatic speakers - entropy by alpha (selected alphas):\")\n",
    "selected_alphas = [1.0, 2.073, 5.482, 14.48, 38.28, 100.0]\n",
    "for psi in [\"inf\", \"pers+\", \"pers-\"]:\n",
    "    print(f\"\\n  psi='{psi}':\")\n",
    "    subset = summary_df[\n",
    "        (summary_df['psi'] == psi) & \n",
    "        (summary_df['alpha'].isin(selected_alphas))\n",
    "    ][['update_internal', 'alpha', 'entropy', 'top1_prob', 'top10_prob']]\n",
    "    print(subset.to_string(index=False))\n",
    "\n",
    "# =============================================================================\n",
    "# Step 9: Compare top sequences across speaker types\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 9: Top 10 sequences for each speaker type (alpha=5.48)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "alpha_demo = 5.482\n",
    "alpha_str = f\"{alpha_demo:.2f}\"\n",
    "\n",
    "print(\"\\n--- LITERAL ---\")\n",
    "top_literal = results_df.nlargest(10, 'literal')[['sequence', 'literal']]\n",
    "print(top_literal.to_string(index=False))\n",
    "\n",
    "for psi, short in [(\"inf\", \"inf\"), (\"pers+\", \"persp\"), (\"pers-\", \"persm\")]:\n",
    "    print(f\"\\n--- PRAGMATIC psi='{psi}' update_internal=False ---\")\n",
    "    col = f\"pragmatic_{short}_F_alpha={alpha_str}\"\n",
    "    print(results_df.nlargest(10, col)[['sequence', col]].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n--- PRAGMATIC psi='{psi}' update_internal=True ---\")\n",
    "    col = f\"pragmatic_{short}_T_alpha={alpha_str}\"\n",
    "    print(results_df.nlargest(10, col)[['sequence', col]].to_string(index=False))\n",
    "\n",
    "# =============================================================================\n",
    "# Step 10: Save results\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 10: Saving results\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa96da23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./sequence_probabilities.csv\n",
      "Saved: ./sequence_summary.csv\n",
      "Saved: ./sequence_log_probabilities.csv\n",
      "\n",
      "======================================================================\n",
      "COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save main results\n",
    "results_df.to_csv('./sequence_probabilities.csv', index=False)\n",
    "print(\"Saved: ./sequence_probabilities.csv\")\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('./sequence_summary.csv', index=False)\n",
    "print(\"Saved: ./sequence_summary.csv\")\n",
    "\n",
    "# Also save in a more compact format (log probabilities)\n",
    "log_results = {\n",
    "    'sequence': sequence_labels,\n",
    "    'sequence_idx': all_sequences,\n",
    "    'log_literal': log_P_seq_literal\n",
    "}\n",
    "\n",
    "for psi, short_name in [(\"inf\", \"inf\"), (\"pers+\", \"persp\"), (\"pers-\", \"persm\")]:\n",
    "    for alpha_idx, alpha in enumerate(alpha_values):\n",
    "        log_results[f\"log_pragmatic_{short_name}_F_alpha={alpha:.2f}\"] = log_P_seq_pragmatic_F[psi][:, alpha_idx]\n",
    "        log_results[f\"log_pragmatic_{short_name}_T_alpha={alpha:.2f}\"] = log_P_seq_pragmatic_T[psi][:, alpha_idx]\n",
    "\n",
    "log_results_df = pd.DataFrame(log_results)\n",
    "log_results_df.to_csv('./sequence_log_probabilities.csv', index=False)\n",
    "print(\"Saved: ./sequence_log_probabilities.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8061f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 1: Checking results_df structure\n",
      "======================================================================\n",
      "Total columns: 123\n",
      "\n",
      "Column names sample:\n",
      "['pragmatic_inf_T_alpha=1.00', 'pragmatic_inf_T_alpha=1.27', 'pragmatic_inf_T_alpha=1.63', 'pragmatic_inf_T_alpha=2.07', 'pragmatic_inf_T_alpha=2.64']\n",
      "\n",
      "======================================================================\n",
      "STEP 2: Analyzing rank stability across alpha values\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Results for each speaker type\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "Speaker type: inf_T\n",
      "============================================================\n",
      "\n",
      "Spearman correlation matrix (selected alphas):\n",
      "Alphas: [1.0, 2.643, 8.909, 30.02, 100.0]\n",
      "  α=  1.00: ['1.000', '0.969', '0.628', '-0.020', '-0.230']\n",
      "  α=  2.64: ['0.969', '1.000', '0.778', '0.184', '-0.029']\n",
      "  α=  8.91: ['0.628', '0.778', '1.000', '0.724', '0.553']\n",
      "  α= 30.02: ['-0.020', '0.184', '0.724', '1.000', '0.969']\n",
      "  α=100.00: ['-0.230', '-0.029', '0.553', '0.969', '1.000']\n",
      "\n",
      "Top-k stability:\n",
      "  k      Jaccard(consec)    Jaccard(1st-last)  Common to ALL  \n",
      "  1      0.421 (min:0.000)   0.000              0              \n",
      "  5      0.730 (min:0.000)   0.000              0              \n",
      "  10     0.847 (min:0.000)   0.000              0              \n",
      "  50     0.856 (min:0.250)   0.020              2              \n",
      "  100    0.830 (min:0.266)   0.010              2              \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=1.0:\n",
      "  Sequence index: 10922\n",
      "  Sequence: ('most,successful', 'some,unsuccessful', 'most,successful', 'some,unsuccessful', 'most,successful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#33, α=8.9→#23, α=30.0→#51, α=100.0→#1063, \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=100:\n",
      "  Sequence index: 10901\n",
      "  Sequence: ('most,successful', 'some,unsuccessful', 'most,successful', 'most,successful', 'some,unsuccessful')\n",
      "  Ranks across α: α=1.0→#11, α=2.6→#37, α=8.9→#21, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "============================================================\n",
      "Speaker type: inf_F\n",
      "============================================================\n",
      "\n",
      "Spearman correlation matrix (selected alphas):\n",
      "Alphas: [1.0, 2.643, 8.909, 30.02, 100.0]\n",
      "  α=  1.00: ['1.000', '0.967', '0.488', '-0.229', '-0.231']\n",
      "  α=  2.64: ['0.967', '1.000', '0.667', '-0.019', '-0.021']\n",
      "  α=  8.91: ['0.488', '0.667', '1.000', '0.685', '0.683']\n",
      "  α= 30.02: ['-0.229', '-0.019', '0.685', '1.000', '0.999']\n",
      "  α=100.00: ['-0.231', '-0.021', '0.683', '0.999', '1.000']\n",
      "\n",
      "Top-k stability:\n",
      "  k      Jaccard(consec)    Jaccard(1st-last)  Common to ALL  \n",
      "  1      0.737 (min:0.000)   1.000              0              \n",
      "  5      0.603 (min:0.250)   0.250              0              \n",
      "  10     0.768 (min:0.111)   0.111              0              \n",
      "  50     0.901 (min:0.136)   0.020              0              \n",
      "  100    0.938 (min:0.667)   0.333              50             \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=1.0:\n",
      "  Sequence index: 14043\n",
      "  Sequence: ('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#2, α=8.9→#1, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=100:\n",
      "  Sequence index: 14043\n",
      "  Sequence: ('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#2, α=8.9→#1, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "============================================================\n",
      "Speaker type: persp_T\n",
      "============================================================\n",
      "\n",
      "Spearman correlation matrix (selected alphas):\n",
      "Alphas: [1.0, 2.643, 8.909, 30.02, 100.0]\n",
      "  α=  1.00: ['1.000', '0.978', '0.721', '0.491', '0.408']\n",
      "  α=  2.64: ['0.978', '1.000', '0.840', '0.635', '0.556']\n",
      "  α=  8.91: ['0.721', '0.840', '1.000', '0.936', '0.888']\n",
      "  α= 30.02: ['0.491', '0.635', '0.936', '1.000', '0.991']\n",
      "  α=100.00: ['0.408', '0.556', '0.888', '0.991', '1.000']\n",
      "\n",
      "Top-k stability:\n",
      "  k      Jaccard(consec)    Jaccard(1st-last)  Common to ALL  \n",
      "  1      1.000 (min:1.000)   1.000              1              \n",
      "  5      0.799 (min:0.429)   0.250              1              \n",
      "  10     0.837 (min:0.538)   0.111              2              \n",
      "  50     0.926 (min:0.818)   0.316              19             \n",
      "  100    0.921 (min:0.835)   0.439              57             \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=1.0:\n",
      "  Sequence index: 23405\n",
      "  Sequence: ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#1, α=8.9→#1, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=100:\n",
      "  Sequence index: 23405\n",
      "  Sequence: ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#1, α=8.9→#1, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "============================================================\n",
      "Speaker type: persp_F\n",
      "============================================================\n",
      "\n",
      "Spearman correlation matrix (selected alphas):\n",
      "Alphas: [1.0, 2.643, 8.909, 30.02, 100.0]\n",
      "  α=  1.00: ['1.000', '0.969', '0.766', '0.628', '0.614']\n",
      "  α=  2.64: ['0.969', '1.000', '0.893', '0.783', '0.771']\n",
      "  α=  8.91: ['0.766', '0.893', '1.000', '0.972', '0.966']\n",
      "  α= 30.02: ['0.628', '0.783', '0.972', '1.000', '0.999']\n",
      "  α=100.00: ['0.614', '0.771', '0.966', '0.999', '1.000']\n",
      "\n",
      "Top-k stability:\n",
      "  k      Jaccard(consec)    Jaccard(1st-last)  Common to ALL  \n",
      "  1      1.000 (min:1.000)   1.000              1              \n",
      "  5      0.630 (min:0.250)   0.250              2              \n",
      "  10     0.831 (min:0.333)   0.111              2              \n",
      "  50     0.909 (min:0.724)   0.316              20             \n",
      "  100    0.951 (min:0.600)   0.408              58             \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=1.0:\n",
      "  Sequence index: 23405\n",
      "  Sequence: ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#1, α=8.9→#1, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=100:\n",
      "  Sequence index: 23405\n",
      "  Sequence: ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#1, α=8.9→#1, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "============================================================\n",
      "Speaker type: persm_T\n",
      "============================================================\n",
      "\n",
      "Spearman correlation matrix (selected alphas):\n",
      "Alphas: [1.0, 2.643, 8.909, 30.02, 100.0]\n",
      "  α=  1.00: ['1.000', '0.978', '0.721', '0.491', '0.408']\n",
      "  α=  2.64: ['0.978', '1.000', '0.840', '0.635', '0.556']\n",
      "  α=  8.91: ['0.721', '0.840', '1.000', '0.936', '0.888']\n",
      "  α= 30.02: ['0.491', '0.635', '0.936', '1.000', '0.991']\n",
      "  α=100.00: ['0.408', '0.556', '0.888', '0.991', '1.000']\n",
      "\n",
      "Top-k stability:\n",
      "  k      Jaccard(consec)    Jaccard(1st-last)  Common to ALL  \n",
      "  1      1.000 (min:1.000)   1.000              1              \n",
      "  5      0.799 (min:0.429)   0.250              1              \n",
      "  10     0.837 (min:0.538)   0.111              2              \n",
      "  50     0.926 (min:0.818)   0.316              19             \n",
      "  100    0.921 (min:0.835)   0.439              57             \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=1.0:\n",
      "  Sequence index: 18724\n",
      "  Sequence: ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#1, α=8.9→#1, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=100:\n",
      "  Sequence index: 18724\n",
      "  Sequence: ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#1, α=8.9→#1, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "============================================================\n",
      "Speaker type: persm_F\n",
      "============================================================\n",
      "\n",
      "Spearman correlation matrix (selected alphas):\n",
      "Alphas: [1.0, 2.643, 8.909, 30.02, 100.0]\n",
      "  α=  1.00: ['1.000', '0.969', '0.766', '0.628', '0.614']\n",
      "  α=  2.64: ['0.969', '1.000', '0.893', '0.783', '0.771']\n",
      "  α=  8.91: ['0.766', '0.893', '1.000', '0.972', '0.966']\n",
      "  α= 30.02: ['0.628', '0.783', '0.972', '1.000', '0.999']\n",
      "  α=100.00: ['0.614', '0.771', '0.966', '0.999', '1.000']\n",
      "\n",
      "Top-k stability:\n",
      "  k      Jaccard(consec)    Jaccard(1st-last)  Common to ALL  \n",
      "  1      1.000 (min:1.000)   1.000              1              \n",
      "  5      0.647 (min:0.250)   0.250              2              \n",
      "  10     0.765 (min:0.333)   0.111              2              \n",
      "  50     0.905 (min:0.724)   0.316              20             \n",
      "  100    0.913 (min:0.600)   0.408              58             \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=1.0:\n",
      "  Sequence index: 18724\n",
      "  Sequence: ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#1, α=8.9→#1, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "Rank trajectory of top-1 sequence at α=100:\n",
      "  Sequence index: 18724\n",
      "  Sequence: ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "  Ranks across α: α=1.0→#1, α=2.6→#1, α=8.9→#1, α=30.0→#1, α=100.0→#1, \n",
      "\n",
      "======================================================================\n",
      "STEP 4: Summary comparison across speaker types\n",
      "======================================================================\n",
      "\n",
      "Rank stability summary:\n",
      "speaker_type  spearman_1_vs_100  spearman_1_vs_10  spearman_10_vs_100  top1_stable  top5_common_all  top10_common_all  top50_common_all  top100_jaccard_1_100\n",
      "       inf_T          -0.229839          0.628097            0.552977        False                0                 0                 2              0.010101\n",
      "       inf_F          -0.231357          0.488386            0.682790         True                0                 0                 0              0.333333\n",
      "     persp_T           0.408022          0.720715            0.887959         True                1                 2                19              0.438849\n",
      "     persp_F           0.614203          0.765711            0.966419         True                2                 2                20              0.408451\n",
      "     persm_T           0.408022          0.720715            0.887959         True                1                 2                19              0.438849\n",
      "     persm_F           0.614201          0.765709            0.966413         True                2                 2                20              0.408451\n",
      "\n",
      "======================================================================\n",
      "STEP 5: Which sequences are consistently top-ranked?\n",
      "======================================================================\n",
      "\n",
      "inf_T:\n",
      "  Number of sequences that are #1 for at least one alpha: 6\n",
      "  Top sequences by #1 count:\n",
      "    ('most,successful', 'some,unsuccessful', 'most,successful', 'most,successful', 'some,unsuccessful'): #1 for 7/20 alphas\n",
      "    ('most,successful', 'most,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,successful'): #1 for 5/20 alphas\n",
      "    ('most,successful', 'most,unsuccessful', 'most,successful', 'most,successful', 'most,successful'): #1 for 3/20 alphas\n",
      "    ('most,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful'): #1 for 2/20 alphas\n",
      "    ('most,successful', 'some,unsuccessful', 'most,successful', 'some,unsuccessful', 'most,successful'): #1 for 2/20 alphas\n",
      "\n",
      "inf_F:\n",
      "  Number of sequences that are #1 for at least one alpha: 3\n",
      "  These sequences:\n",
      "    ('all,successful', 'all,successful', 'all,successful', 'all,successful', 'all,successful'): #1 for 2/20 alphas\n",
      "    ('most,successful', 'most,successful', 'most,successful', 'most,successful', 'most,successful'): #1 for 10/20 alphas\n",
      "    ('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful'): #1 for 8/20 alphas\n",
      "\n",
      "persp_T:\n",
      "  Number of sequences that are #1 for at least one alpha: 1\n",
      "  These sequences:\n",
      "    ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful'): #1 for 20/20 alphas\n",
      "\n",
      "persp_F:\n",
      "  Number of sequences that are #1 for at least one alpha: 1\n",
      "  These sequences:\n",
      "    ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful'): #1 for 20/20 alphas\n",
      "\n",
      "persm_T:\n",
      "  Number of sequences that are #1 for at least one alpha: 1\n",
      "  These sequences:\n",
      "    ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful'): #1 for 20/20 alphas\n",
      "\n",
      "persm_F:\n",
      "  Number of sequences that are #1 for at least one alpha: 1\n",
      "  These sequences:\n",
      "    ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful'): #1 for 20/20 alphas\n",
      "\n",
      "======================================================================\n",
      "STEP 6: Detailed rank change analysis for inf_T\n",
      "======================================================================\n",
      "\n",
      "Most volatile sequences (largest rank range across alphas):\n",
      "Sequence                                                     Min Rank   Max Rank   Range     \n",
      "('some,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,successful') 97         32768      32671     \n",
      "('some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful') 93         32763      32670     \n",
      "('some,unsuccessful', 'some,successful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful') 98         32768      32670     \n",
      "('some,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful') 94         32763      32669     \n",
      "('some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,successful') 96         32764      32668     \n",
      "('some,unsuccessful', 'some,successful', 'some,successful', 'some,unsuccessful', 'some,successful') 102        32768      32666     \n",
      "('some,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful') 95         32761      32666     \n",
      "('some,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful') 101        32765      32664     \n",
      "('some,successful', 'some,unsuccessful', 'some,successful', 'some,successful', 'some,unsuccessful') 99         32754      32655     \n",
      "('some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful') 100        32754      32654     \n",
      "\n",
      "Most stable sequences (among those in top-100 for any alpha):\n",
      "Sequence                                                     Min Rank   Max Rank   Range     \n",
      "('most,successful', 'some,unsuccessful', 'most,successful', 'most,successful', 'some,unsuccessful') 1          37         36        \n",
      "('most,unsuccessful', 'some,successful', 'most,unsuccessful', 'most,unsuccessful', 'some,successful') 1          38         37        \n",
      "('most,successful', 'some,unsuccessful', 'most,successful', 'most,successful', 'most,successful') 12         118        106       \n",
      "('most,unsuccessful', 'some,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful') 11         117        106       \n",
      "('most,unsuccessful', 'some,successful', 'most,successful', 'most,unsuccessful', 'most,unsuccessful') 5          411        406       \n",
      "('most,successful', 'some,unsuccessful', 'most,unsuccessful', 'most,successful', 'most,successful') 5          412        407       \n",
      "('most,unsuccessful', 'some,successful', 'most,unsuccessful', 'most,successful', 'most,unsuccessful') 10         548        538       \n",
      "('most,successful', 'some,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,successful') 9          547        538       \n",
      "('most,successful', 'most,unsuccessful', 'most,successful', 'most,successful', 'most,successful') 1          643        642       \n",
      "('most,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful') 1          644        643       \n",
      "\n",
      "======================================================================\n",
      "STEP 7: Comparing update_internal=T vs F stability\n",
      "======================================================================\n",
      "\n",
      "inf:\n",
      "  Spearman(α=1 vs α=100): T=-0.230, F=-0.231\n",
      "  Top-10 Jaccard(α=1 vs α=100): T=0.000, F=0.111\n",
      "  Top-1 at α=100: T=('most,successful', 'some,unsuccessful', 'most,successful', 'most,successful', 'some,unsuccessful'), F=('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "  Same? False\n",
      "\n",
      "persp:\n",
      "  Spearman(α=1 vs α=100): T=0.408, F=0.614\n",
      "  Top-10 Jaccard(α=1 vs α=100): T=0.111, F=0.111\n",
      "  Top-1 at α=100: T=('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful'), F=('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "  Same? True\n",
      "\n",
      "persm:\n",
      "  Spearman(α=1 vs α=100): T=0.408, F=0.614\n",
      "  Top-10 Jaccard(α=1 vs α=100): T=0.111, F=0.111\n",
      "  Top-1 at α=100: T=('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful'), F=('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "  Same? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "import itertools\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Assuming we have results_df from earlier computation\n",
    "# Let's first check its structure\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: Checking results_df structure\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# List all columns\n",
    "print(f\"Total columns: {len(results_df.columns)}\")\n",
    "print(f\"\\nColumn names sample:\")\n",
    "print([c for c in results_df.columns if 'inf_T' in c][:5])\n",
    "\n",
    "# Extract alpha values from column names\n",
    "alpha_values = [1.000, 1.275, 1.626, 2.073, 2.643, 3.371, 4.299, 5.482, \n",
    "                6.988, 8.909, 11.36, 14.48, 18.46, 23.54, 30.02, 38.28, \n",
    "                48.80, 62.23, 79.32, 100.0]\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Define function to analyze rank stability\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: Analyzing rank stability across alpha values\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def analyze_rank_stability(results_df, speaker_type, alpha_values):\n",
    "    \"\"\"\n",
    "    Analyze how stable the ranking of sequences is across different alpha values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame with sequence probabilities\n",
    "    speaker_type : str\n",
    "        e.g., 'inf_T', 'inf_F', 'persp_T', etc.\n",
    "    alpha_values : list\n",
    "        List of alpha values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict with stability metrics\n",
    "    \"\"\"\n",
    "    # Get columns for this speaker type\n",
    "    cols = [f\"pragmatic_{speaker_type}_alpha={a:.2f}\" for a in alpha_values]\n",
    "    \n",
    "    # Check all columns exist\n",
    "    missing = [c for c in cols if c not in results_df.columns]\n",
    "    if missing:\n",
    "        print(f\"Warning: Missing columns: {missing[:3]}...\")\n",
    "        # Try alternative format\n",
    "        cols = [f\"pragmatic_{speaker_type}_alpha={a}\" for a in alpha_values]\n",
    "    \n",
    "    # Extract probability matrix: (n_sequences, n_alphas)\n",
    "    prob_matrix = results_df[cols].values\n",
    "    \n",
    "    # Compute ranks for each alpha (rank 1 = highest probability)\n",
    "    rank_matrix = np.zeros_like(prob_matrix)\n",
    "    for j in range(len(alpha_values)):\n",
    "        rank_matrix[:, j] = (-prob_matrix[:, j]).argsort().argsort() + 1\n",
    "    \n",
    "    # Spearman correlation between all pairs of alphas\n",
    "    n_alphas = len(alpha_values)\n",
    "    spearman_corr = np.zeros((n_alphas, n_alphas))\n",
    "    for i in range(n_alphas):\n",
    "        for j in range(n_alphas):\n",
    "            spearman_corr[i, j], _ = spearmanr(rank_matrix[:, i], rank_matrix[:, j])\n",
    "    \n",
    "    # Track the top-k sequences for each alpha\n",
    "    top_k_values = [1, 5, 10, 50, 100]\n",
    "    top_k_stability = {}\n",
    "    \n",
    "    for k in top_k_values:\n",
    "        # For each alpha, get the top-k sequence indices\n",
    "        top_k_sets = []\n",
    "        for j in range(n_alphas):\n",
    "            top_k_idx = np.argsort(-prob_matrix[:, j])[:k]\n",
    "            top_k_sets.append(set(top_k_idx))\n",
    "        \n",
    "        # Compute Jaccard similarity between consecutive alphas\n",
    "        jaccard_consecutive = []\n",
    "        for j in range(n_alphas - 1):\n",
    "            intersection = len(top_k_sets[j] & top_k_sets[j+1])\n",
    "            union = len(top_k_sets[j] | top_k_sets[j+1])\n",
    "            jaccard_consecutive.append(intersection / union if union > 0 else 0)\n",
    "        \n",
    "        # Compute Jaccard between first and last alpha\n",
    "        jaccard_first_last = len(top_k_sets[0] & top_k_sets[-1]) / len(top_k_sets[0] | top_k_sets[-1])\n",
    "        \n",
    "        # How many sequences are in top-k for ALL alphas?\n",
    "        common_all = set.intersection(*top_k_sets)\n",
    "        \n",
    "        top_k_stability[k] = {\n",
    "            'jaccard_consecutive_mean': np.mean(jaccard_consecutive),\n",
    "            'jaccard_consecutive_min': np.min(jaccard_consecutive),\n",
    "            'jaccard_first_last': jaccard_first_last,\n",
    "            'common_all_count': len(common_all),\n",
    "            'common_all_sequences': common_all\n",
    "        }\n",
    "    \n",
    "    # Track rank of the #1 sequence (at alpha_min) across all alphas\n",
    "    top1_at_alpha_min = np.argmax(prob_matrix[:, 0])\n",
    "    top1_ranks_across_alpha = rank_matrix[top1_at_alpha_min, :]\n",
    "    \n",
    "    # Track rank of the #1 sequence (at alpha_max) across all alphas\n",
    "    top1_at_alpha_max = np.argmax(prob_matrix[:, -1])\n",
    "    top1_max_ranks_across_alpha = rank_matrix[top1_at_alpha_max, :]\n",
    "    \n",
    "    return {\n",
    "        'spearman_corr': spearman_corr,\n",
    "        'top_k_stability': top_k_stability,\n",
    "        'top1_at_alpha_min_idx': top1_at_alpha_min,\n",
    "        'top1_at_alpha_min_ranks': top1_ranks_across_alpha,\n",
    "        'top1_at_alpha_max_idx': top1_at_alpha_max,\n",
    "        'top1_at_alpha_max_ranks': top1_max_ranks_across_alpha,\n",
    "        'prob_matrix': prob_matrix,\n",
    "        'rank_matrix': rank_matrix\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3: Analyze each speaker type\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: Results for each speaker type\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "speaker_types = ['inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for speaker_type in speaker_types:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Speaker type: {speaker_type}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = analyze_rank_stability(results_df, speaker_type, alpha_values)\n",
    "    all_results[speaker_type] = results\n",
    "    \n",
    "    # Print Spearman correlation summary\n",
    "    spearman = results['spearman_corr']\n",
    "    print(f\"\\nSpearman correlation matrix (selected alphas):\")\n",
    "    selected_idx = [0, 4, 9, 14, 19]  # alpha = 1, 2.64, 8.91, 30.0, 100\n",
    "    selected_alphas = [alpha_values[i] for i in selected_idx]\n",
    "    print(f\"Alphas: {selected_alphas}\")\n",
    "    for i in selected_idx:\n",
    "        row = [f\"{spearman[i, j]:.3f}\" for j in selected_idx]\n",
    "        print(f\"  α={alpha_values[i]:>6.2f}: {row}\")\n",
    "    \n",
    "    # Print top-k stability\n",
    "    print(f\"\\nTop-k stability:\")\n",
    "    print(f\"  {'k':<6} {'Jaccard(consec)':<18} {'Jaccard(1st-last)':<18} {'Common to ALL':<15}\")\n",
    "    for k in [1, 5, 10, 50, 100]:\n",
    "        stats = results['top_k_stability'][k]\n",
    "        print(f\"  {k:<6} {stats['jaccard_consecutive_mean']:.3f} (min:{stats['jaccard_consecutive_min']:.3f})   \"\n",
    "              f\"{stats['jaccard_first_last']:.3f}              {stats['common_all_count']:<15}\")\n",
    "    \n",
    "    # Print rank trajectory of top sequence\n",
    "    print(f\"\\nRank trajectory of top-1 sequence at α=1.0:\")\n",
    "    print(f\"  Sequence index: {results['top1_at_alpha_min_idx']}\")\n",
    "    print(f\"  Sequence: {results_df.loc[results['top1_at_alpha_min_idx'], 'sequence']}\")\n",
    "    print(f\"  Ranks across α: \", end=\"\")\n",
    "    for i in [0, 4, 9, 14, 19]:\n",
    "        print(f\"α={alpha_values[i]:.1f}→#{int(results['top1_at_alpha_min_ranks'][i])}, \", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"\\nRank trajectory of top-1 sequence at α=100:\")\n",
    "    print(f\"  Sequence index: {results['top1_at_alpha_max_idx']}\")\n",
    "    print(f\"  Sequence: {results_df.loc[results['top1_at_alpha_max_idx'], 'sequence']}\")\n",
    "    print(f\"  Ranks across α: \", end=\"\")\n",
    "    for i in [0, 4, 9, 14, 19]:\n",
    "        print(f\"α={alpha_values[i]:.1f}→#{int(results['top1_at_alpha_max_ranks'][i])}, \", end=\"\")\n",
    "    print()\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4: Visualize rank stability with a summary table\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: Summary comparison across speaker types\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary_rows = []\n",
    "for speaker_type in speaker_types:\n",
    "    results = all_results[speaker_type]\n",
    "    spearman = results['spearman_corr']\n",
    "    \n",
    "    summary_rows.append({\n",
    "        'speaker_type': speaker_type,\n",
    "        'spearman_1_vs_100': spearman[0, -1],\n",
    "        'spearman_1_vs_10': spearman[0, 9],  # alpha ~8.9\n",
    "        'spearman_10_vs_100': spearman[9, -1],\n",
    "        'top1_stable': results['top1_at_alpha_min_idx'] == results['top1_at_alpha_max_idx'],\n",
    "        'top5_common_all': results['top_k_stability'][5]['common_all_count'],\n",
    "        'top10_common_all': results['top_k_stability'][10]['common_all_count'],\n",
    "        'top50_common_all': results['top_k_stability'][50]['common_all_count'],\n",
    "        'top100_jaccard_1_100': results['top_k_stability'][100]['jaccard_first_last'],\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "print(\"\\nRank stability summary:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5: Check if same sequence is top-1 across all alphas\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: Which sequences are consistently top-ranked?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for speaker_type in speaker_types:\n",
    "    results = all_results[speaker_type]\n",
    "    prob_matrix = results['prob_matrix']\n",
    "    \n",
    "    # Find sequence that is #1 most often\n",
    "    top1_counts = np.zeros(prob_matrix.shape[0])\n",
    "    for j in range(len(alpha_values)):\n",
    "        top1_idx = np.argmax(prob_matrix[:, j])\n",
    "        top1_counts[top1_idx] += 1\n",
    "    \n",
    "    # Get sequences that are ever #1\n",
    "    ever_top1 = np.where(top1_counts > 0)[0]\n",
    "    \n",
    "    print(f\"\\n{speaker_type}:\")\n",
    "    print(f\"  Number of sequences that are #1 for at least one alpha: {len(ever_top1)}\")\n",
    "    \n",
    "    if len(ever_top1) <= 5:\n",
    "        print(f\"  These sequences:\")\n",
    "        for idx in ever_top1:\n",
    "            seq = results_df.loc[idx, 'sequence']\n",
    "            count = int(top1_counts[idx])\n",
    "            print(f\"    {seq}: #1 for {count}/{len(alpha_values)} alphas\")\n",
    "    else:\n",
    "        print(f\"  Top sequences by #1 count:\")\n",
    "        for idx in np.argsort(-top1_counts)[:5]:\n",
    "            if top1_counts[idx] > 0:\n",
    "                seq = results_df.loc[idx, 'sequence']\n",
    "                count = int(top1_counts[idx])\n",
    "                print(f\"    {seq}: #1 for {count}/{len(alpha_values)} alphas\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 6: Detailed look at rank changes\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: Detailed rank change analysis for inf_T\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = all_results['inf_T']\n",
    "prob_matrix = results['prob_matrix']\n",
    "rank_matrix = results['rank_matrix']\n",
    "\n",
    "# Find sequences with biggest rank changes\n",
    "rank_range = np.max(rank_matrix, axis=1) - np.min(rank_matrix, axis=1)\n",
    "most_volatile = np.argsort(-rank_range)[:10]\n",
    "\n",
    "print(\"\\nMost volatile sequences (largest rank range across alphas):\")\n",
    "print(f\"{'Sequence':<60} {'Min Rank':<10} {'Max Rank':<10} {'Range':<10}\")\n",
    "for idx in most_volatile:\n",
    "    seq = results_df.loc[idx, 'sequence']\n",
    "    min_rank = int(np.min(rank_matrix[idx, :]))\n",
    "    max_rank = int(np.max(rank_matrix[idx, :]))\n",
    "    rng = int(rank_range[idx])\n",
    "    print(f\"{str(seq):<60} {min_rank:<10} {max_rank:<10} {rng:<10}\")\n",
    "\n",
    "# Find most stable sequences (among top 100 at any alpha)\n",
    "top100_any = set()\n",
    "for j in range(len(alpha_values)):\n",
    "    top100_any.update(np.argsort(-prob_matrix[:, j])[:100])\n",
    "\n",
    "top100_list = list(top100_any)\n",
    "rank_range_top100 = rank_range[top100_list]\n",
    "most_stable_top100 = [top100_list[i] for i in np.argsort(rank_range_top100)[:10]]\n",
    "\n",
    "print(\"\\nMost stable sequences (among those in top-100 for any alpha):\")\n",
    "print(f\"{'Sequence':<60} {'Min Rank':<10} {'Max Rank':<10} {'Range':<10}\")\n",
    "for idx in most_stable_top100:\n",
    "    seq = results_df.loc[idx, 'sequence']\n",
    "    min_rank = int(np.min(rank_matrix[idx, :]))\n",
    "    max_rank = int(np.max(rank_matrix[idx, :]))\n",
    "    rng = int(rank_range[idx])\n",
    "    print(f\"{str(seq):<60} {min_rank:<10} {max_rank:<10} {rng:<10}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 7: Compare rank stability between T and F versions\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 7: Comparing update_internal=T vs F stability\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for psi in ['inf', 'persp', 'persm']:\n",
    "    type_T = f'{psi}_T'\n",
    "    type_F = f'{psi}_F'\n",
    "    \n",
    "    spearman_T = all_results[type_T]['spearman_corr'][0, -1]\n",
    "    spearman_F = all_results[type_F]['spearman_corr'][0, -1]\n",
    "    \n",
    "    top10_T = all_results[type_T]['top_k_stability'][10]['jaccard_first_last']\n",
    "    top10_F = all_results[type_F]['top_k_stability'][10]['jaccard_first_last']\n",
    "    \n",
    "    print(f\"\\n{psi}:\")\n",
    "    print(f\"  Spearman(α=1 vs α=100): T={spearman_T:.3f}, F={spearman_F:.3f}\")\n",
    "    print(f\"  Top-10 Jaccard(α=1 vs α=100): T={top10_T:.3f}, F={top10_F:.3f}\")\n",
    "    \n",
    "    # Are the top sequences the same between T and F?\n",
    "    top1_T = all_results[type_T]['top1_at_alpha_max_idx']\n",
    "    top1_F = all_results[type_F]['top1_at_alpha_max_idx']\n",
    "    seq_T = results_df.loc[top1_T, 'sequence']\n",
    "    seq_F = results_df.loc[top1_F, 'sequence']\n",
    "    print(f\"  Top-1 at α=100: T={seq_T}, F={seq_F}\")\n",
    "    print(f\"  Same? {seq_T == seq_F}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6838bda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Analyzing stability around α ≈ 8.9\n",
      "======================================================================\n",
      "Mid-range alphas: [5.482, 6.988, 8.909, 11.36, 14.48]\n",
      "\n",
      "--- inf_T ---\n",
      "  k=1: 0 sequences in top-1 for ALL mid-range alphas\n",
      "  k=5: 4 sequences in top-5 for ALL mid-range alphas\n",
      "    ('most,successful', 'most,unsuccessful', 'most,successful', 'most,successful', 'most,successful')\n",
      "      Ranks: {5.482: 2, 6.988: 2, 8.909: 1, 11.36: 2, 14.48: 1}\n",
      "    ('most,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "      Ranks: {5.482: 1, 6.988: 1, 8.909: 2, 11.36: 1, 14.48: 2}\n",
      "    ('most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "      Ranks: {5.482: 4, 6.988: 4, 8.909: 3, 11.36: 4, 14.48: 4}\n",
      "    ('most,unsuccessful', 'most,successful', 'most,successful', 'most,successful', 'most,successful')\n",
      "      Ranks: {5.482: 3, 6.988: 3, 8.909: 4, 11.36: 3, 14.48: 3}\n",
      "  k=10: 4 sequences in top-10 for ALL mid-range alphas\n",
      "    ('most,successful', 'most,unsuccessful', 'most,successful', 'most,successful', 'most,successful')\n",
      "      Ranks: {5.482: 2, 6.988: 2, 8.909: 1, 11.36: 2, 14.48: 1}\n",
      "    ('most,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "      Ranks: {5.482: 1, 6.988: 1, 8.909: 2, 11.36: 1, 14.48: 2}\n",
      "    ('most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "      Ranks: {5.482: 4, 6.988: 4, 8.909: 3, 11.36: 4, 14.48: 4}\n",
      "    ('most,unsuccessful', 'most,successful', 'most,successful', 'most,successful', 'most,successful')\n",
      "      Ranks: {5.482: 3, 6.988: 3, 8.909: 4, 11.36: 3, 14.48: 3}\n",
      "  k=20: 16 sequences in top-20 for ALL mid-range alphas\n",
      "  k=50: 42 sequences in top-50 for ALL mid-range alphas\n",
      "\n",
      "--- inf_F ---\n",
      "  k=1: 0 sequences in top-1 for ALL mid-range alphas\n",
      "  k=5: 2 sequences in top-5 for ALL mid-range alphas\n",
      "    ('most,successful', 'most,successful', 'most,successful', 'most,successful', 'most,successful')\n",
      "      Ranks: {5.482: 2, 6.988: 2, 8.909: 2, 11.36: 1, 14.48: 2}\n",
      "    ('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "      Ranks: {5.482: 1, 6.988: 1, 8.909: 1, 11.36: 2, 14.48: 1}\n",
      "  k=10: 5 sequences in top-10 for ALL mid-range alphas\n",
      "    ('most,unsuccessful', 'most,successful', 'most,successful', 'most,successful', 'most,successful')\n",
      "      Ranks: {5.482: 6, 6.988: 6, 8.909: 6, 11.36: 6, 14.48: 4}\n",
      "    ('most,successful', 'most,successful', 'most,successful', 'most,successful', 'most,successful')\n",
      "      Ranks: {5.482: 2, 6.988: 2, 8.909: 2, 11.36: 1, 14.48: 2}\n",
      "    ('most,successful', 'most,unsuccessful', 'most,successful', 'most,successful', 'most,successful')\n",
      "      Ranks: {5.482: 7, 6.988: 8, 8.909: 5, 11.36: 8, 14.48: 5}\n",
      "    ('most,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "      Ranks: {5.482: 9, 6.988: 5, 8.909: 10, 11.36: 5, 14.48: 8}\n",
      "    ('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "      Ranks: {5.482: 1, 6.988: 1, 8.909: 1, 11.36: 2, 14.48: 1}\n",
      "  k=20: 13 sequences in top-20 for ALL mid-range alphas\n",
      "  k=50: 47 sequences in top-50 for ALL mid-range alphas\n",
      "\n",
      "--- persp_T ---\n",
      "  k=1: 1 sequences in top-1 for ALL mid-range alphas\n",
      "    ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "      Ranks: {5.482: 1, 6.988: 1, 8.909: 1, 11.36: 1, 14.48: 1}\n",
      "  k=5: 2 sequences in top-5 for ALL mid-range alphas\n",
      "    ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "      Ranks: {5.482: 4, 6.988: 3, 8.909: 2, 11.36: 2, 14.48: 2}\n",
      "    ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "      Ranks: {5.482: 1, 6.988: 1, 8.909: 1, 11.36: 1, 14.48: 1}\n",
      "  k=10: 7 sequences in top-10 for ALL mid-range alphas\n",
      "    ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "      Ranks: {5.482: 4, 6.988: 3, 8.909: 2, 11.36: 2, 14.48: 2}\n",
      "    ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,unsuccessful')\n",
      "      Ranks: {5.482: 7, 6.988: 6, 8.909: 3, 11.36: 3, 14.48: 3}\n",
      "    ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "      Ranks: {5.482: 1, 6.988: 1, 8.909: 1, 11.36: 1, 14.48: 1}\n",
      "    ('some,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "      Ranks: {5.482: 5, 6.988: 4, 8.909: 4, 11.36: 4, 14.48: 6}\n",
      "    ('some,successful', 'some,successful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "      Ranks: {5.482: 9, 6.988: 7, 8.909: 6, 11.36: 5, 14.48: 7}\n",
      "  k=20: 13 sequences in top-20 for ALL mid-range alphas\n",
      "  k=50: 36 sequences in top-50 for ALL mid-range alphas\n",
      "\n",
      "--- persm_T ---\n",
      "  k=1: 1 sequences in top-1 for ALL mid-range alphas\n",
      "    ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "      Ranks: {5.482: 1, 6.988: 1, 8.909: 1, 11.36: 1, 14.48: 1}\n",
      "  k=5: 2 sequences in top-5 for ALL mid-range alphas\n",
      "    ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "      Ranks: {5.482: 1, 6.988: 1, 8.909: 1, 11.36: 1, 14.48: 1}\n",
      "    ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "      Ranks: {5.482: 4, 6.988: 3, 8.909: 2, 11.36: 2, 14.48: 2}\n",
      "  k=10: 7 sequences in top-10 for ALL mid-range alphas\n",
      "    ('some,successful', 'some,unsuccessful', 'some,successful', 'some,successful', 'some,successful')\n",
      "      Ranks: {5.482: 10, 6.988: 10, 8.909: 9, 11.36: 8, 14.48: 9}\n",
      "    ('some,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,successful', 'some,successful')\n",
      "      Ranks: {5.482: 8, 6.988: 8, 8.909: 7, 11.36: 7, 14.48: 10}\n",
      "    ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,successful')\n",
      "      Ranks: {5.482: 9, 6.988: 7, 8.909: 6, 11.36: 5, 14.48: 7}\n",
      "    ('some,unsuccessful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "      Ranks: {5.482: 5, 6.988: 4, 8.909: 4, 11.36: 4, 14.48: 6}\n",
      "    ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "      Ranks: {5.482: 1, 6.988: 1, 8.909: 1, 11.36: 1, 14.48: 1}\n",
      "  k=20: 13 sequences in top-20 for ALL mid-range alphas\n",
      "  k=50: 36 sequences in top-50 for ALL mid-range alphas\n",
      "\n",
      "======================================================================\n",
      "Most stable sequences in α ∈ [5.5, 14.5] for inf_T\n",
      "======================================================================\n",
      "Sequences in top-100 for any mid-range alpha: 142\n",
      "\n",
      "Top 20 most stable sequences (smallest rank range in mid-range alphas):\n",
      "Sequence                                                               Min    Max    Range \n",
      "('most,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful') 1      2      1     \n",
      "('most,successful', 'most,unsuccessful', 'most,successful', 'most,successful', 'most,successful') 1      2      1     \n",
      "('most,unsuccessful', 'most,successful', 'most,successful', 'most,successful', 'most,successful') 3      4      1     \n",
      "('most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful') 3      4      1     \n",
      "('most,unsuccessful', 'all,unsuccessful', 'some,successful', 'some,successful', 'some,successful') 38     39     1     \n",
      "('most,successful', 'some,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,unsuccessful') 33     35     2     \n",
      "('most,unsuccessful', 'some,successful', 'most,unsuccessful', 'most,successful', 'most,successful') 34     36     2     \n",
      "('most,successful', 'all,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful') 40     42     2     \n",
      "('most,unsuccessful', 'no,successful', 'some,successful', 'some,successful', 'some,successful') 37     40     3     \n",
      "('most,successful', 'no,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful') 39     42     3     \n",
      "('most,successful', 'some,unsuccessful', 'most,successful', 'some,unsuccessful', 'most,successful') 23     27     4     \n",
      "('most,unsuccessful', 'some,successful', 'most,unsuccessful', 'some,successful', 'most,unsuccessful') 24     28     4     \n",
      "('most,successful', 'some,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful') 29     33     4     \n",
      "('most,unsuccessful', 'some,successful', 'most,successful', 'most,successful', 'most,successful') 30     34     4     \n",
      "('most,unsuccessful', 'most,unsuccessful', 'some,successful', 'most,unsuccessful', 'some,successful') 45     49     4     \n",
      "('most,successful', 'most,successful', 'some,unsuccessful', 'most,successful', 'some,unsuccessful') 46     50     4     \n",
      "('most,successful', 'some,unsuccessful', 'most,successful', 'some,unsuccessful', 'most,unsuccessful') 59     63     4     \n",
      "('most,unsuccessful', 'some,successful', 'most,unsuccessful', 'some,successful', 'most,successful') 60     64     4     \n",
      "('most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,successful', 'most,successful') 8      13     5     \n",
      "('most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,successful', 'most,unsuccessful') 10     17     7     \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Analyze stability around α ≈ 8.9\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Analyzing stability around α ≈ 8.9\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find indices for alphas in the range 5-15 (neighborhood of 8.9)\n",
    "alpha_values = [1.000, 1.275, 1.626, 2.073, 2.643, 3.371, 4.299, 5.482, \n",
    "                6.988, 8.909, 11.36, 14.48, 18.46, 23.54, 30.02, 38.28, \n",
    "                48.80, 62.23, 79.32, 100.0]\n",
    "\n",
    "# Indices for α ∈ [5, 15]: indices 7, 8, 9, 10, 11 → alphas 5.48, 6.99, 8.91, 11.36, 14.48\n",
    "mid_range_indices = [7, 8, 9, 10, 11]\n",
    "mid_range_alphas = [alpha_values[i] for i in mid_range_indices]\n",
    "print(f\"Mid-range alphas: {mid_range_alphas}\")\n",
    "\n",
    "for speaker_type in ['inf_T', 'inf_F', 'persp_T', 'persm_T']:\n",
    "    print(f\"\\n--- {speaker_type} ---\")\n",
    "    \n",
    "    # Get columns for this speaker type\n",
    "    cols = [f\"pragmatic_{speaker_type}_alpha={alpha_values[i]:.2f}\" for i in mid_range_indices]\n",
    "    prob_matrix = results_df[cols].values\n",
    "    \n",
    "    # Compute ranks\n",
    "    rank_matrix = np.zeros_like(prob_matrix)\n",
    "    for j in range(len(mid_range_indices)):\n",
    "        rank_matrix[:, j] = (-prob_matrix[:, j]).argsort().argsort() + 1\n",
    "    \n",
    "    # Find sequences in top-k for ALL mid-range alphas\n",
    "    for k in [1, 5, 10, 20, 50]:\n",
    "        top_k_sets = []\n",
    "        for j in range(len(mid_range_indices)):\n",
    "            top_k_idx = set(np.argsort(-prob_matrix[:, j])[:k])\n",
    "            top_k_sets.append(top_k_idx)\n",
    "        \n",
    "        common = set.intersection(*top_k_sets)\n",
    "        \n",
    "        print(f\"  k={k}: {len(common)} sequences in top-{k} for ALL mid-range alphas\")\n",
    "        \n",
    "        if k <= 10 and len(common) > 0:\n",
    "            for idx in list(common)[:5]:  # Show up to 5\n",
    "                seq = results_df.loc[idx, 'sequence']\n",
    "                ranks = [int(rank_matrix[idx, j]) for j in range(len(mid_range_indices))]\n",
    "                print(f\"    {seq}\")\n",
    "                print(f\"      Ranks: {dict(zip(mid_range_alphas, ranks))}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Find the MOST stable sequences in the mid-range\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Most stable sequences in α ∈ [5.5, 14.5] for inf_T\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cols = [f\"pragmatic_inf_T_alpha={alpha_values[i]:.2f}\" for i in mid_range_indices]\n",
    "prob_matrix = results_df[cols].values\n",
    "\n",
    "# Compute rank range (max - min) across mid-range alphas only\n",
    "rank_matrix = np.zeros_like(prob_matrix)\n",
    "for j in range(len(mid_range_indices)):\n",
    "    rank_matrix[:, j] = (-prob_matrix[:, j]).argsort().argsort() + 1\n",
    "\n",
    "rank_range_mid = np.max(rank_matrix, axis=1) - np.min(rank_matrix, axis=1)\n",
    "min_rank_mid = np.min(rank_matrix, axis=1)\n",
    "\n",
    "# Find sequences that are: (1) in top-100 for at least one mid-range alpha, (2) have small rank range\n",
    "top100_any_mid = set()\n",
    "for j in range(len(mid_range_indices)):\n",
    "    top100_any_mid.update(np.argsort(-prob_matrix[:, j])[:100])\n",
    "\n",
    "top100_list = list(top100_any_mid)\n",
    "print(f\"Sequences in top-100 for any mid-range alpha: {len(top100_list)}\")\n",
    "\n",
    "# Sort by rank range (most stable first)\n",
    "stability_data = []\n",
    "for idx in top100_list:\n",
    "    stability_data.append({\n",
    "        'idx': idx,\n",
    "        'sequence': results_df.loc[idx, 'sequence'],\n",
    "        'min_rank': int(np.min(rank_matrix[idx, :])),\n",
    "        'max_rank': int(np.max(rank_matrix[idx, :])),\n",
    "        'rank_range': int(rank_range_mid[idx]),\n",
    "        'mean_rank': np.mean(rank_matrix[idx, :])\n",
    "    })\n",
    "\n",
    "stability_df = pd.DataFrame(stability_data)\n",
    "stability_df = stability_df.sort_values(['rank_range', 'mean_rank'])\n",
    "\n",
    "print(\"\\nTop 20 most stable sequences (smallest rank range in mid-range alphas):\")\n",
    "print(f\"{'Sequence':<70} {'Min':<6} {'Max':<6} {'Range':<6}\")\n",
    "for _, row in stability_df.head(20).iterrows():\n",
    "    print(f\"{str(row['sequence']):<70} {row['min_rank']:<6} {row['max_rank']:<6} {row['rank_range']:<6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9640a3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e568a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 1: Setup\n",
      "======================================================================\n",
      "Utterances (8): ['all,successful', 'all,unsuccessful', 'most,successful', 'most,unsuccessful', 'some,successful', 'some,unsuccessful', 'no,successful', 'no,unsuccessful']\n",
      "Theta values (11): [np.float64(0.0), np.float64(0.1), np.float64(0.2), np.float64(0.3), np.float64(0.4), np.float64(0.5), np.float64(0.6), np.float64(0.7), np.float64(0.8), np.float64(0.9), np.float64(1.0)]\n",
      "Alpha values: 20 values from 1.0 to 100.0\n",
      "Sequences: 32768\n",
      "Rounds: 5\n",
      "\n",
      "======================================================================\n",
      "STEP 2: Define helper function\n",
      "======================================================================\n",
      "Helper function defined: get_log_P_u_given_theta(speaker, log_P_O_given_theta)\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Computing log P(seq | θ) matrices for all speakers\n",
      "======================================================================\n",
      "\n",
      "Literal speaker...\n",
      "  Shape: (32768, 11)\n",
      "  Done.\n",
      "\n",
      "Pragmatic speakers (update_internal=False)...\n",
      "\n",
      "  inf_F (psi=inf, omega=coop)...\n",
      "    alpha=1.000 done\n",
      "    alpha=3.371 done\n",
      "    alpha=11.360 done\n",
      "    alpha=38.280 done\n",
      "  inf_F complete: 20 matrices stored\n",
      "\n",
      "  persp_F (psi=pers+, omega=strat)...\n",
      "    alpha=1.000 done\n",
      "    alpha=3.371 done\n",
      "    alpha=11.360 done\n",
      "    alpha=38.280 done\n",
      "  persp_F complete: 20 matrices stored\n",
      "\n",
      "  persm_F (psi=pers-, omega=strat)...\n",
      "    alpha=1.000 done\n",
      "    alpha=3.371 done\n",
      "    alpha=11.360 done\n",
      "    alpha=38.280 done\n",
      "  persm_F complete: 20 matrices stored\n",
      "\n",
      "Pragmatic speakers (update_internal=True)...\n",
      "\n",
      "  inf_T (psi=inf, omega=coop)...\n",
      "    alpha=1.000 done\n",
      "    alpha=3.371 done\n",
      "    alpha=11.360 done\n",
      "    alpha=38.280 done\n",
      "  inf_T complete: 20 matrices stored\n",
      "\n",
      "  persp_T (psi=pers+, omega=strat)...\n",
      "    alpha=1.000 done\n",
      "    alpha=3.371 done\n",
      "    alpha=11.360 done\n",
      "    alpha=38.280 done\n",
      "  persp_T complete: 20 matrices stored\n",
      "\n",
      "  persm_T (psi=pers-, omega=strat)...\n",
      "    alpha=1.000 done\n",
      "    alpha=3.371 done\n",
      "    alpha=11.360 done\n",
      "    alpha=38.280 done\n",
      "  persm_T complete: 20 matrices stored\n",
      "\n",
      "Total matrices stored: 121\n",
      "  Expected: 1 (literal) + 3×20 (F) + 3×20 (T) = 121\n",
      "\n",
      "======================================================================\n",
      "STEP 4: Verification - each P(seq|θ) should sum to 1 over sequences\n",
      "======================================================================\n",
      "All matrices verified: Σ_seq P(seq|θ) = 1.0 for each θ ✓\n",
      "\n",
      "======================================================================\n",
      "STEP 5: Define marginalization helpers\n",
      "======================================================================\n",
      "Helper functions defined:\n",
      "  - get_log_P_seq_given_theta_matrix(speaker_type, alpha)\n",
      "  - get_P_seq_for_theta(speaker_type, theta, alpha)\n",
      "  - get_P_seq_marginalized(speaker_type, alpha, log_prior_theta)\n",
      "\n",
      "======================================================================\n",
      "STEP 6: Build comprehensive DataFrame\n",
      "======================================================================\n",
      "DataFrame shape: (32768, 1333)\n",
      "  Rows (sequences): 32768\n",
      "  Columns: 1333\n",
      "    - 2 identifier columns\n",
      "    - 11 literal columns\n",
      "    - 6 × 20 × 11 = 1320 pragmatic columns\n",
      "\n",
      "======================================================================\n",
      "STEP 7: Verify DataFrame columns sum to 1\n",
      "======================================================================\n",
      "Checking 1331 probability columns...\n",
      "  All probability columns sum to 1.0 ✓\n",
      "\n",
      "======================================================================\n",
      "STEP 8: Save results\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/home/claude'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 385\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# Save DataFrame as CSV\u001b[39;00m\n\u001b[32m    384\u001b[39m csv_path = \u001b[33m'\u001b[39m\u001b[33m/home/claude/P_seq_given_speaker_alpha_theta.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved DataFrame: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# Save raw log matrices as NPZ (more compact, preserves precision)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/core/generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/io/common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/programming-test/lib/python3.13/site-packages/pandas/io/common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '/home/claude'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Setup\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "world = World(n=1, m=5)\n",
    "\n",
    "utterances = world.utterances\n",
    "theta_values = world.theta_values\n",
    "n_utterances = len(utterances)\n",
    "n_theta = len(theta_values)\n",
    "n_rounds = 5\n",
    "n_sequences = n_utterances ** n_rounds\n",
    "\n",
    "# P(O|θ) matrix - rows are observations, columns are theta values\n",
    "log_P_O_given_theta = world.obs_log_likelihood_theta.values  # (n_obs, n_theta)\n",
    "\n",
    "# All sequences as tuples of utterance indices\n",
    "all_sequences = list(itertools.product(range(n_utterances), repeat=n_rounds))\n",
    "sequence_labels = [tuple(utterances[i] for i in seq) for seq in all_sequences]\n",
    "\n",
    "# Alpha values\n",
    "alpha_values = [1.000, 1.275, 1.626, 2.073, 2.643, 3.371, 4.299, 5.482, \n",
    "                6.988, 8.909, 11.36, 14.48, 18.46, 23.54, 30.02, 38.28, \n",
    "                48.80, 62.23, 79.32, 100.0]\n",
    "n_alpha = len(alpha_values)\n",
    "\n",
    "print(f\"Utterances ({n_utterances}): {utterances}\")\n",
    "print(f\"Theta values ({n_theta}): {list(theta_values)}\")\n",
    "print(f\"Alpha values: {n_alpha} values from {alpha_values[0]} to {alpha_values[-1]}\")\n",
    "print(f\"Sequences: {n_sequences}\")\n",
    "print(f\"Rounds: {n_rounds}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Helper function\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: Define helper function\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def get_log_P_u_given_theta(speaker, log_P_O_given_theta):\n",
    "    \"\"\"\n",
    "    Marginalize P(u|O) over O to get P(u|θ).\n",
    "    \n",
    "    P(u|θ) = Σ_O P(u|O) P(O|θ)\n",
    "    \n",
    "    In log space: log P(u|θ) = logsumexp_O [log P(u|O) + log P(O|θ)]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    speaker : PragmaticSpeaker_obs\n",
    "        Speaker with utterance_log_prob_obs attribute (shape: n_utt × n_obs)\n",
    "    log_P_O_given_theta : np.ndarray\n",
    "        Log P(O|θ) matrix (shape: n_obs × n_theta)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Log P(u|θ) matrix (shape: n_utt × n_theta)\n",
    "    \"\"\"\n",
    "    log_P_u_given_O = speaker.utterance_log_prob_obs.values  # (n_utt, n_obs)\n",
    "    # Matrix multiply in log space: (n_utt, n_obs) @ (n_obs, n_theta) -> (n_utt, n_theta)\n",
    "    return log_M_product(log_P_u_given_O, log_P_O_given_theta, precise=USE_PRECISE_LOGSPACE)\n",
    "\n",
    "print(\"Helper function defined: get_log_P_u_given_theta(speaker, log_P_O_given_theta)\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3: Storage and computation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: Computing log P(seq | θ) matrices for all speakers\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Storage: (speaker_type, alpha) -> np.array of shape (n_sequences, n_theta)\n",
    "# For literal speaker, alpha is None\n",
    "log_P_seq_given_theta = {}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# LITERAL SPEAKER\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nLiteral speaker...\")\n",
    "\n",
    "# LiteralListener already computes P(u|θ) internally via marginalizing over O\n",
    "literal_listener = LiteralListener(world)\n",
    "log_P_u_given_theta_literal = literal_listener.utterance_log_likelihood_theta.values  # (n_utt, n_theta)\n",
    "\n",
    "# Verify shape\n",
    "assert log_P_u_given_theta_literal.shape == (n_utterances, n_theta), \\\n",
    "    f\"Expected shape ({n_utterances}, {n_theta}), got {log_P_u_given_theta_literal.shape}\"\n",
    "\n",
    "# Compute P(seq|θ) - utterances are conditionally independent given θ\n",
    "# log P(seq|θ) = Σ_r log P(u_r|θ)\n",
    "log_P_seq_theta_literal = np.zeros((n_sequences, n_theta))\n",
    "for seq_idx, seq in enumerate(all_sequences):\n",
    "    for r in range(n_rounds):\n",
    "        u_idx = seq[r]\n",
    "        log_P_seq_theta_literal[seq_idx, :] += log_P_u_given_theta_literal[u_idx, :]\n",
    "\n",
    "log_P_seq_given_theta[('literal', None)] = log_P_seq_theta_literal\n",
    "print(f\"  Shape: {log_P_seq_theta_literal.shape}\")\n",
    "print(\"  Done.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PRAGMATIC SPEAKERS with update_internal=False\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nPragmatic speakers (update_internal=False)...\")\n",
    "\n",
    "psi_map_F = {\n",
    "    'inf_F': 'inf',\n",
    "    'persp_F': 'pers+',\n",
    "    'persm_F': 'pers-'\n",
    "}\n",
    "\n",
    "for speaker_type, psi in psi_map_F.items():\n",
    "    omega = 'coop' if psi == 'inf' else 'strat'\n",
    "    print(f\"\\n  {speaker_type} (psi={psi}, omega={omega})...\")\n",
    "    \n",
    "    for alpha_idx, alpha in enumerate(alpha_values):\n",
    "        # Create pragmatic speaker\n",
    "        speaker = PragmaticSpeaker_obs(\n",
    "            world=world,\n",
    "            omega=omega,\n",
    "            psi=psi,\n",
    "            update_internal=False,\n",
    "            alpha=alpha,\n",
    "            beta=0.0\n",
    "        )\n",
    "        \n",
    "        # Get log P(u|θ) by marginalizing P(u|O) over O\n",
    "        log_P_u_given_theta = get_log_P_u_given_theta(speaker, log_P_O_given_theta)\n",
    "        \n",
    "        # Verify shape\n",
    "        assert log_P_u_given_theta.shape == (n_utterances, n_theta), \\\n",
    "            f\"Expected shape ({n_utterances}, {n_theta}), got {log_P_u_given_theta.shape}\"\n",
    "        \n",
    "        # Compute P(seq|θ) - conditionally independent given θ\n",
    "        log_P_seq_theta = np.zeros((n_sequences, n_theta))\n",
    "        for seq_idx, seq in enumerate(all_sequences):\n",
    "            for r in range(n_rounds):\n",
    "                u_idx = seq[r]\n",
    "                log_P_seq_theta[seq_idx, :] += log_P_u_given_theta[u_idx, :]\n",
    "        \n",
    "        log_P_seq_given_theta[(speaker_type, alpha)] = log_P_seq_theta\n",
    "        \n",
    "        if alpha_idx % 5 == 0:\n",
    "            print(f\"    alpha={alpha:.3f} done\")\n",
    "    \n",
    "    print(f\"  {speaker_type} complete: {n_alpha} matrices stored\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PRAGMATIC SPEAKERS with update_internal=True\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nPragmatic speakers (update_internal=True)...\")\n",
    "\n",
    "psi_map_T = {\n",
    "    'inf_T': 'inf',\n",
    "    'persp_T': 'pers+',\n",
    "    'persm_T': 'pers-'\n",
    "}\n",
    "\n",
    "for speaker_type, psi in psi_map_T.items():\n",
    "    omega = 'coop' if psi == 'inf' else 'strat'\n",
    "    print(f\"\\n  {speaker_type} (psi={psi}, omega={omega})...\")\n",
    "    \n",
    "    for alpha_idx, alpha in enumerate(alpha_values):\n",
    "        \n",
    "        # Precompute log P(u|θ) for all possible histories\n",
    "        # History = tuple of utterance indices for previous rounds\n",
    "        # We need histories of length 0, 1, 2, 3, 4\n",
    "        history_log_P_u_given_theta = {}\n",
    "        \n",
    "        for hist_len in range(n_rounds):\n",
    "            if hist_len == 0:\n",
    "                histories = [()]\n",
    "            else:\n",
    "                histories = list(itertools.product(range(n_utterances), repeat=hist_len))\n",
    "            \n",
    "            for history in histories:\n",
    "                # Convert history indices to utterance strings\n",
    "                history_utterances = [utterances[i] for i in history]\n",
    "                \n",
    "                # Create a fresh speaker\n",
    "                speaker = PragmaticSpeaker_obs(\n",
    "                    world=world,\n",
    "                    omega=omega,\n",
    "                    psi=psi,\n",
    "                    update_internal=True,\n",
    "                    alpha=alpha,\n",
    "                    beta=0.0\n",
    "                )\n",
    "                \n",
    "                # Apply history: update internal listener for each past utterance\n",
    "                for u in history_utterances:\n",
    "                    speaker.literal_listener.listen_and_update(u)\n",
    "                    speaker.utterance_log_prob_obs = speaker._compute_utterance_log_prob_obs(alpha)\n",
    "                \n",
    "                # Now get P(u|θ) for this history state\n",
    "                history_log_P_u_given_theta[history] = get_log_P_u_given_theta(speaker, log_P_O_given_theta)\n",
    "        \n",
    "        # Compute P(seq|θ) using history-dependent probabilities\n",
    "        # log P(seq|θ) = Σ_r log P^{history_r}(u_r|θ)\n",
    "        log_P_seq_theta = np.zeros((n_sequences, n_theta))\n",
    "        for seq_idx, seq in enumerate(all_sequences):\n",
    "            for r in range(n_rounds):\n",
    "                history = seq[:r]  # Utterances before round r\n",
    "                u_idx = seq[r]     # Utterance at round r\n",
    "                log_P_seq_theta[seq_idx, :] += history_log_P_u_given_theta[history][u_idx, :]\n",
    "        \n",
    "        log_P_seq_given_theta[(speaker_type, alpha)] = log_P_seq_theta\n",
    "        \n",
    "        if alpha_idx % 5 == 0:\n",
    "            print(f\"    alpha={alpha:.3f} done\")\n",
    "    \n",
    "    print(f\"  {speaker_type} complete: {n_alpha} matrices stored\")\n",
    "\n",
    "print(f\"\\nTotal matrices stored: {len(log_P_seq_given_theta)}\")\n",
    "print(f\"  Expected: 1 (literal) + 3×{n_alpha} (F) + 3×{n_alpha} (T) = {1 + 6*n_alpha}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4: Verification\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: Verification - each P(seq|θ) should sum to 1 over sequences\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_valid = True\n",
    "for key, log_P in log_P_seq_given_theta.items():\n",
    "    P = np.exp(log_P)\n",
    "    sums = P.sum(axis=0)  # Sum over sequences for each theta\n",
    "    \n",
    "    if not np.allclose(sums, 1.0, atol=1e-5):\n",
    "        print(f\"  WARNING {key}: sums range [{sums.min():.6f}, {sums.max():.6f}]\")\n",
    "        all_valid = False\n",
    "\n",
    "if all_valid:\n",
    "    print(\"All matrices verified: Σ_seq P(seq|θ) = 1.0 for each θ ✓\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5: Define marginalization helper functions\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: Define marginalization helpers\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def get_log_P_seq_given_theta_matrix(speaker_type, alpha=None):\n",
    "    \"\"\"\n",
    "    Get the full log P(seq|θ) matrix for a speaker.\n",
    "    \n",
    "    Returns array of shape (n_sequences, n_theta).\n",
    "    \"\"\"\n",
    "    if speaker_type == 'literal':\n",
    "        key = ('literal', None)\n",
    "    else:\n",
    "        key = (speaker_type, alpha)\n",
    "    \n",
    "    if key not in log_P_seq_given_theta:\n",
    "        raise KeyError(f\"No matrix found for {key}\")\n",
    "    \n",
    "    return log_P_seq_given_theta[key]\n",
    "\n",
    "\n",
    "def get_P_seq_for_theta(speaker_type, theta, alpha=None):\n",
    "    \"\"\"\n",
    "    Get P(seq | speaker, alpha, θ) for a specific theta value.\n",
    "    \n",
    "    Returns array of shape (n_sequences,).\n",
    "    \"\"\"\n",
    "    log_P = get_log_P_seq_given_theta_matrix(speaker_type, alpha)\n",
    "    theta_idx = np.where(np.isclose(theta_values, theta))[0]\n",
    "    \n",
    "    if len(theta_idx) == 0:\n",
    "        raise ValueError(f\"Theta {theta} not found in theta_values: {list(theta_values)}\")\n",
    "    \n",
    "    return np.exp(log_P[:, theta_idx[0]])\n",
    "\n",
    "\n",
    "def get_P_seq_marginalized(speaker_type, alpha=None, log_prior_theta=None):\n",
    "    \"\"\"\n",
    "    Get P(seq | speaker, alpha) marginalized over θ.\n",
    "    \n",
    "    P(seq) = Σ_θ P(seq|θ) P(θ)\n",
    "    \n",
    "    If log_prior_theta is None, uses flat (uniform) prior over theta.\n",
    "    \n",
    "    Returns array of shape (n_sequences,).\n",
    "    \"\"\"\n",
    "    log_P = get_log_P_seq_given_theta_matrix(speaker_type, alpha)\n",
    "    \n",
    "    if log_prior_theta is None:\n",
    "        log_prior_theta = np.full(n_theta, -np.log(n_theta))\n",
    "    \n",
    "    # log P(seq) = logsumexp_θ [log P(seq|θ) + log P(θ)]\n",
    "    log_P_seq = logsumexp(log_P + log_prior_theta, axis=1)\n",
    "    return np.exp(log_P_seq)\n",
    "\n",
    "print(\"Helper functions defined:\")\n",
    "print(\"  - get_log_P_seq_given_theta_matrix(speaker_type, alpha)\")\n",
    "print(\"  - get_P_seq_for_theta(speaker_type, theta, alpha)\")\n",
    "print(\"  - get_P_seq_marginalized(speaker_type, alpha, log_prior_theta)\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 6: Build comprehensive DataFrame\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: Build comprehensive DataFrame\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Collect all columns in a dictionary first (avoids fragmentation warning)\n",
    "all_columns = {}\n",
    "\n",
    "# Sequence identifiers\n",
    "all_columns['sequence'] = sequence_labels\n",
    "all_columns['sequence_idx'] = all_sequences\n",
    "\n",
    "# Literal columns: one per theta\n",
    "for theta_idx, theta in enumerate(theta_values):\n",
    "    col_name = f\"literal_theta={theta:.1f}\"\n",
    "    all_columns[col_name] = np.exp(log_P_seq_given_theta[('literal', None)][:, theta_idx])\n",
    "\n",
    "# Pragmatic columns: speaker × alpha × theta\n",
    "for speaker_type in ['inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']:\n",
    "    for alpha in alpha_values:\n",
    "        log_P = log_P_seq_given_theta[(speaker_type, alpha)]\n",
    "        for theta_idx, theta in enumerate(theta_values):\n",
    "            col_name = f\"{speaker_type}_alpha={alpha:.2f}_theta={theta:.1f}\"\n",
    "            all_columns[col_name] = np.exp(log_P[:, theta_idx])\n",
    "\n",
    "# Build DataFrame in one shot\n",
    "results = pd.DataFrame(all_columns)\n",
    "\n",
    "print(f\"DataFrame shape: {results.shape}\")\n",
    "print(f\"  Rows (sequences): {results.shape[0]}\")\n",
    "print(f\"  Columns: {results.shape[1]}\")\n",
    "print(f\"    - 2 identifier columns\")\n",
    "print(f\"    - {n_theta} literal columns\")\n",
    "print(f\"    - 6 × {n_alpha} × {n_theta} = {6 * n_alpha * n_theta} pragmatic columns\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 7: Verify DataFrame\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 7: Verify DataFrame columns sum to 1\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "prob_cols = [c for c in results.columns if c not in ['sequence', 'sequence_idx']]\n",
    "print(f\"Checking {len(prob_cols)} probability columns...\")\n",
    "\n",
    "bad_cols = []\n",
    "for col in prob_cols:\n",
    "    total = results[col].sum()\n",
    "    if not np.isclose(total, 1.0, atol=1e-5):\n",
    "        bad_cols.append((col, total))\n",
    "\n",
    "if bad_cols:\n",
    "    print(f\"  WARNING: {len(bad_cols)} columns don't sum to 1:\")\n",
    "    for col, total in bad_cols[:5]:\n",
    "        print(f\"    {col}: {total:.6f}\")\n",
    "else:\n",
    "    print(\"  All probability columns sum to 1.0 ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eba3044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 8: Save results\n",
      "======================================================================\n",
      "Saved DataFrame: P_seq_given_speaker_alpha_theta.csv\n",
      "Saved log matrices: log_P_seq_given_theta_matrices.npz\n",
      "\n",
      "======================================================================\n",
      "STEP 9: Usage examples\n",
      "======================================================================\n",
      "\n",
      "Example 1: P(seq | inf_T, α=8.909, θ=0.5)\n",
      "  Top sequence: ('most,successful', 'most,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,successful')\n",
      "  Probability: 0.021869\n",
      "\n",
      "Example 2: P(seq | inf_T, α=8.909) marginalized over θ [flat prior]\n",
      "  Top sequence: ('most,successful', 'most,unsuccessful', 'most,successful', 'most,successful', 'most,successful')\n",
      "  Probability: 0.008243\n",
      "\n",
      "Example 3: P(seq | literal) marginalized over θ [flat prior]\n",
      "  Top sequence: ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "  Probability: 0.001877\n",
      "\n",
      "Example 4: Top sequence for inf_T (α=8.909) at each θ:\n",
      "  θ=0.0: al,al,al,al,al       (P=0.0131)\n",
      "  θ=0.1: mo,al,so,al,so       (P=0.0053)\n",
      "  θ=0.2: mo,so,mo,mo,so       (P=0.0143)\n",
      "  θ=0.3: mo,mo,mo,mo,mo       (P=0.0265)\n",
      "  θ=0.4: mo,mo,mo,mo,mo       (P=0.0338)\n",
      "  θ=0.5: mo,mo,mo,mo,mo       (P=0.0219)\n",
      "  θ=0.6: mo,mo,mo,mo,mo       (P=0.0338)\n",
      "  θ=0.7: mo,mo,mo,mo,mo       (P=0.0265)\n",
      "  θ=0.8: mo,so,mo,mo,so       (P=0.0143)\n",
      "  θ=0.9: mo,al,so,al,so       (P=0.0053)\n",
      "  θ=1.0: al,al,al,al,al       (P=0.0131)\n",
      "\n",
      "Example 5: Top sequence for each speaker type (α=8.909, flat prior):\n",
      "  literal   : ('some,successful', 'some,successful', 'some,successful',...      (P=0.0019)\n",
      "  inf_T     : ('most,successful', 'most,unsuccessful', 'most,successful...      (P=0.0082)\n",
      "  inf_F     : ('most,successful', 'most,successful', 'most,successful',...      (P=0.0277)\n",
      "  persp_T   : ('some,unsuccessful', 'some,unsuccessful', 'some,unsucces...      (P=0.0741)\n",
      "  persp_F   : ('some,unsuccessful', 'some,unsuccessful', 'some,unsucces...      (P=0.0886)\n",
      "  persm_T   : ('some,successful', 'some,successful', 'some,successful',...      (P=0.0741)\n",
      "  persm_F   : ('some,successful', 'some,successful', 'some,successful',...      (P=0.0886)\n",
      "\n",
      "======================================================================\n",
      "COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Stored objects:\n",
      "  - log_P_seq_given_theta: dict with 121 matrices\n",
      "  - results: DataFrame with shape (32768, 1333)\n",
      "\n",
      "Files saved:\n",
      "  - P_seq_given_speaker_alpha_theta.csv\n",
      "  - log_P_seq_given_theta_matrices.npz\n",
      "\n",
      "======================================================================\n",
      "STEP 9: Usage examples\n",
      "======================================================================\n",
      "\n",
      "Example 1: P(seq | inf_T, α=8.909, θ=0.5)\n",
      "  Top sequence: ('most,successful', 'most,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,successful')\n",
      "  Probability: 0.021869\n",
      "\n",
      "Example 2: P(seq | inf_T, α=8.909) marginalized over θ [flat prior]\n",
      "  Top sequence: ('most,successful', 'most,unsuccessful', 'most,successful', 'most,successful', 'most,successful')\n",
      "  Probability: 0.008243\n",
      "\n",
      "Example 3: P(seq | literal) marginalized over θ [flat prior]\n",
      "  Top sequence: ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "  Probability: 0.001877\n",
      "\n",
      "Example 4: Top sequence for inf_T (α=8.909) at each θ:\n",
      "  θ=0.0: al,al,al,al,al       (P=0.0131)\n",
      "  θ=0.1: mo,al,so,al,so       (P=0.0053)\n",
      "  θ=0.2: mo,so,mo,mo,so       (P=0.0143)\n",
      "  θ=0.3: mo,mo,mo,mo,mo       (P=0.0265)\n",
      "  θ=0.4: mo,mo,mo,mo,mo       (P=0.0338)\n",
      "  θ=0.5: mo,mo,mo,mo,mo       (P=0.0219)\n",
      "  θ=0.6: mo,mo,mo,mo,mo       (P=0.0338)\n",
      "  θ=0.7: mo,mo,mo,mo,mo       (P=0.0265)\n",
      "  θ=0.8: mo,so,mo,mo,so       (P=0.0143)\n",
      "  θ=0.9: mo,al,so,al,so       (P=0.0053)\n",
      "  θ=1.0: al,al,al,al,al       (P=0.0131)\n",
      "\n",
      "Example 5: Top sequence for each speaker type (α=8.909, flat prior):\n",
      "  literal   : ('some,successful', 'some,successful', 'some,successful',...      (P=0.0019)\n",
      "  inf_T     : ('most,successful', 'most,unsuccessful', 'most,successful...      (P=0.0082)\n",
      "  inf_F     : ('most,successful', 'most,successful', 'most,successful',...      (P=0.0277)\n",
      "  persp_T   : ('some,unsuccessful', 'some,unsuccessful', 'some,unsucces...      (P=0.0741)\n",
      "  persp_F   : ('some,unsuccessful', 'some,unsuccessful', 'some,unsucces...      (P=0.0886)\n",
      "  persm_T   : ('some,successful', 'some,successful', 'some,successful',...      (P=0.0741)\n",
      "  persm_F   : ('some,successful', 'some,successful', 'some,successful',...      (P=0.0886)\n",
      "\n",
      "======================================================================\n",
      "COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Stored objects:\n",
      "  - log_P_seq_given_theta: dict with 121 matrices\n",
      "  - results: DataFrame with shape (32768, 1333)\n",
      "\n",
      "Files saved:\n",
      "  - P_seq_given_speaker_alpha_theta.csv\n",
      "  - log_P_seq_given_theta_matrices.npz\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 8: Save results\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 8: Save results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save DataFrame as CSV\n",
    "csv_path = 'P_seq_given_speaker_alpha_theta.csv'\n",
    "results.to_csv(csv_path, index=False)\n",
    "print(f\"Saved DataFrame: {csv_path}\")\n",
    "\n",
    "# Save raw log matrices as NPZ (preserves precision for later use)\n",
    "npz_data = {\n",
    "    'theta_values': theta_values,\n",
    "    'alpha_values': np.array(alpha_values),\n",
    "    'sequences': np.array(all_sequences),\n",
    "    'utterances': np.array(utterances)\n",
    "}\n",
    "\n",
    "# Add each log P(seq|θ) matrix\n",
    "for (speaker_type, alpha), log_P in log_P_seq_given_theta.items():\n",
    "    if alpha is None:\n",
    "        key = f\"{speaker_type}\"\n",
    "    else:\n",
    "        key = f\"{speaker_type}_alpha={alpha:.2f}\"\n",
    "    npz_data[key] = log_P\n",
    "\n",
    "npz_path = 'log_P_seq_given_theta_matrices.npz'\n",
    "np.savez(npz_path, **npz_data)  # Use np.savez instead of np.savez_compressed\n",
    "print(f\"Saved log matrices: {npz_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 9: Usage examples\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 9: Usage examples\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Example 1: P(seq | inf_T, alpha=8.909, theta=0.5)\n",
    "print(\"\\nExample 1: P(seq | inf_T, α=8.909, θ=0.5)\")\n",
    "P = get_P_seq_for_theta('inf_T', 0.5, alpha=8.909)\n",
    "top_idx = np.argmax(P)\n",
    "print(f\"  Top sequence: {sequence_labels[top_idx]}\")\n",
    "print(f\"  Probability: {P[top_idx]:.6f}\")\n",
    "\n",
    "# Example 2: P(seq | inf_T, alpha=8.909) with flat prior over theta\n",
    "print(\"\\nExample 2: P(seq | inf_T, α=8.909) marginalized over θ [flat prior]\")\n",
    "P = get_P_seq_marginalized('inf_T', alpha=8.909)\n",
    "top_idx = np.argmax(P)\n",
    "print(f\"  Top sequence: {sequence_labels[top_idx]}\")\n",
    "print(f\"  Probability: {P[top_idx]:.6f}\")\n",
    "\n",
    "# Example 3: P(seq | literal) with flat prior\n",
    "print(\"\\nExample 3: P(seq | literal) marginalized over θ [flat prior]\")\n",
    "P = get_P_seq_marginalized('literal')\n",
    "top_idx = np.argmax(P)\n",
    "print(f\"  Top sequence: {sequence_labels[top_idx]}\")\n",
    "print(f\"  Probability: {P[top_idx]:.6f}\")\n",
    "\n",
    "# Example 4: Top sequence for inf_T at each theta\n",
    "print(\"\\nExample 4: Top sequence for inf_T (α=8.909) at each θ:\")\n",
    "for theta in theta_values:\n",
    "    P = get_P_seq_for_theta('inf_T', theta, alpha=8.909)\n",
    "    top_idx = np.argmax(P)\n",
    "    seq_abbrev = \",\".join([u.split(\",\")[0][:2] for u in sequence_labels[top_idx]])\n",
    "    print(f\"  θ={theta:.1f}: {seq_abbrev:<20} (P={P[top_idx]:.4f})\")\n",
    "\n",
    "# Example 5: Compare marginals across speaker types\n",
    "print(\"\\nExample 5: Top sequence for each speaker type (α=8.909, flat prior):\")\n",
    "for speaker_type in ['literal', 'inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']:\n",
    "    alpha = 8.909 if speaker_type != 'literal' else None\n",
    "    P = get_P_seq_marginalized(speaker_type, alpha=alpha)\n",
    "    top_idx = np.argmax(P)\n",
    "    seq_str = str(sequence_labels[top_idx])\n",
    "    if len(seq_str) > 60:\n",
    "        seq_str = seq_str[:57] + \"...\"\n",
    "    print(f\"  {speaker_type:<10}: {seq_str:<65} (P={P[top_idx]:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nStored objects:\")\n",
    "print(f\"  - log_P_seq_given_theta: dict with {len(log_P_seq_given_theta)} matrices\")\n",
    "print(f\"  - results: DataFrame with shape {results.shape}\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  - {csv_path}\")\n",
    "print(f\"  - {npz_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 9: Usage examples\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 9: Usage examples\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Example 1: P(seq | inf_T, alpha=8.909, theta=0.5)\n",
    "print(\"\\nExample 1: P(seq | inf_T, α=8.909, θ=0.5)\")\n",
    "P = get_P_seq_for_theta('inf_T', 0.5, alpha=8.909)\n",
    "top_idx = np.argmax(P)\n",
    "print(f\"  Top sequence: {sequence_labels[top_idx]}\")\n",
    "print(f\"  Probability: {P[top_idx]:.6f}\")\n",
    "\n",
    "# Example 2: P(seq | inf_T, alpha=8.909) with flat prior over theta\n",
    "print(\"\\nExample 2: P(seq | inf_T, α=8.909) marginalized over θ [flat prior]\")\n",
    "P = get_P_seq_marginalized('inf_T', alpha=8.909)\n",
    "top_idx = np.argmax(P)\n",
    "print(f\"  Top sequence: {sequence_labels[top_idx]}\")\n",
    "print(f\"  Probability: {P[top_idx]:.6f}\")\n",
    "\n",
    "# Example 3: P(seq | literal) with flat prior\n",
    "print(\"\\nExample 3: P(seq | literal) marginalized over θ [flat prior]\")\n",
    "P = get_P_seq_marginalized('literal')\n",
    "top_idx = np.argmax(P)\n",
    "print(f\"  Top sequence: {sequence_labels[top_idx]}\")\n",
    "print(f\"  Probability: {P[top_idx]:.6f}\")\n",
    "\n",
    "# Example 4: Top sequence for inf_T at each theta\n",
    "print(\"\\nExample 4: Top sequence for inf_T (α=8.909) at each θ:\")\n",
    "for theta in theta_values:\n",
    "    P = get_P_seq_for_theta('inf_T', theta, alpha=8.909)\n",
    "    top_idx = np.argmax(P)\n",
    "    seq_abbrev = \",\".join([u.split(\",\")[0][:2] for u in sequence_labels[top_idx]])\n",
    "    print(f\"  θ={theta:.1f}: {seq_abbrev:<20} (P={P[top_idx]:.4f})\")\n",
    "\n",
    "# Example 5: Compare marginals across speaker types\n",
    "print(\"\\nExample 5: Top sequence for each speaker type (α=8.909, flat prior):\")\n",
    "for speaker_type in ['literal', 'inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']:\n",
    "    alpha = 8.909 if speaker_type != 'literal' else None\n",
    "    P = get_P_seq_marginalized(speaker_type, alpha=alpha)\n",
    "    top_idx = np.argmax(P)\n",
    "    seq_str = str(sequence_labels[top_idx])\n",
    "    if len(seq_str) > 60:\n",
    "        seq_str = seq_str[:57] + \"...\"\n",
    "    print(f\"  {speaker_type:<10}: {seq_str:<65} (P={P[top_idx]:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nStored objects:\")\n",
    "print(f\"  - log_P_seq_given_theta: dict with {len(log_P_seq_given_theta)} matrices\")\n",
    "print(f\"  - results: DataFrame with shape {results.shape}\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  - {csv_path}\")\n",
    "print(f\"  - {npz_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b61b2b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "REVISED RANK STABILITY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Key insight:\n",
      "- Theta = different true world states (not comparable)\n",
      "- We analyze stability WITHIN each theta\n",
      "- We want T and F variants of same psi to agree (experimental robustness)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Part 2: Rank stability across ALPHA (within each theta)\n",
      "======================================================================\n",
      "\n",
      "--- inf_T ---\n",
      "θ       ρ(1.0,5.5)    ρ(5.5,8.9)   ρ(8.9,14.5)  ρ(14.5,100.0)  ρ(5.5,14.5)  \n",
      "--------------------------------------------------------------------------------\n",
      "0.0       1.000         1.000         1.000         0.998         1.000     \n",
      "0.1       0.966         0.987         0.977         0.566         0.933     \n",
      "0.2       0.935         0.977         0.960         0.643         0.881     \n",
      "0.3       0.892         0.959         0.947         0.728         0.823     \n",
      "0.4       0.826         0.942         0.937         0.795         0.774     \n",
      "0.5       0.795         0.926         0.938         0.815         0.756     \n",
      "0.6       0.826         0.942         0.937         0.795         0.774     \n",
      "0.7       0.892         0.959         0.947         0.728         0.823     \n",
      "0.8       0.935         0.977         0.960         0.643         0.881     \n",
      "0.9       0.966         0.987         0.977         0.566         0.933     \n",
      "1.0       1.000         1.000         1.000         0.998         1.000     \n",
      "\n",
      "--- inf_F ---\n",
      "θ       ρ(1.0,5.5)    ρ(5.5,8.9)   ρ(8.9,14.5)  ρ(14.5,100.0)  ρ(5.5,14.5)  \n",
      "--------------------------------------------------------------------------------\n",
      "0.0       1.000         1.000         1.000         0.997         1.000     \n",
      "0.1       0.985         0.976         0.980         0.488         0.918     \n",
      "0.2       0.931         0.971         0.929         0.694         0.818     \n",
      "0.3       0.907         0.929         0.901         0.839         0.689     \n",
      "0.4       0.856         0.871         0.887         0.917         0.565     \n",
      "0.5       0.679         0.760         0.978         0.871         0.638     \n",
      "0.6       0.856         0.871         0.887         0.917         0.565     \n",
      "0.7       0.907         0.929         0.901         0.839         0.689     \n",
      "0.8       0.931         0.971         0.929         0.694         0.818     \n",
      "0.9       0.985         0.976         0.980         0.488         0.918     \n",
      "1.0       1.000         1.000         1.000         0.997         1.000     \n",
      "\n",
      "--- persp_T ---\n",
      "θ       ρ(1.0,5.5)    ρ(5.5,8.9)   ρ(8.9,14.5)  ρ(14.5,100.0)  ρ(5.5,14.5)  \n",
      "--------------------------------------------------------------------------------\n",
      "0.0       1.000         1.000         1.000         1.000         1.000     \n",
      "0.1       0.941         0.953         0.927         0.568         0.776     \n",
      "0.2       0.866         0.938         0.939         0.745         0.769     \n",
      "0.3       0.793         0.948         0.958         0.854         0.823     \n",
      "0.4       0.778         0.963         0.975         0.923         0.886     \n",
      "0.5       0.848         0.979         0.987         0.962         0.935     \n",
      "0.6       0.896         0.987         0.993         0.979         0.963     \n",
      "0.7       0.940         0.991         0.995         0.985         0.973     \n",
      "0.8       0.959         0.993         0.995         0.984         0.977     \n",
      "0.9       0.977         0.994         0.995         0.981         0.979     \n",
      "1.0       1.000         1.000         1.000         1.000         1.000     \n",
      "\n",
      "--- persp_F ---\n",
      "θ       ρ(1.0,5.5)    ρ(5.5,8.9)   ρ(8.9,14.5)  ρ(14.5,100.0)  ρ(5.5,14.5)  \n",
      "--------------------------------------------------------------------------------\n",
      "0.0       1.000         1.000         1.000         1.000         1.000     \n",
      "0.1       0.838         0.902         0.935         0.862         0.702     \n",
      "0.2       0.715         0.918         0.964         0.947         0.785     \n",
      "0.3       0.662         0.959         0.981         0.981         0.888     \n",
      "0.4       0.714         0.975         0.993         0.993         0.945     \n",
      "0.5       0.850         0.990         0.997         0.998         0.977     \n",
      "0.6       0.939         0.994         0.998         0.998         0.988     \n",
      "0.7       0.974         0.998         0.999         0.997         0.995     \n",
      "0.8       0.987         0.998         1.000         0.996         0.997     \n",
      "0.9       0.994         0.999         0.999         0.994         0.997     \n",
      "1.0       1.000         1.000         1.000         1.000         1.000     \n",
      "\n",
      "--- persm_T ---\n",
      "θ       ρ(1.0,5.5)    ρ(5.5,8.9)   ρ(8.9,14.5)  ρ(14.5,100.0)  ρ(5.5,14.5)  \n",
      "--------------------------------------------------------------------------------\n",
      "0.0       1.000         1.000         1.000         1.000         1.000     \n",
      "0.1       0.977         0.994         0.995         0.981         0.979     \n",
      "0.2       0.959         0.993         0.995         0.984         0.977     \n",
      "0.3       0.940         0.991         0.995         0.985         0.973     \n",
      "0.4       0.896         0.987         0.993         0.979         0.963     \n",
      "0.5       0.848         0.979         0.987         0.962         0.935     \n",
      "0.6       0.778         0.963         0.975         0.923         0.886     \n",
      "0.7       0.793         0.948         0.958         0.854         0.823     \n",
      "0.8       0.866         0.938         0.939         0.745         0.769     \n",
      "0.9       0.941         0.953         0.927         0.568         0.776     \n",
      "1.0       1.000         1.000         1.000         1.000         1.000     \n",
      "\n",
      "--- persm_F ---\n",
      "θ       ρ(1.0,5.5)    ρ(5.5,8.9)   ρ(8.9,14.5)  ρ(14.5,100.0)  ρ(5.5,14.5)  \n",
      "--------------------------------------------------------------------------------\n",
      "0.0       1.000         1.000         1.000         1.000         1.000     \n",
      "0.1       0.994         0.999         0.999         0.994         0.997     \n",
      "0.2       0.987         0.998         1.000         0.996         0.997     \n",
      "0.3       0.974         0.998         0.999         0.997         0.995     \n",
      "0.4       0.939         0.994         0.998         0.998         0.988     \n",
      "0.5       0.850         0.990         0.997         0.998         0.977     \n",
      "0.6       0.714         0.975         0.993         0.993         0.945     \n",
      "0.7       0.662         0.959         0.981         0.981         0.888     \n",
      "0.8       0.715         0.918         0.964         0.947         0.785     \n",
      "0.9       0.838         0.902         0.935         0.862         0.702     \n",
      "1.0       1.000         1.000         1.000         1.000         1.000     \n",
      "\n",
      "======================================================================\n",
      "Part 3: Stability across T vs F (same psi)\n",
      "======================================================================\n",
      "\n",
      "Question: For a given (theta, alpha), do inf_T and inf_F agree on rankings?\n",
      "If yes, we can treat \"informative speaker\" as one model regardless of T/F.\n",
      "\n",
      "\n",
      "--- inf: inf_T vs inf_F ---\n",
      "θ        α=1.0       α=5.5       α=8.9       α=14.5      α=30.0     α=100.0   \n",
      "--------------------------------------------------------------------------------\n",
      "0.0      1.000       1.000       1.000       1.000       1.000       0.998    \n",
      "0.1      0.994       0.967       0.945       0.902       0.740       0.681    \n",
      "0.2      0.987       0.946       0.900       0.803       0.667       0.670    \n",
      "0.3      0.983       0.899       0.796       0.672       0.619       0.654    \n",
      "0.4      0.974       0.800       0.651       0.557       0.587       0.631    \n",
      "0.5      0.923       0.736       0.534       0.527       0.580       0.623    \n",
      "0.6      0.974       0.800       0.651       0.557       0.587       0.632    \n",
      "0.7      0.983       0.899       0.796       0.672       0.619       0.653    \n",
      "0.8      0.987       0.946       0.900       0.803       0.667       0.670    \n",
      "0.9      0.994       0.967       0.945       0.902       0.740       0.681    \n",
      "1.0      1.000       1.000       1.000       1.000       1.000       0.998    \n",
      "\n",
      "--- persp: persp_T vs persp_F ---\n",
      "θ        α=1.0       α=5.5       α=8.9       α=14.5      α=30.0     α=100.0   \n",
      "--------------------------------------------------------------------------------\n",
      "0.0      1.000       1.000       1.000       1.000       1.000       1.000    \n",
      "0.1      0.998       0.899       0.761       0.687       0.729       0.824    \n",
      "0.2      0.996       0.843       0.737       0.718       0.791       0.827    \n",
      "0.3      0.993       0.815       0.760       0.768       0.819       0.828    \n",
      "0.4      0.993       0.839       0.809       0.819       0.837       0.830    \n",
      "0.5      0.990       0.884       0.856       0.850       0.846       0.831    \n",
      "0.6      0.992       0.920       0.890       0.871       0.857       0.840    \n",
      "0.7      0.995       0.943       0.912       0.887       0.865       0.849    \n",
      "0.8      0.998       0.959       0.931       0.902       0.873       0.854    \n",
      "0.9      0.998       0.973       0.949       0.921       0.885       0.860    \n",
      "1.0      1.000       1.000       1.000       1.000       1.000       1.000    \n",
      "\n",
      "--- persm: persm_T vs persm_F ---\n",
      "θ        α=1.0       α=5.5       α=8.9       α=14.5      α=30.0     α=100.0   \n",
      "--------------------------------------------------------------------------------\n",
      "0.0      1.000       1.000       1.000       1.000       1.000       1.000    \n",
      "0.1      0.998       0.973       0.949       0.921       0.885       0.860    \n",
      "0.2      0.998       0.958       0.931       0.903       0.873       0.855    \n",
      "0.3      0.995       0.943       0.912       0.887       0.865       0.848    \n",
      "0.4      0.992       0.919       0.890       0.871       0.858       0.840    \n",
      "0.5      0.990       0.884       0.857       0.850       0.846       0.831    \n",
      "0.6      0.993       0.840       0.809       0.819       0.837       0.830    \n",
      "0.7      0.993       0.816       0.759       0.768       0.818       0.828    \n",
      "0.8      0.996       0.843       0.737       0.718       0.792       0.827    \n",
      "0.9      0.998       0.899       0.761       0.688       0.730       0.823    \n",
      "1.0      1.000       1.000       1.000       1.000       1.000       1.000    \n",
      "\n",
      "======================================================================\n",
      "Part 4: Top-k Jaccard overlap between T and F (same psi)\n",
      "======================================================================\n",
      "\n",
      "--- inf (α=8.909) ---\n",
      "θ      Top-1 same?  Top-5 Jacc   Top-10 Jacc  Top-20 Jacc \n",
      "------------------------------------------------------------\n",
      "0.0    True         0.111        0.250        0.429       \n",
      "0.1    False        0.000        0.000        0.000       \n",
      "0.2    False        0.000        0.000        0.053       \n",
      "0.3    False        0.250        0.111        0.081       \n",
      "0.4    False        0.111        0.333        0.290       \n",
      "0.5    False        0.250        0.429        0.379       \n",
      "0.6    False        0.111        0.333        0.290       \n",
      "0.7    False        0.250        0.111        0.081       \n",
      "0.8    False        0.000        0.000        0.053       \n",
      "0.9    False        0.000        0.000        0.000       \n",
      "1.0    True         1.000        1.000        1.000       \n",
      "\n",
      "--- persp (α=8.909) ---\n",
      "θ      Top-1 same?  Top-5 Jacc   Top-10 Jacc  Top-20 Jacc \n",
      "------------------------------------------------------------\n",
      "0.0    True         0.667        0.429        0.818       \n",
      "0.1    True         0.667        0.667        0.818       \n",
      "0.2    False        0.250        0.176        0.481       \n",
      "0.3    True         0.429        0.333        0.667       \n",
      "0.4    True         0.429        0.429        0.290       \n",
      "0.5    False        0.667        0.538        0.667       \n",
      "0.6    False        0.000        0.053        0.429       \n",
      "0.7    False        0.111        0.429        0.538       \n",
      "0.8    True         0.111        0.053        0.143       \n",
      "0.9    True         0.250        0.333        0.212       \n",
      "1.0    True         1.000        1.000        1.000       \n",
      "\n",
      "--- persm (α=8.909) ---\n",
      "θ      Top-1 same?  Top-5 Jacc   Top-10 Jacc  Top-20 Jacc \n",
      "------------------------------------------------------------\n",
      "0.0    True         0.111        0.176        0.379       \n",
      "0.1    True         0.250        0.250        0.212       \n",
      "0.2    True         0.111        0.053        0.143       \n",
      "0.3    False        0.250        0.538        0.538       \n",
      "0.4    False        0.000        0.053        0.379       \n",
      "0.5    False        1.000        0.538        0.667       \n",
      "0.6    True         0.429        0.429        0.333       \n",
      "0.7    True         0.429        0.333        0.600       \n",
      "0.8    False        0.111        0.176        0.429       \n",
      "0.9    True         1.000        1.000        1.000       \n",
      "1.0    True         0.667        0.538        0.818       \n",
      "\n",
      "======================================================================\n",
      "Part 5: Stable sequences within each theta (across alpha & T/F)\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "θ = 0.0\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 1\n",
      "  ('no,successful', 'all,unsuccessful', 'no,successful', 'all,unsuccessful', 'no,successful')\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 16\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 0\n",
      "\n",
      "============================================================\n",
      "θ = 0.1\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 0\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 16\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 5\n",
      "  ('most,unsuccessful', 'most,unsuccessful', 'no,successful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "  ('most,unsuccessful', 'no,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "  ('most,unsuccessful', 'most,unsuccessful', 'all,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "  ('most,unsuccessful', 'all,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "  ('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "\n",
      "============================================================\n",
      "θ = 0.2\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 0\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 8\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 5\n",
      "  ('most,unsuccessful', 'some,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "  ('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'some,unsuccessful', 'most,unsuccessful')\n",
      "  ('most,unsuccessful', 'most,unsuccessful', 'some,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "  ('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'some,unsuccessful')\n",
      "  ('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "\n",
      "============================================================\n",
      "θ = 0.3\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 2\n",
      "  ('most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "  ('most,unsuccessful', 'most,successful', 'most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful')\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 11\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 7\n",
      "\n",
      "============================================================\n",
      "θ = 0.4\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 8\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 7\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 4\n",
      "  ('most,unsuccessful', 'some,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'some,unsuccessful')\n",
      "  ('most,unsuccessful', 'most,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'most,unsuccessful')\n",
      "  ('most,unsuccessful', 'most,unsuccessful', 'some,unsuccessful', 'most,unsuccessful', 'some,unsuccessful')\n",
      "  ('most,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "\n",
      "============================================================\n",
      "θ = 0.5\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 1\n",
      "  ('most,successful', 'most,unsuccessful', 'most,successful', 'most,successful', 'most,successful')\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 11\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 11\n",
      "\n",
      "============================================================\n",
      "θ = 0.6\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 8\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 4\n",
      "  ('most,successful', 'some,successful', 'most,successful', 'most,successful', 'some,successful')\n",
      "  ('most,successful', 'most,successful', 'some,successful', 'some,successful', 'most,successful')\n",
      "  ('most,successful', 'most,successful', 'most,successful', 'some,successful', 'some,successful')\n",
      "  ('most,successful', 'most,successful', 'some,successful', 'most,successful', 'some,successful')\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 8\n",
      "\n",
      "============================================================\n",
      "θ = 0.7\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 2\n",
      "  ('most,successful', 'most,unsuccessful', 'most,successful', 'most,successful', 'most,successful')\n",
      "  ('most,unsuccessful', 'most,successful', 'most,successful', 'most,successful', 'most,successful')\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 7\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 9\n",
      "\n",
      "============================================================\n",
      "θ = 0.8\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 0\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 5\n",
      "  ('most,successful', 'most,successful', 'most,successful', 'some,successful', 'most,successful')\n",
      "  ('most,successful', 'most,successful', 'some,successful', 'most,successful', 'most,successful')\n",
      "  ('most,successful', 'most,successful', 'most,successful', 'most,successful', 'most,successful')\n",
      "  ('most,successful', 'most,successful', 'most,successful', 'most,successful', 'some,successful')\n",
      "  ('most,successful', 'some,successful', 'most,successful', 'most,successful', 'most,successful')\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 8\n",
      "\n",
      "============================================================\n",
      "θ = 0.9\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 0\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 5\n",
      "  ('most,successful', 'most,successful', 'no,unsuccessful', 'most,successful', 'most,successful')\n",
      "  ('most,successful', 'most,successful', 'all,successful', 'most,successful', 'most,successful')\n",
      "  ('most,successful', 'all,successful', 'most,successful', 'most,successful', 'most,successful')\n",
      "  ('most,successful', 'most,successful', 'most,successful', 'most,successful', 'most,successful')\n",
      "  ('most,successful', 'no,unsuccessful', 'most,successful', 'most,successful', 'most,successful')\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 16\n",
      "\n",
      "============================================================\n",
      "θ = 1.0\n",
      "============================================================\n",
      "\n",
      "INF: Sequences in top-20 for ALL (mid-α, T/F) combos: 20\n",
      "\n",
      "PERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: 20\n",
      "\n",
      "PERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: 16\n",
      "\n",
      "======================================================================\n",
      "Part 6: Detailed analysis for θ = 0.5\n",
      "======================================================================\n",
      "\n",
      "Comparing top sequences at θ=0.5, α=8.909\n",
      "\n",
      "--- literal ---\n",
      "   1. so,so,so,so,so            P=0.003372\n",
      "   2. so,so,so,so,so            P=0.003372\n",
      "   3. so,so,so,so,so            P=0.003372\n",
      "   4. so,so,so,so,so            P=0.003372\n",
      "   5. so,so,so,so,so            P=0.003372\n",
      "   6. so,so,so,so,so            P=0.003372\n",
      "   7. so,so,so,so,so            P=0.003372\n",
      "   8. so,so,so,so,so            P=0.003372\n",
      "   9. so,so,so,so,so            P=0.003372\n",
      "  10. so,so,so,so,so            P=0.003372\n",
      "\n",
      "--- inf_T ---\n",
      "   1. mo,mo,mo,mo,mo            P=0.021869\n",
      "   2. mo,mo,mo,mo,mo            P=0.021869\n",
      "   3. mo,mo,mo,mo,mo            P=0.021869\n",
      "   4. mo,mo,mo,mo,mo            P=0.021869\n",
      "   5. mo,mo,mo,mo,mo            P=0.021869\n",
      "   6. mo,mo,mo,mo,mo            P=0.021869\n",
      "   7. mo,mo,mo,mo,mo            P=0.021869\n",
      "   8. mo,mo,mo,mo,mo            P=0.021869\n",
      "   9. mo,mo,mo,mo,mo            P=0.021055\n",
      "  10. mo,mo,mo,mo,mo            P=0.021055\n",
      "\n",
      "--- inf_F ---\n",
      "   1. mo,mo,mo,mo,mo            P=0.020371\n",
      "   2. mo,mo,mo,mo,mo            P=0.020371\n",
      "   3. mo,mo,mo,mo,mo            P=0.020371\n",
      "   4. mo,mo,mo,mo,mo            P=0.020371\n",
      "   5. mo,mo,mo,mo,mo            P=0.020371\n",
      "   6. mo,mo,mo,mo,mo            P=0.020371\n",
      "   7. mo,mo,mo,mo,mo            P=0.020371\n",
      "   8. mo,mo,mo,mo,mo            P=0.020371\n",
      "   9. mo,mo,mo,mo,mo            P=0.020371\n",
      "  10. mo,mo,mo,mo,mo            P=0.020371\n",
      "\n",
      "--- persp_T ---\n",
      "   1. mo,so,so,so,so            P=0.019239\n",
      "   2. so,so,so,so,so            P=0.018796\n",
      "   3. so,mo,so,so,so            P=0.018380\n",
      "   4. so,so,mo,so,so            P=0.016795\n",
      "   5. so,so,so,mo,so            P=0.015483\n",
      "   6. so,so,so,so,mo            P=0.014375\n",
      "   7. mo,mo,so,so,so            P=0.011762\n",
      "   8. mo,so,mo,so,so            P=0.011659\n",
      "   9. mo,so,so,mo,so            P=0.011538\n",
      "  10. mo,so,so,so,mo            P=0.011399\n",
      "\n",
      "--- persp_F ---\n",
      "   1. so,so,so,so,so            P=0.030982\n",
      "   2. so,so,so,mo,so            P=0.025553\n",
      "   3. so,so,so,so,mo            P=0.025553\n",
      "   4. mo,so,so,so,so            P=0.025553\n",
      "   5. so,mo,so,so,so            P=0.025553\n",
      "   6. so,so,mo,so,so            P=0.025553\n",
      "   7. so,so,so,mo,mo            P=0.021076\n",
      "   8. mo,so,so,mo,so            P=0.021076\n",
      "   9. so,so,mo,mo,so            P=0.021076\n",
      "  10. so,mo,so,mo,so            P=0.021076\n",
      "\n",
      "--- persm_T ---\n",
      "   1. mo,so,so,so,so            P=0.019239\n",
      "   2. so,so,so,so,so            P=0.018796\n",
      "   3. so,mo,so,so,so            P=0.018380\n",
      "   4. so,so,mo,so,so            P=0.016795\n",
      "   5. so,so,so,mo,so            P=0.015483\n",
      "   6. so,so,so,so,mo            P=0.014375\n",
      "   7. mo,mo,so,so,so            P=0.011762\n",
      "   8. mo,so,mo,so,so            P=0.011659\n",
      "   9. mo,so,so,mo,so            P=0.011538\n",
      "  10. mo,so,so,so,mo            P=0.011399\n",
      "\n",
      "--- persm_F ---\n",
      "   1. so,so,so,so,so            P=0.030982\n",
      "   2. so,so,mo,so,so            P=0.025553\n",
      "   3. so,mo,so,so,so            P=0.025553\n",
      "   4. mo,so,so,so,so            P=0.025553\n",
      "   5. so,so,so,mo,so            P=0.025553\n",
      "   6. so,so,so,so,mo            P=0.025553\n",
      "   7. mo,mo,so,so,so            P=0.021076\n",
      "   8. so,so,mo,so,mo            P=0.021076\n",
      "   9. so,so,so,mo,mo            P=0.021076\n",
      "  10. so,so,mo,mo,so            P=0.021076\n",
      "\n",
      "======================================================================\n",
      "Part 7: Rank correlation between speaker types (within theta)\n",
      "======================================================================\n",
      "\n",
      "--- θ = 0.3, α = 8.909 ---\n",
      "               literal     inf_T     inf_F   persp_T   persp_F   persm_T   persm_F\n",
      "literal          1.000     0.633     0.623     0.502     0.304     0.833     0.918\n",
      "inf_T            0.633     1.000     0.796     0.133    -0.138     0.715     0.707\n",
      "inf_F            0.623     0.796     1.000     0.081    -0.195     0.671     0.709\n",
      "persp_T          0.502     0.133     0.081     1.000     0.760     0.035     0.225\n",
      "persp_F          0.304    -0.138    -0.195     0.760     1.000    -0.064    -0.052\n",
      "persm_T          0.833     0.715     0.671     0.035    -0.064     1.000     0.912\n",
      "persm_F          0.918     0.707     0.709     0.225    -0.052     0.912     1.000\n",
      "\n",
      "--- θ = 0.5, α = 8.909 ---\n",
      "               literal     inf_T     inf_F   persp_T   persp_F   persm_T   persm_F\n",
      "literal          1.000     0.309     0.076     0.611     0.628     0.611     0.629\n",
      "inf_T            0.309     1.000     0.534     0.284     0.206     0.284     0.206\n",
      "inf_F            0.076     0.534     1.000     0.122     0.064     0.122     0.064\n",
      "persp_T          0.611     0.284     0.122     1.000     0.856    -0.151    -0.052\n",
      "persp_F          0.628     0.206     0.064     0.856     1.000    -0.052    -0.153\n",
      "persm_T          0.611     0.284     0.122    -0.151    -0.052     1.000     0.857\n",
      "persm_F          0.629     0.206     0.064    -0.052    -0.153     0.857     1.000\n",
      "\n",
      "--- θ = 0.7, α = 8.909 ---\n",
      "               literal     inf_T     inf_F   persp_T   persp_F   persm_T   persm_F\n",
      "literal          1.000     0.633     0.623     0.833     0.918     0.503     0.304\n",
      "inf_T            0.633     1.000     0.796     0.715     0.707     0.133    -0.138\n",
      "inf_F            0.623     0.796     1.000     0.671     0.709     0.081    -0.195\n",
      "persp_T          0.833     0.715     0.671     1.000     0.912     0.035    -0.064\n",
      "persp_F          0.918     0.707     0.709     0.912     1.000     0.225    -0.052\n",
      "persm_T          0.503     0.133     0.081     0.035     0.225     1.000     0.759\n",
      "persm_F          0.304    -0.138    -0.195    -0.064    -0.052     0.759     1.000\n",
      "\n",
      "======================================================================\n",
      "Part 8: Best alpha range for T/F agreement (by psi, by theta)\n",
      "======================================================================\n",
      "\n",
      "For each (psi, theta), find alpha range where Spearman(T, F) > 0.9\n",
      "\n",
      "\n",
      "--- inf ---\n",
      "θ      Alphas with ρ(T,F) > 0.9                           Best ρ    \n",
      "----------------------------------------------------------------------\n",
      "0.0    [1.00, 100.00] (20 vals)                           1.000     \n",
      "0.1    [1.00, 14.48] (12 vals)                            0.994     \n",
      "0.2    [1.00, 6.99] (9 vals)                              0.987     \n",
      "0.3    [1.00, 4.30] (7 vals)                              0.983     \n",
      "0.4    [1.00, 2.64] (5 vals)                              0.974     \n",
      "0.5    [1.00, 2.07] (4 vals)                              0.928     \n",
      "0.6    [1.00, 2.64] (5 vals)                              0.974     \n",
      "0.7    [1.00, 4.30] (7 vals)                              0.983     \n",
      "0.8    [1.00, 6.99] (9 vals)                              0.987     \n",
      "0.9    [1.00, 14.48] (12 vals)                            0.994     \n",
      "1.0    [1.00, 100.00] (20 vals)                           1.000     \n",
      "\n",
      "--- persp ---\n",
      "θ      Alphas with ρ(T,F) > 0.9                           Best ρ    \n",
      "----------------------------------------------------------------------\n",
      "0.0    [1.00, 100.00] (20 vals)                           1.000     \n",
      "0.1    [1.00, 4.30] (7 vals)                              0.998     \n",
      "0.2    [1.00, 3.37] (6 vals)                              0.996     \n",
      "0.3    [1.00, 3.37] (6 vals)                              0.993     \n",
      "0.4    [1.00, 3.37] (6 vals)                              0.993     \n",
      "0.5    [1.00, 4.30] (7 vals)                              0.990     \n",
      "0.6    [1.00, 6.99] (9 vals)                              0.992     \n",
      "0.7    [1.00, 8.91] (10 vals)                             0.995     \n",
      "0.8    [1.00, 14.48] (12 vals)                            0.998     \n",
      "0.9    [1.00, 18.46] (13 vals)                            0.998     \n",
      "1.0    [1.00, 100.00] (20 vals)                           1.000     \n",
      "\n",
      "--- persm ---\n",
      "θ      Alphas with ρ(T,F) > 0.9                           Best ρ    \n",
      "----------------------------------------------------------------------\n",
      "0.0    [1.00, 100.00] (20 vals)                           1.000     \n",
      "0.1    [1.00, 18.46] (13 vals)                            0.998     \n",
      "0.2    [1.00, 14.48] (12 vals)                            0.998     \n",
      "0.3    [1.00, 8.91] (10 vals)                             0.995     \n",
      "0.4    [1.00, 6.99] (9 vals)                              0.992     \n",
      "0.5    [1.00, 4.30] (7 vals)                              0.990     \n",
      "0.6    [1.00, 3.37] (6 vals)                              0.993     \n",
      "0.7    [1.00, 3.37] (6 vals)                              0.993     \n",
      "0.8    [1.00, 3.37] (6 vals)                              0.996     \n",
      "0.9    [1.00, 4.30] (7 vals)                              0.998     \n",
      "1.0    [1.00, 100.00] (20 vals)                           1.000     \n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "\n",
      "KEY FINDINGS:\n",
      "\n",
      "1. WITHIN-THETA ALPHA STABILITY:\n",
      "   - Rankings change across alpha, but mid-range alphas are more stable\n",
      "   - Extreme alphas (1.0, 100.0) often have different rankings\n",
      "\n",
      "2. T vs F AGREEMENT:\n",
      "   - For same psi, T and F versions may or may not agree\n",
      "   - Agreement depends on theta and alpha\n",
      "   - Some (theta, alpha) combinations show high T/F correlation\n",
      "\n",
      "3. IMPLICATIONS FOR EXPERIMENT:\n",
      "   - Choose (theta, alpha) where T/F agreement is high for each psi\n",
      "   - This allows treating inf_T and inf_F as \"informative model\"\n",
      "   - Select sequences that are stable across this range\n",
      "\n",
      "NEXT STEPS:\n",
      "   - Focus on (theta, alpha) combos with high T/F agreement\n",
      "   - For those conditions, compute discriminability (JS) between psi types\n",
      "   - Find sequences that discriminate between psi while being likely\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import itertools\n",
    "\n",
    "# =============================================================================\n",
    "# REVISED ANALYSIS: Stability within theta, across T/F\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"REVISED RANK STABILITY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Key insight:\n",
    "- Theta = different true world states (not comparable)\n",
    "- We analyze stability WITHIN each theta\n",
    "- We want T and F variants of same psi to agree (experimental robustness)\n",
    "\"\"\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 1: Helper functions\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def compute_ranks(P):\n",
    "    \"\"\"Convert probabilities to ranks (1 = highest probability).\"\"\"\n",
    "    return (-P).argsort().argsort() + 1\n",
    "\n",
    "def get_top_k_set(P, k):\n",
    "    \"\"\"Get set of indices in top-k by probability.\"\"\"\n",
    "    return set(np.argsort(-P)[:k])\n",
    "\n",
    "def jaccard(set1, set2):\n",
    "    \"\"\"Compute Jaccard similarity between two sets.\"\"\"\n",
    "    if len(set1) == 0 and len(set2) == 0:\n",
    "        return 1.0\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 2: For each THETA, analyze rank stability across ALPHA\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 2: Rank stability across ALPHA (within each theta)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Selected alphas for comparison\n",
    "alpha_pairs = [\n",
    "    (1.0, 5.482),\n",
    "    (5.482, 8.909),\n",
    "    (8.909, 14.48),\n",
    "    (14.48, 100.0),\n",
    "    (5.482, 14.48),  # Mid-range comparison\n",
    "]\n",
    "\n",
    "for speaker_type in ['inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']:\n",
    "    print(f\"\\n--- {speaker_type} ---\")\n",
    "    print(f\"{'θ':<6}\", end=\"\")\n",
    "    for a1, a2 in alpha_pairs:\n",
    "        print(f\"ρ({a1:.1f},{a2:.1f})\".center(14), end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for theta in theta_values:\n",
    "        print(f\"{theta:<6.1f}\", end=\"\")\n",
    "        for a1, a2 in alpha_pairs:\n",
    "            P1 = get_P_seq_for_theta(speaker_type, theta, alpha=a1)\n",
    "            P2 = get_P_seq_for_theta(speaker_type, theta, alpha=a2)\n",
    "            rho, _ = spearmanr(P1, P2)\n",
    "            print(f\"{rho:^14.3f}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 3: For each (theta, alpha), compare T vs F for same psi\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 3: Stability across T vs F (same psi)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Question: For a given (theta, alpha), do inf_T and inf_F agree on rankings?\n",
    "If yes, we can treat \"informative speaker\" as one model regardless of T/F.\n",
    "\"\"\")\n",
    "\n",
    "selected_alphas = [1.0, 5.482, 8.909, 14.48, 30.02, 100.0]\n",
    "\n",
    "for psi_name, type_T, type_F in [('inf', 'inf_T', 'inf_F'), \n",
    "                                   ('persp', 'persp_T', 'persp_F'), \n",
    "                                   ('persm', 'persm_T', 'persm_F')]:\n",
    "    print(f\"\\n--- {psi_name}: {type_T} vs {type_F} ---\")\n",
    "    print(f\"{'θ':<6}\", end=\"\")\n",
    "    for alpha in selected_alphas:\n",
    "        print(f\"α={alpha:.1f}\".center(12), end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for theta in theta_values:\n",
    "        print(f\"{theta:<6.1f}\", end=\"\")\n",
    "        for alpha in selected_alphas:\n",
    "            P_T = get_P_seq_for_theta(type_T, theta, alpha=alpha)\n",
    "            P_F = get_P_seq_for_theta(type_F, theta, alpha=alpha)\n",
    "            rho, _ = spearmanr(P_T, P_F)\n",
    "            print(f\"{rho:^12.3f}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 4: Top-k overlap between T and F\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 4: Top-k Jaccard overlap between T and F (same psi)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Focus on mid-range alpha\n",
    "alpha_focus = 8.909\n",
    "\n",
    "for psi_name, type_T, type_F in [('inf', 'inf_T', 'inf_F'), \n",
    "                                   ('persp', 'persp_T', 'persp_F'), \n",
    "                                   ('persm', 'persm_T', 'persm_F')]:\n",
    "    print(f\"\\n--- {psi_name} (α={alpha_focus}) ---\")\n",
    "    print(f\"{'θ':<6} {'Top-1 same?':<12} {'Top-5 Jacc':<12} {'Top-10 Jacc':<12} {'Top-20 Jacc':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for theta in theta_values:\n",
    "        P_T = get_P_seq_for_theta(type_T, theta, alpha=alpha_focus)\n",
    "        P_F = get_P_seq_for_theta(type_F, theta, alpha=alpha_focus)\n",
    "        \n",
    "        top1_same = np.argmax(P_T) == np.argmax(P_F)\n",
    "        jacc5 = jaccard(get_top_k_set(P_T, 5), get_top_k_set(P_F, 5))\n",
    "        jacc10 = jaccard(get_top_k_set(P_T, 10), get_top_k_set(P_F, 10))\n",
    "        jacc20 = jaccard(get_top_k_set(P_T, 20), get_top_k_set(P_F, 20))\n",
    "        \n",
    "        print(f\"{theta:<6.1f} {str(top1_same):<12} {jacc5:<12.3f} {jacc10:<12.3f} {jacc20:<12.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 5: Within each theta, find sequences stable across alpha AND across T/F\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 5: Stable sequences within each theta (across alpha & T/F)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Mid-range alphas\n",
    "mid_alphas = [5.482, 6.988, 8.909, 11.36, 14.48]\n",
    "\n",
    "for theta in theta_values:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"θ = {theta}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # For inf: collect top-20 sets for all (alpha, T/F) combinations\n",
    "    top20_sets_inf = []\n",
    "    for alpha in mid_alphas:\n",
    "        for speaker in ['inf_T', 'inf_F']:\n",
    "            P = get_P_seq_for_theta(speaker, theta, alpha=alpha)\n",
    "            top20_sets_inf.append(get_top_k_set(P, 20))\n",
    "    \n",
    "    common_inf = set.intersection(*top20_sets_inf)\n",
    "    print(f\"\\nINF: Sequences in top-20 for ALL (mid-α, T/F) combos: {len(common_inf)}\")\n",
    "    if len(common_inf) > 0 and len(common_inf) <= 5:\n",
    "        for idx in common_inf:\n",
    "            print(f\"  {sequence_labels[idx]}\")\n",
    "    \n",
    "    # For persp\n",
    "    top20_sets_persp = []\n",
    "    for alpha in mid_alphas:\n",
    "        for speaker in ['persp_T', 'persp_F']:\n",
    "            P = get_P_seq_for_theta(speaker, theta, alpha=alpha)\n",
    "            top20_sets_persp.append(get_top_k_set(P, 20))\n",
    "    \n",
    "    common_persp = set.intersection(*top20_sets_persp)\n",
    "    print(f\"\\nPERSP: Sequences in top-20 for ALL (mid-α, T/F) combos: {len(common_persp)}\")\n",
    "    if len(common_persp) > 0 and len(common_persp) <= 5:\n",
    "        for idx in common_persp:\n",
    "            print(f\"  {sequence_labels[idx]}\")\n",
    "    \n",
    "    # For persm\n",
    "    top20_sets_persm = []\n",
    "    for alpha in mid_alphas:\n",
    "        for speaker in ['persm_T', 'persm_F']:\n",
    "            P = get_P_seq_for_theta(speaker, theta, alpha=alpha)\n",
    "            top20_sets_persm.append(get_top_k_set(P, 20))\n",
    "    \n",
    "    common_persm = set.intersection(*top20_sets_persm)\n",
    "    print(f\"\\nPERSM: Sequences in top-20 for ALL (mid-α, T/F) combos: {len(common_persm)}\")\n",
    "    if len(common_persm) > 0 and len(common_persm) <= 5:\n",
    "        for idx in common_persm:\n",
    "            print(f\"  {sequence_labels[idx]}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 6: Detailed comparison for a specific theta (e.g., 0.5)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 6: Detailed analysis for θ = 0.5\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "theta_focus = 0.5\n",
    "alpha_focus = 8.909\n",
    "\n",
    "print(f\"\\nComparing top sequences at θ={theta_focus}, α={alpha_focus}\")\n",
    "\n",
    "# Get top-10 for each speaker type\n",
    "for speaker in ['literal', 'inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']:\n",
    "    if speaker == 'literal':\n",
    "        P = get_P_seq_for_theta('literal', theta_focus, alpha=None)\n",
    "    else:\n",
    "        P = get_P_seq_for_theta(speaker, theta_focus, alpha=alpha_focus)\n",
    "    \n",
    "    print(f\"\\n--- {speaker} ---\")\n",
    "    top10_idx = np.argsort(-P)[:10]\n",
    "    for rank, idx in enumerate(top10_idx, 1):\n",
    "        seq = sequence_labels[idx]\n",
    "        prob = P[idx]\n",
    "        # Abbreviate\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] for u in seq])\n",
    "        print(f\"  {rank:>2}. {abbrev:<25} P={prob:.6f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 7: For each theta, compute rank correlation matrix across all speakers\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 7: Rank correlation between speaker types (within theta)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "alpha_focus = 8.909\n",
    "speakers = ['literal', 'inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']\n",
    "\n",
    "for theta in [0.3, 0.5, 0.7]:  # Selected thetas\n",
    "    print(f\"\\n--- θ = {theta}, α = {alpha_focus} ---\")\n",
    "    print(f\"{'':12}\", end=\"\")\n",
    "    for s in speakers:\n",
    "        print(f\"{s:>10}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for s1 in speakers:\n",
    "        print(f\"{s1:12}\", end=\"\")\n",
    "        for s2 in speakers:\n",
    "            if s1 == 'literal':\n",
    "                P1 = get_P_seq_for_theta('literal', theta, alpha=None)\n",
    "            else:\n",
    "                P1 = get_P_seq_for_theta(s1, theta, alpha=alpha_focus)\n",
    "            \n",
    "            if s2 == 'literal':\n",
    "                P2 = get_P_seq_for_theta('literal', theta, alpha=None)\n",
    "            else:\n",
    "                P2 = get_P_seq_for_theta(s2, theta, alpha=alpha_focus)\n",
    "            \n",
    "            rho, _ = spearmanr(P1, P2)\n",
    "            print(f\"{rho:>10.3f}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 8: Summary table - best alpha range for T/F agreement\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 8: Best alpha range for T/F agreement (by psi, by theta)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "For each (psi, theta), find alpha range where Spearman(T, F) > 0.9\n",
    "\"\"\")\n",
    "\n",
    "all_alphas = alpha_values\n",
    "\n",
    "for psi_name, type_T, type_F in [('inf', 'inf_T', 'inf_F'), \n",
    "                                   ('persp', 'persp_T', 'persp_F'), \n",
    "                                   ('persm', 'persm_T', 'persm_F')]:\n",
    "    print(f\"\\n--- {psi_name} ---\")\n",
    "    print(f\"{'θ':<6} {'Alphas with ρ(T,F) > 0.9':<50} {'Best ρ':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for theta in theta_values:\n",
    "        good_alphas = []\n",
    "        best_rho = -1\n",
    "        for alpha in all_alphas:\n",
    "            P_T = get_P_seq_for_theta(type_T, theta, alpha=alpha)\n",
    "            P_F = get_P_seq_for_theta(type_F, theta, alpha=alpha)\n",
    "            rho, _ = spearmanr(P_T, P_F)\n",
    "            if rho > 0.9:\n",
    "                good_alphas.append(alpha)\n",
    "            if rho > best_rho:\n",
    "                best_rho = rho\n",
    "        \n",
    "        if good_alphas:\n",
    "            alpha_str = f\"[{min(good_alphas):.2f}, {max(good_alphas):.2f}] ({len(good_alphas)} vals)\"\n",
    "        else:\n",
    "            alpha_str = \"None\"\n",
    "        print(f\"{theta:<6.1f} {alpha_str:<50} {best_rho:<10.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 9: Summary\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "KEY FINDINGS:\n",
    "\n",
    "1. WITHIN-THETA ALPHA STABILITY:\n",
    "   - Rankings change across alpha, but mid-range alphas are more stable\n",
    "   - Extreme alphas (1.0, 100.0) often have different rankings\n",
    "\n",
    "2. T vs F AGREEMENT:\n",
    "   - For same psi, T and F versions may or may not agree\n",
    "   - Agreement depends on theta and alpha\n",
    "   - Some (theta, alpha) combinations show high T/F correlation\n",
    "\n",
    "3. IMPLICATIONS FOR EXPERIMENT:\n",
    "   - Choose (theta, alpha) where T/F agreement is high for each psi\n",
    "   - This allows treating inf_T and inf_F as \"informative model\"\n",
    "   - Select sequences that are stable across this range\n",
    "\n",
    "NEXT STEPS:\n",
    "   - Focus on (theta, alpha) combos with high T/F agreement\n",
    "   - For those conditions, compute discriminability (JS) between psi types\n",
    "   - Find sequences that discriminate between psi while being likely\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e744c441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINDING DISCRIMINATING SEQUENCES\n",
      "======================================================================\n",
      "\n",
      "Goal: Find sequences that are:\n",
      "  - STABLE within a speaker type (across alphas) → characteristic\n",
      "  - UNSTABLE between speaker types → discriminating\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Part 1: Compute mean rank across mid-alphas for each sequence\n",
      "======================================================================\n",
      "Computed mean ranks for 11 theta values\n",
      "Shape per theta: (32768, 7)\n",
      "\n",
      "======================================================================\n",
      "Part 2: Compute rank variance (stability) across mid-alphas\n",
      "======================================================================\n",
      "Computed rank variance for each theta\n",
      "\n",
      "======================================================================\n",
      "Part 3: Sequences characteristic of each speaker (stable & top-ranked)\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "θ = 0.3\n",
      "============================================================\n",
      "\n",
      "--- inf_T: 20 stable sequences in top-20 ---\n",
      "  mo,mo,mo,mo,mo            mean_rank=1.4, var=0.2\n",
      "  mo,mo,mo,mo,mo            mean_rank=2.4, var=0.2\n",
      "  mo,so,mo,mo,so            mean_rank=2.6, var=1.8\n",
      "  mo,so,mo,mo,mo            mean_rank=4.0, var=0.8\n",
      "  mo,so,mo,so,mo            mean_rank=5.4, var=0.2\n",
      "\n",
      "--- inf_F: 20 stable sequences in top-20 ---\n",
      "  mo,mo,mo,mo,mo            mean_rank=1.0, var=0.0\n",
      "  mo,mo,mo,mo,mo            mean_rank=3.2, var=2.2\n",
      "  mo,mo,mo,mo,mo            mean_rank=3.8, var=1.0\n",
      "  mo,mo,mo,mo,mo            mean_rank=3.8, var=3.4\n",
      "  mo,mo,mo,mo,mo            mean_rank=4.2, var=1.4\n",
      "\n",
      "--- persp_T: 16 stable sequences in top-20 ---\n",
      "  so,so,so,so,so            mean_rank=1.0, var=0.0\n",
      "  so,so,so,so,so            mean_rank=2.0, var=0.0\n",
      "  so,so,so,so,so            mean_rank=3.2, var=0.2\n",
      "  so,so,so,so,so            mean_rank=4.0, var=0.4\n",
      "  so,so,so,so,so            mean_rank=5.0, var=0.4\n",
      "\n",
      "--- persp_F: 20 stable sequences in top-20 ---\n",
      "  so,so,so,so,so            mean_rank=1.0, var=0.0\n",
      "  so,so,so,so,so            mean_rank=3.0, var=2.4\n",
      "  so,so,so,so,so            mean_rank=3.6, var=1.0\n",
      "  so,so,so,so,so            mean_rank=4.0, var=2.8\n",
      "  so,so,so,so,so            mean_rank=4.6, var=0.6\n",
      "\n",
      "--- persm_T: 20 stable sequences in top-20 ---\n",
      "  mo,mo,mo,so,so            mean_rank=1.8, var=1.4\n",
      "  mo,mo,so,mo,so            mean_rank=3.4, var=2.2\n",
      "  mo,mo,mo,mo,so            mean_rank=4.0, var=8.0\n",
      "  mo,mo,mo,so,mo            mean_rank=5.0, var=8.0\n",
      "  mo,mo,so,so,mo            mean_rank=5.4, var=1.0\n",
      "\n",
      "--- persm_F: 18 stable sequences in top-20 ---\n",
      "  mo,mo,mo,mo,mo            mean_rank=1.0, var=0.0\n",
      "  so,mo,mo,mo,mo            mean_rank=3.6, var=3.8\n",
      "  mo,mo,so,mo,mo            mean_rank=3.6, var=1.0\n",
      "  mo,so,mo,mo,mo            mean_rank=4.0, var=0.8\n",
      "  mo,mo,mo,so,mo            mean_rank=4.2, var=1.4\n",
      "\n",
      "============================================================\n",
      "θ = 0.5\n",
      "============================================================\n",
      "\n",
      "--- inf_T: 20 stable sequences in top-20 ---\n",
      "  mo,mo,mo,mo,mo            mean_rank=3.2, var=7.0\n",
      "  mo,mo,mo,mo,mo            mean_rank=4.0, var=6.4\n",
      "  mo,mo,mo,mo,mo            mean_rank=4.2, var=4.2\n",
      "  mo,mo,mo,mo,mo            mean_rank=4.4, var=6.6\n",
      "  mo,mo,mo,mo,mo            mean_rank=4.6, var=3.4\n",
      "\n",
      "--- inf_F: 3 stable sequences in top-20 ---\n",
      "  mo,mo,mo,mo,mo            mean_rank=12.4, var=10.6\n",
      "  mo,mo,mo,mo,mo            mean_rank=15.6, var=13.4\n",
      "  mo,mo,mo,mo,mo            mean_rank=16.0, var=35.6\n",
      "\n",
      "--- persp_T: 19 stable sequences in top-20 ---\n",
      "  mo,so,so,so,so            mean_rank=1.6, var=0.6\n",
      "  so,so,so,so,so            mean_rank=2.4, var=2.2\n",
      "  so,mo,so,so,so            mean_rank=2.4, var=0.2\n",
      "  so,so,mo,so,so            mean_rank=3.8, var=0.2\n",
      "  so,so,so,mo,so            mean_rank=5.2, var=0.2\n",
      "\n",
      "--- persp_F: 20 stable sequences in top-20 ---\n",
      "  so,so,so,so,so            mean_rank=1.0, var=0.0\n",
      "  so,so,so,mo,so            mean_rank=3.2, var=1.4\n",
      "  so,so,mo,so,so            mean_rank=3.8, var=2.2\n",
      "  so,so,so,so,mo            mean_rank=4.2, var=2.6\n",
      "  mo,so,so,so,so            mean_rank=4.2, var=1.8\n",
      "\n",
      "--- persm_T: 19 stable sequences in top-20 ---\n",
      "  mo,so,so,so,so            mean_rank=1.6, var=0.6\n",
      "  so,so,so,so,so            mean_rank=2.4, var=2.2\n",
      "  so,mo,so,so,so            mean_rank=2.4, var=0.2\n",
      "  so,so,mo,so,so            mean_rank=3.8, var=0.2\n",
      "  so,so,so,mo,so            mean_rank=5.2, var=0.2\n",
      "\n",
      "--- persm_F: 20 stable sequences in top-20 ---\n",
      "  so,so,so,so,so            mean_rank=1.0, var=0.0\n",
      "  so,mo,so,so,so            mean_rank=3.2, var=2.2\n",
      "  so,so,so,mo,so            mean_rank=3.6, var=1.8\n",
      "  mo,so,so,so,so            mean_rank=4.0, var=0.8\n",
      "  so,so,mo,so,so            mean_rank=4.2, var=2.6\n",
      "\n",
      "============================================================\n",
      "θ = 0.7\n",
      "============================================================\n",
      "\n",
      "--- inf_T: 20 stable sequences in top-20 ---\n",
      "  mo,mo,mo,mo,mo            mean_rank=1.4, var=0.2\n",
      "  mo,mo,mo,mo,mo            mean_rank=2.4, var=0.2\n",
      "  mo,so,mo,mo,so            mean_rank=2.6, var=1.8\n",
      "  mo,so,mo,mo,mo            mean_rank=4.0, var=0.8\n",
      "  mo,so,mo,mo,mo            mean_rank=5.4, var=1.4\n",
      "\n",
      "--- inf_F: 19 stable sequences in top-20 ---\n",
      "  mo,mo,mo,mo,mo            mean_rank=1.0, var=0.0\n",
      "  mo,mo,mo,mo,mo            mean_rank=3.2, var=0.6\n",
      "  mo,mo,mo,mo,mo            mean_rank=3.4, var=1.0\n",
      "  mo,mo,mo,mo,mo            mean_rank=3.8, var=1.4\n",
      "  mo,mo,mo,mo,mo            mean_rank=4.0, var=2.8\n",
      "\n",
      "--- persp_T: 20 stable sequences in top-20 ---\n",
      "  mo,mo,mo,so,so            mean_rank=1.8, var=1.4\n",
      "  mo,mo,so,mo,so            mean_rank=3.4, var=2.2\n",
      "  mo,mo,mo,mo,so            mean_rank=4.0, var=8.0\n",
      "  mo,mo,mo,so,mo            mean_rank=5.0, var=8.0\n",
      "  mo,mo,so,so,mo            mean_rank=5.4, var=1.0\n",
      "\n",
      "--- persp_F: 15 stable sequences in top-20 ---\n",
      "  mo,mo,mo,mo,mo            mean_rank=1.0, var=0.0\n",
      "  mo,mo,so,mo,mo            mean_rank=3.2, var=0.6\n",
      "  mo,mo,mo,mo,so            mean_rank=3.8, var=2.6\n",
      "  mo,mo,mo,so,mo            mean_rank=4.0, var=2.0\n",
      "  mo,so,mo,mo,mo            mean_rank=4.2, var=2.6\n",
      "\n",
      "--- persm_T: 16 stable sequences in top-20 ---\n",
      "  so,so,so,so,so            mean_rank=1.0, var=0.0\n",
      "  so,so,so,so,so            mean_rank=2.0, var=0.0\n",
      "  so,so,so,so,so            mean_rank=3.2, var=0.2\n",
      "  so,so,so,so,so            mean_rank=4.0, var=0.4\n",
      "  so,so,so,so,so            mean_rank=5.0, var=0.4\n",
      "\n",
      "--- persm_F: 20 stable sequences in top-20 ---\n",
      "  so,so,so,so,so            mean_rank=1.0, var=0.0\n",
      "  so,so,so,so,so            mean_rank=3.6, var=1.0\n",
      "  so,so,so,so,so            mean_rank=3.8, var=2.2\n",
      "  so,so,so,so,so            mean_rank=4.0, var=2.8\n",
      "  so,so,so,so,so            mean_rank=4.2, var=1.8\n",
      "\n",
      "======================================================================\n",
      "Part 4: Compute discrimination score for each sequence\n",
      "======================================================================\n",
      "\n",
      "Discrimination score for sequence s, target speaker A:\n",
      "  = (mean rank of s for other speakers) - (mean rank of s for speaker A)\n",
      "\n",
      "High score = sequence is good for A but bad for others = discriminating!\n",
      "\n",
      "\n",
      "--- θ = 0.5: Top discriminating sequences per speaker ---\n",
      "\n",
      "inf_T:\n",
      "  Sequence                       Disc Score   Mean Rank    Variance    \n",
      "  al,mo,no,no,mo                 13789.1      6525.6       4540995.8   \n",
      "  al,mo,no,al,mo                 13754.4      6520.8       4561518.2   \n",
      "  al,mo,al,al,mo                 13732.3      6524.8       4565836.2   \n",
      "  al,so,mo,al,al                 13720.8      6669.4       4585809.8   \n",
      "  al,mo,al,no,mo                 13719.1      6524.8       4550125.4   \n",
      "  al,so,mo,al,no                 13717.4      6668.4       4569947.8   \n",
      "  al,so,mo,no,al                 13706.5      6670.2       4565281.4   \n",
      "  al,so,mo,no,no                 13704.7      6670.6       4554706.6   \n",
      "  al,mo,al,al,mo                 13670.8      6520.4       4542101.4   \n",
      "  al,mo,al,no,mo                 13670.4      6522.4       4547390.6   \n",
      "\n",
      "inf_F:\n",
      "  Sequence                       Disc Score   Mean Rank    Variance    \n",
      "  no,al,mo,mo,mo                 17676.2      1511.0       974272.4    \n",
      "  no,al,mo,mo,mo                 17675.6      1524.4       819792.2    \n",
      "  no,no,mo,mo,mo                 17652.6      1512.4       875490.6    \n",
      "  no,no,mo,mo,mo                 17604.7      1597.4       1141202.2   \n",
      "  al,al,mo,mo,mo                 17571.2      1632.8       967737.4    \n",
      "  no,mo,al,mo,mo                 17534.0      1702.4       1004311.0   \n",
      "  al,no,mo,mo,mo                 17502.0      1662.8       1119792.2   \n",
      "  al,no,mo,mo,mo                 17493.8      1526.6       807797.0    \n",
      "  no,mo,al,mo,mo                 17413.5      1822.0       633436.4    \n",
      "  al,mo,no,mo,mo                 17383.3      1856.8       617352.6    \n",
      "\n",
      "persp_T:\n",
      "  Sequence                       Disc Score   Mean Rank    Variance    \n",
      "  al,so,so,so,no                 19143.3      1609.8       341886.2    \n",
      "  no,so,so,so,al                 19133.6      1610.4       342131.8    \n",
      "  no,so,so,so,no                 19129.7      1610.0       340449.2    \n",
      "  no,so,so,al,so                 19120.0      1631.0       348512.4    \n",
      "  al,so,so,so,al                 19119.4      1611.0       340964.8    \n",
      "  al,so,so,no,so                 19104.4      1631.8       350038.2    \n",
      "  no,so,so,no,so                 19088.2      1632.2       348453.8    \n",
      "  al,so,so,al,so                 19067.0      1630.2       348666.2    \n",
      "  no,so,al,so,so                 18977.8      1668.6       369557.8    \n",
      "  al,so,no,so,so                 18963.0      1669.0       371330.8    \n",
      "\n",
      "persp_F:\n",
      "  Sequence                       Disc Score   Mean Rank    Variance    \n",
      "  no,so,no,no,al                 22242.8      5090.2       2134485.4   \n",
      "  no,so,no,al,no                 22228.3      5102.2       2135629.4   \n",
      "  no,so,no,al,al                 22225.2      5104.2       2172785.0   \n",
      "  no,so,no,no,no                 22220.2      5090.2       2111523.8   \n",
      "  no,no,al,so,al                 22193.8      5100.4       2183547.4   \n",
      "  al,so,no,no,no                 22193.0      5090.2       2183945.0   \n",
      "  al,so,no,no,al                 22181.6      5102.6       2187109.0   \n",
      "  no,no,al,so,no                 22179.1      5105.2       2162329.8   \n",
      "  no,no,al,no,so                 22111.4      5078.6       2166949.0   \n",
      "  al,al,no,so,no                 22108.7      5103.6       2138784.6   \n",
      "\n",
      "persm_T:\n",
      "  Sequence                       Disc Score   Mean Rank    Variance    \n",
      "  al,so,so,so,no                 19105.6      1609.6       340695.8    \n",
      "  al,so,so,so,al                 19103.2      1610.6       342145.4    \n",
      "  no,so,so,so,al                 19079.0      1610.2       341347.0    \n",
      "  no,so,so,so,no                 19076.4      1610.8       341243.8    \n",
      "  no,so,so,no,so                 19058.2      1631.2       348652.6    \n",
      "  al,so,so,no,so                 19056.4      1631.6       349656.2    \n",
      "  al,so,so,al,so                 19056.0      1631.8       348615.0    \n",
      "  no,so,so,al,so                 19005.8      1630.6       348748.2    \n",
      "  no,so,no,so,so                 18929.6      1668.8       370957.8    \n",
      "  al,so,al,so,so                 18912.2      1668.8       369337.8    \n",
      "\n",
      "persm_F:\n",
      "  Sequence                       Disc Score   Mean Rank    Variance    \n",
      "  no,so,al,al,al                 22300.2      5086.4       2114040.6   \n",
      "  no,so,al,al,no                 22288.1      5094.2       2169435.0   \n",
      "  no,so,al,no,al                 22283.2      5080.8       2109078.2   \n",
      "  no,so,al,no,no                 22257.3      5095.2       2121784.2   \n",
      "  al,no,al,so,al                 22196.0      5110.8       2132001.0   \n",
      "  al,no,al,so,no                 22192.3      5113.6       2097383.4   \n",
      "  no,al,no,so,al                 22189.7      5113.8       2175498.2   \n",
      "  no,al,no,so,no                 22181.2      5112.2       2160610.2   \n",
      "  al,so,no,no,no                 22168.6      5084.0       2172029.2   \n",
      "  no,al,no,al,so                 22153.2      5096.4       2195152.2   \n",
      "\n",
      "======================================================================\n",
      "Part 5: Combined score (discrimination × stability × good rank)\n",
      "======================================================================\n",
      "\n",
      "We want sequences that are:\n",
      "  1. Highly discriminating (high disc score)\n",
      "  2. Stable across alphas (low variance)\n",
      "  3. Actually likely for the target speaker (low mean rank)\n",
      "\n",
      "Combined score = disc_score / (1 + sqrt(variance)) / (1 + log(mean_rank))\n",
      "\n",
      "\n",
      "--- θ = 0.5: Top sequences by combined score ---\n",
      "\n",
      "inf_T:\n",
      "  Sequence                       Combined   Disc       MeanRank   Var       \n",
      "  mo,mo,mo,mo,mo                 638.450    3302.4     13.8       0.2       \n",
      "  mo,mo,mo,mo,mo                 622.933    3300.9     15.2       0.2       \n",
      "  mo,so,mo,mo,mo                 589.652    2294.0     17.0       0.0       \n",
      "  mo,so,mo,mo,mo                 584.063    2303.8     18.0       0.0       \n",
      "  mo,mo,mo,mo,mo                 571.058    3006.5     11.6       0.2       \n",
      "  mo,so,mo,mo,mo                 552.297    2351.7     25.0       0.0       \n",
      "  mo,so,mo,mo,mo                 546.746    2348.7     26.0       0.0       \n",
      "  mo,mo,mo,mo,mo                 544.988    3611.0     13.6       0.6       \n",
      "  mo,mo,mo,mo,mo                 508.939    3007.1     9.8        0.6       \n",
      "  mo,mo,mo,mo,mo                 487.913    2882.9     9.8        0.6       \n",
      "\n",
      "inf_F:\n",
      "  Sequence                       Combined   Disc       MeanRank   Var       \n",
      "  mo,mo,mo,mo,mo                 279.430    4966.8     15.6       13.4      \n",
      "  mo,mo,mo,mo,mo                 242.133    2865.2     18.0       4.0       \n",
      "  mo,mo,mo,mo,mo                 235.693    3611.4     12.4       10.6      \n",
      "  mo,mo,mo,mo,mo                 234.071    7163.3     19.4       43.8      \n",
      "  mo,mo,mo,mo,mo                 196.781    7176.3     9.6        97.0      \n",
      "  mo,mo,mo,mo,mo                 166.564    3349.3     19.2       16.2      \n",
      "  mo,mo,mo,mo,mo                 156.116    4974.6     10.2       69.4      \n",
      "  mo,mo,mo,mo,mo                 143.542    3595.6     26.8       23.0      \n",
      "  mo,mo,mo,mo,mo                 141.570    3780.5     16.0       35.6      \n",
      "  mo,mo,mo,mo,mo                 126.756    4434.9     12.4       76.2      \n",
      "\n",
      "persp_T:\n",
      "  Sequence                       Combined   Disc       MeanRank   Var       \n",
      "  so,mo,so,so,so                 2423.901   8030.9     2.4        0.2       \n",
      "  so,so,mo,so,so                 2307.023   8296.2     3.8        0.2       \n",
      "  mo,so,so,so,so                 2279.076   8022.2     1.6        0.6       \n",
      "  so,so,so,mo,so                 2138.765   8457.5     5.2        0.2       \n",
      "  so,so,so,so,so                 1764.800   9798.2     2.4        2.2       \n",
      "  so,so,so,so,mo                 1077.031   8552.4     6.8        2.6       \n",
      "  so,mo,so,so,mo                 681.794    6266.0     14.2       2.2       \n",
      "  so,mo,so,mo,so                 584.268    6579.3     13.6       4.2       \n",
      "  so,mo,mo,so,so                 450.209    6783.0     13.2       9.8       \n",
      "  mo,so,so,so,mo                 411.804    6292.6     12.0       10.8      \n",
      "\n",
      "persp_F:\n",
      "  Sequence                       Combined   Disc       MeanRank   Var       \n",
      "  so,so,so,so,so                 5787.939   9799.8     1.0        0.0       \n",
      "  so,so,so,mo,so                 1603.797   8459.8     3.2        1.4       \n",
      "  so,mo,so,so,so                 1459.836   8028.3     4.6        1.0       \n",
      "  so,so,mo,so,so                 1307.787   8296.2     3.8        2.2       \n",
      "  mo,so,so,so,so                 1301.279   8019.1     4.2        1.8       \n",
      "  mo,so,so,so,mo                 1283.868   6293.5     11.2       0.2       \n",
      "  so,so,so,so,mo                 1242.346   8555.4     4.2        2.6       \n",
      "  so,so,so,so,so                 1173.575   9334.9     33.8       0.6       \n",
      "  so,so,so,so,so                 1019.544   9461.5     35.4       1.0       \n",
      "  mo,mo,mo,mo,so                 1013.548   6615.7     28.4       0.2       \n",
      "\n",
      "persm_T:\n",
      "  Sequence                       Combined   Disc       MeanRank   Var       \n",
      "  so,mo,so,so,so                 2421.286   8022.2     2.4        0.2       \n",
      "  so,so,mo,so,so                 2309.294   8304.4     3.8        0.2       \n",
      "  mo,so,so,so,so                 2276.046   8011.5     1.6        0.6       \n",
      "  so,so,so,mo,so                 2139.735   8461.3     5.2        0.2       \n",
      "  so,so,so,so,so                 1765.148   9800.1     2.4        2.2       \n",
      "  so,so,so,so,mo                 1077.635   8557.2     6.8        2.6       \n",
      "  so,mo,so,so,mo                 683.586    6282.5     14.2       2.2       \n",
      "  so,mo,so,mo,so                 586.109    6600.0     13.6       4.2       \n",
      "  so,mo,mo,so,so                 450.674    6790.0     13.2       9.8       \n",
      "  mo,so,so,so,mo                 410.401    6271.2     12.0       10.8      \n",
      "\n",
      "persm_F:\n",
      "  Sequence                       Combined   Disc       MeanRank   Var       \n",
      "  so,so,so,so,so                 5789.081   9801.8     1.0        0.0       \n",
      "  mo,so,so,so,so                 1620.083   8008.7     4.0        0.8       \n",
      "  so,so,so,so,mo                 1618.387   8559.3     5.0        0.8       \n",
      "  so,so,so,mo,so                 1421.768   8463.2     3.6        1.8       \n",
      "  so,mo,so,so,so                 1333.785   8021.3     3.2        2.2       \n",
      "  so,so,mo,so,so                 1205.821   8303.9     4.2        2.6       \n",
      "  so,so,so,so,so                 982.698    9438.3     35.0       1.2       \n",
      "  so,so,so,so,so                 893.173    9272.3     35.0       1.6       \n",
      "  so,so,so,so,so                 834.480    9457.6     35.2       2.2       \n",
      "  mo,mo,mo,mo,so                 825.503    6607.5     30.4       0.6       \n",
      "\n",
      "======================================================================\n",
      "Part 6: PSI-level discrimination (inf vs persp vs persm)\n",
      "======================================================================\n",
      "\n",
      "Now treating inf_T and inf_F as one \"inf\" model, etc.\n",
      "Find sequences that discriminate between PSI types.\n",
      "\n",
      "\n",
      "--- θ = 0.5: Top PSI-discriminating sequences ---\n",
      "\n",
      "INF:\n",
      "  Sequence                       PSI Disc     inf rank     persp rank   persm rank  \n",
      "  al,no,mo,no,mo                 16583.1      6812.8       21345.8      22586.8     \n",
      "  al,no,mo,al,mo                 16518.6      6855.9       21336.7      22560.8     \n",
      "  al,no,mo,mo,al                 16510.5      6845.6       21369.8      22434.6     \n",
      "  al,no,mo,mo,no                 16506.0      6852.7       21381.1      22433.9     \n",
      "  al,no,mo,mo,no                 16492.3      6833.3       21462.1      22322.8     \n",
      "  al,no,mo,mo,al                 16484.4      6843.6       21466.1      22322.9     \n",
      "  al,al,no,mo,mo                 16463.4      6555.7       23816.0      19524.3     \n",
      "  al,al,mo,mo,al                 16436.4      6873.3       25532.1      18665.9     \n",
      "  al,mo,al,al,mo                 16427.4      6865.5       21145.8      22912.0     \n",
      "  al,al,mo,al,mo                 16421.9      6909.0       25648.6      18609.1     \n",
      "\n",
      "PERSP:\n",
      "  Sequence                       PSI Disc     inf rank     persp rank   persm rank  \n",
      "  no,so,so,al,al                 22563.8      30544.4      4295.3       31316.0     \n",
      "  no,so,so,al,no                 22550.7      30555.7      4296.3       31314.3     \n",
      "  no,so,so,no,no                 22541.9      30496.0      4290.1       31317.1     \n",
      "  no,so,so,no,al                 22538.8      30502.7      4294.3       31316.6     \n",
      "  al,so,al,so,no                 22524.6      30425.0      4323.4       31334.0     \n",
      "  no,so,no,so,al                 22516.3      30246.9      4326.4       31344.2     \n",
      "  no,so,no,so,no                 22511.5      30239.9      4324.5       31342.1     \n",
      "  al,so,al,so,al                 22496.8      30348.5      4327.6       31336.7     \n",
      "  no,so,al,so,no                 22464.5      30202.1      4332.1       31329.8     \n",
      "  no,so,al,so,al                 22454.8      30168.8      4331.5       31335.1     \n",
      "\n",
      "PERSM:\n",
      "  Sequence                       PSI Disc     inf rank     persp rank   persm rank  \n",
      "  al,no,so,so,no                 22331.0      30113.0      31378.8      4365.3      \n",
      "  no,so,al,so,al                 22316.1      30650.8      31348.4      4327.0      \n",
      "  no,so,al,so,no                 22312.8      30649.6      31343.8      4328.0      \n",
      "  al,no,so,so,al                 22310.4      30098.7      31379.1      4380.2      \n",
      "  no,no,so,so,no                 22267.5      29888.5      31383.5      4368.8      \n",
      "  no,so,so,al,no                 22265.8      30886.6      31313.1      4285.4      \n",
      "  no,no,so,so,al                 22258.8      29871.0      31384.7      4372.4      \n",
      "  no,so,so,al,al                 22253.4      30860.4      31316.6      4289.9      \n",
      "  no,so,so,no,no                 22224.7      30844.9      31318.7      4288.8      \n",
      "  no,so,al,no,so                 22223.4      30439.2      31346.9      4354.6      \n",
      "\n",
      "======================================================================\n",
      "Part 7: Sequences that discriminate BETWEEN all PSI types\n",
      "======================================================================\n",
      "\n",
      "Find sequences where inf, persp, and persm have VERY DIFFERENT ranks.\n",
      "Metric: variance of ranks across the three PSI types (higher = more discriminating)\n",
      "\n",
      "\n",
      "--- θ = 0.3 ---\n",
      "  Sequence                            Rank Var     inf      persp    persm   \n",
      "  mo,al,no,al,al                      201593151    1825     32338    2629    \n",
      "  mo,no,no,no,al                      201531863    1834     32333    2618    \n",
      "  mo,no,no,no,no                      201526549    1832     32332    2620    \n",
      "  mo,no,no,al,al                      201524252    1835     32331    2614    \n",
      "  mo,no,al,al,no                      201514074    1835     32335    2624    \n",
      "  mo,al,no,no,al                      201476845    1825     32330    2630    \n",
      "  mo,al,no,no,no                      201473856    1833     32334    2629    \n",
      "  mo,no,al,no,no                      201467272    1834     32334    2630    \n",
      "  mo,no,no,al,no                      201444522    1826     32327    2628    \n",
      "  mo,no,al,al,al                      201441324    1835     32332    2629    \n",
      "  mo,al,al,al,al                      201432056    1832     32332    2632    \n",
      "  mo,al,al,al,no                      201428312    1834     32332    2632    \n",
      "  mo,al,al,no,no                      201427834    1834     32332    2631    \n",
      "  mo,al,no,al,no                      201416490    1834     32330    2630    \n",
      "  mo,no,al,no,al                      201362463    1837     32328    2629    \n",
      "\n",
      "--- θ = 0.5 ---\n",
      "  Sequence                            Rank Var     inf      persp    persm   \n",
      "  no,so,so,no,so                      174844447    30906    1262     27385   \n",
      "  no,so,so,al,so                      174707215    30882    1259     27387   \n",
      "  al,so,so,no,so                      174648863    30865    1254     27388   \n",
      "  no,so,so,so,al                      174143628    30863    1245     27266   \n",
      "  al,so,so,so,no                      174100729    30858    1245     27265   \n",
      "  al,so,so,al,so                      174068071    30790    27386    1256    \n",
      "  no,so,so,so,no                      174059412    30852    1245     27265   \n",
      "  al,so,so,no,so                      173958848    30777    27387    1258    \n",
      "  no,so,no,so,so                      173791946    30714    1275     27488   \n",
      "  al,so,so,al,so                      173719942    30736    1253     27388   \n",
      "  al,so,so,so,al                      173645811    30795    1244     27264   \n",
      "  al,so,so,so,al                      173556441    30784    27262    1244    \n",
      "  al,so,so,so,no                      173508788    30780    27266    1247    \n",
      "  no,so,al,so,so                      173430061    30674    1280     27485   \n",
      "  al,so,al,so,so                      173400457    30663    27486    1276    \n",
      "\n",
      "--- θ = 0.7 ---\n",
      "  Sequence                            Rank Var     inf      persp    persm   \n",
      "  mo,no,no,no,no                      201610880    1829     2624     32339   \n",
      "  mo,no,no,al,no                      201602519    1824     2626     32337   \n",
      "  mo,no,no,al,al                      201589143    1831     2627     32340   \n",
      "  mo,no,al,al,no                      201581846    1837     2623     32341   \n",
      "  mo,no,al,no,no                      201574481    1834     2629     32342   \n",
      "  mo,no,no,no,al                      201562403    1835     2624     32339   \n",
      "  mo,al,no,no,no                      201538285    1829     2630     32337   \n",
      "  mo,no,al,al,al                      201522512    1839     2622     32337   \n",
      "  mo,al,no,no,al                      201516180    1828     2630     32335   \n",
      "  mo,al,al,no,al                      201507617    1829     2633     32336   \n",
      "  mo,al,al,al,al                      201506079    1834     2627     32336   \n",
      "  mo,al,al,al,no                      201505383    1834     2627     32335   \n",
      "  mo,al,no,al,no                      201485785    1834     2632     32336   \n",
      "  mo,no,al,no,al                      201473537    1836     2630     32335   \n",
      "  mo,al,no,al,al                      201466434    1840     2630     32337   \n",
      "\n",
      "======================================================================\n",
      "Part 8: Summary - Best discriminating sequences for each theta\n",
      "======================================================================\n",
      "\n",
      "For each theta, show the TOP 5 sequences that maximize rank variance across PSI types.\n",
      "These are sequences where the three PSI models disagree most about likelihood.\n",
      "\n",
      "\n",
      "θ = 0.0:\n",
      "  1. so,so,so,so,so                 var=232562  inf=1024 persp=1 persm=1024\n",
      "  2. so,so,so,so,mo                 var=231132  inf=1022 persp=2 persm=1022\n",
      "  3. so,so,so,mo,so                 var=230272  inf=1022 persp=4 persm=1022\n",
      "  4. so,so,mo,so,so                 var=229232  inf=1020 persp=4 persm=1019\n",
      "  5. so,mo,so,so,so                 var=228061  inf=1019 persp=5 persm=1017\n",
      "\n",
      "θ = 0.1:\n",
      "  1. no,al,no,no,al                 var=191170322  inf=246 persp=29825 persm=750\n",
      "  2. no,al,no,no,no                 var=191104921  inf=250 persp=29824 persm=753\n",
      "  3. al,al,no,al,no                 var=191064257  inf=252 persp=29822 persm=753\n",
      "  4. al,al,no,al,al                 var=191037328  inf=253 persp=29820 persm=752\n",
      "  5. no,no,no,no,no                 var=191036929  inf=252 persp=29822 persm=757\n",
      "\n",
      "θ = 0.2:\n",
      "  1. no,no,al,no,al                 var=209198209  inf=1224 persp=32330 persm=2090\n",
      "  2. al,al,al,no,no                 var=209197446  inf=1226 persp=32328 persm=2084\n",
      "  3. no,no,no,al,al                 var=209182703  inf=1226 persp=32327 persm=2083\n",
      "  4. no,no,al,no,no                 var=209182004  inf=1223 persp=32326 persm=2084\n",
      "  5. no,no,no,al,no                 var=209180856  inf=1230 persp=32326 persm=2078\n",
      "\n",
      "θ = 0.3:\n",
      "  1. mo,al,no,al,al                 var=201593151  inf=1825 persp=32338 persm=2629\n",
      "  2. mo,no,no,no,al                 var=201531863  inf=1834 persp=32333 persm=2618\n",
      "  3. mo,no,no,no,no                 var=201526549  inf=1832 persp=32332 persm=2620\n",
      "  4. mo,no,no,al,al                 var=201524252  inf=1835 persp=32331 persm=2614\n",
      "  5. mo,no,al,al,no                 var=201514074  inf=1835 persp=32335 persm=2624\n",
      "\n",
      "θ = 0.4:\n",
      "  1. mo,mo,no,al,no                 var=187228237  inf=2771 persp=31697 persm=2571\n",
      "  2. mo,mo,al,al,no                 var=187222220  inf=2773 persp=31695 persm=2567\n",
      "  3. mo,mo,no,al,al                 var=187202331  inf=2771 persp=31696 persm=2573\n",
      "  4. mo,mo,no,no,al                 var=187200896  inf=2771 persp=31697 persm=2575\n",
      "  5. mo,mo,al,no,no                 var=187189834  inf=2774 persp=31694 persm=2569\n",
      "\n",
      "θ = 0.5:\n",
      "  1. no,so,so,no,so                 var=174844447  inf=30906 persp=1262 persm=27385\n",
      "  2. no,so,so,al,so                 var=174707215  inf=30882 persp=1259 persm=27387\n",
      "  3. al,so,so,no,so                 var=174648863  inf=30865 persp=1254 persm=27388\n",
      "  4. no,so,so,so,al                 var=174143628  inf=30863 persp=1245 persm=27266\n",
      "  5. al,so,so,so,no                 var=174100729  inf=30858 persp=1245 persm=27265\n",
      "\n",
      "θ = 0.6:\n",
      "  1. mo,mo,al,no,al                 var=187388195  inf=2770 persp=2571 persm=31709\n",
      "  2. mo,mo,al,al,no                 var=187346506  inf=2767 persp=2573 persm=31705\n",
      "  3. mo,mo,al,al,al                 var=187324896  inf=2769 persp=2571 persm=31703\n",
      "  4. mo,mo,al,no,no                 var=187310860  inf=2770 persp=2579 persm=31707\n",
      "  5. mo,mo,no,al,no                 var=187293080  inf=2770 persp=2574 persm=31703\n",
      "\n",
      "θ = 0.7:\n",
      "  1. mo,no,no,no,no                 var=201610880  inf=1829 persp=2624 persm=32339\n",
      "  2. mo,no,no,al,no                 var=201602519  inf=1824 persp=2626 persm=32337\n",
      "  3. mo,no,no,al,al                 var=201589143  inf=1831 persp=2627 persm=32340\n",
      "  4. mo,no,al,al,no                 var=201581846  inf=1837 persp=2623 persm=32341\n",
      "  5. mo,no,al,no,no                 var=201574481  inf=1834 persp=2629 persm=32342\n",
      "\n",
      "θ = 0.8:\n",
      "  1. no,no,no,al,no                 var=209369021  inf=1214 persp=2071 persm=32328\n",
      "  2. no,al,no,no,no                 var=209269812  inf=1226 persp=2079 persm=32331\n",
      "  3. al,no,no,al,no                 var=209268817  inf=1223 persp=2076 persm=32328\n",
      "  4. no,al,al,al,no                 var=209267852  inf=1222 persp=2076 persm=32327\n",
      "  5. no,no,al,no,al                 var=209264789  inf=1221 persp=2079 persm=32328\n",
      "\n",
      "θ = 0.9:\n",
      "  1. al,al,no,al,no                 var=191131649  inf=241 persp=755 persm=29822\n",
      "  2. al,al,no,no,no                 var=191127397  inf=242 persp=754 persm=29821\n",
      "  3. al,al,no,no,al                 var=191122287  inf=242 persp=755 persm=29822\n",
      "  4. al,no,al,al,no                 var=191116452  inf=248 persp=746 persm=29820\n",
      "  5. no,al,no,no,no                 var=191093493  inf=251 persp=752 persm=29823\n",
      "\n",
      "θ = 1.0:\n",
      "  1. so,al,no,mo,so                 var=103238870  inf=5951 persp=5951 persm=27505\n",
      "  2. so,al,no,mo,mo                 var=103238870  inf=5953 persp=5953 persm=27507\n",
      "  3. so,al,no,mo,mo                 var=103238870  inf=5954 persp=5954 persm=27508\n",
      "  4. so,al,no,mo,al                 var=103238870  inf=5955 persp=5955 persm=27509\n",
      "  5. so,al,no,mo,al                 var=103238870  inf=5956 persp=5956 persm=27510\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import itertools\n",
    "\n",
    "# =============================================================================\n",
    "# DISCRIMINATION ANALYSIS: High within-speaker, low between-speaker stability\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINDING DISCRIMINATING SEQUENCES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Goal: Find sequences that are:\n",
    "  - STABLE within a speaker type (across alphas) → characteristic\n",
    "  - UNSTABLE between speaker types → discriminating\n",
    "\"\"\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def compute_ranks(P):\n",
    "    \"\"\"Convert probabilities to ranks (1 = highest probability).\"\"\"\n",
    "    return (-P).argsort().argsort() + 1\n",
    "\n",
    "def get_top_k_set(P, k):\n",
    "    \"\"\"Get set of indices in top-k by probability.\"\"\"\n",
    "    return set(np.argsort(-P)[:k])\n",
    "\n",
    "# Mid-range alphas for stability assessment\n",
    "mid_alphas = [5.482, 6.988, 8.909, 11.36, 14.48]\n",
    "\n",
    "# All speaker types (excluding literal for now, or include it)\n",
    "speaker_types = ['literal', 'inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']\n",
    "# For psi-level analysis\n",
    "psi_speakers = {\n",
    "    'inf': ['inf_T', 'inf_F'],\n",
    "    'persp': ['persp_T', 'persp_F'],\n",
    "    'persm': ['persm_T', 'persm_F']\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 1: For each (theta, speaker), compute mean rank across mid-alphas\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 1: Compute mean rank across mid-alphas for each sequence\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# For each theta, create a DataFrame with mean rank per speaker\n",
    "# Shape: (n_sequences, n_speakers) for each theta\n",
    "\n",
    "mean_ranks_by_theta = {}\n",
    "\n",
    "for theta in theta_values:\n",
    "    mean_ranks = {}\n",
    "    \n",
    "    for speaker in speaker_types:\n",
    "        if speaker == 'literal':\n",
    "            # Literal has no alpha\n",
    "            P = get_P_seq_for_theta('literal', theta, alpha=None)\n",
    "            ranks = compute_ranks(P)\n",
    "            mean_ranks[speaker] = ranks.astype(float)  # Just one \"alpha\"\n",
    "        else:\n",
    "            # Average rank across mid-alphas\n",
    "            all_ranks = []\n",
    "            for alpha in mid_alphas:\n",
    "                P = get_P_seq_for_theta(speaker, theta, alpha=alpha)\n",
    "                ranks = compute_ranks(P)\n",
    "                all_ranks.append(ranks)\n",
    "            mean_ranks[speaker] = np.mean(all_ranks, axis=0)\n",
    "    \n",
    "    mean_ranks_by_theta[theta] = pd.DataFrame(mean_ranks)\n",
    "\n",
    "print(f\"Computed mean ranks for {len(theta_values)} theta values\")\n",
    "print(f\"Shape per theta: {mean_ranks_by_theta[0.5].shape}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 2: For each (theta, speaker), compute rank VARIANCE across mid-alphas\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 2: Compute rank variance (stability) across mid-alphas\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Low variance = high stability within speaker\n",
    "\n",
    "rank_variance_by_theta = {}\n",
    "\n",
    "for theta in theta_values:\n",
    "    rank_vars = {}\n",
    "    \n",
    "    for speaker in speaker_types:\n",
    "        if speaker == 'literal':\n",
    "            # No variance for literal\n",
    "            rank_vars[speaker] = np.zeros(n_sequences)\n",
    "        else:\n",
    "            all_ranks = []\n",
    "            for alpha in mid_alphas:\n",
    "                P = get_P_seq_for_theta(speaker, theta, alpha=alpha)\n",
    "                ranks = compute_ranks(P)\n",
    "                all_ranks.append(ranks)\n",
    "            rank_vars[speaker] = np.var(all_ranks, axis=0)\n",
    "    \n",
    "    rank_variance_by_theta[theta] = pd.DataFrame(rank_vars)\n",
    "\n",
    "print(\"Computed rank variance for each theta\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 3: Find sequences with HIGH within-speaker stability, LOW mean rank\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 3: Sequences characteristic of each speaker (stable & top-ranked)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def find_characteristic_sequences(theta, speaker, top_k=50, max_variance=100):\n",
    "    \"\"\"\n",
    "    Find sequences that are:\n",
    "    - In top-k by mean rank for this speaker\n",
    "    - Have low variance across alphas (stable)\n",
    "    \"\"\"\n",
    "    mean_rank = mean_ranks_by_theta[theta][speaker].values\n",
    "    variance = rank_variance_by_theta[theta][speaker].values\n",
    "    \n",
    "    # Candidates: top-k by mean rank\n",
    "    top_k_idx = np.argsort(mean_rank)[:top_k]\n",
    "    \n",
    "    # Filter by variance\n",
    "    stable_idx = [idx for idx in top_k_idx if variance[idx] <= max_variance]\n",
    "    \n",
    "    return stable_idx, mean_rank, variance\n",
    "\n",
    "# For each theta, for each speaker, show characteristic sequences\n",
    "for theta in [0.3, 0.5, 0.7]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"θ = {theta}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for speaker in ['inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']:\n",
    "        stable_idx, mean_rank, variance = find_characteristic_sequences(theta, speaker, top_k=20, max_variance=50)\n",
    "        \n",
    "        print(f\"\\n--- {speaker}: {len(stable_idx)} stable sequences in top-20 ---\")\n",
    "        if len(stable_idx) > 0:\n",
    "            for idx in stable_idx[:5]:  # Show top 5\n",
    "                seq = sequence_labels[idx]\n",
    "                abbrev = \",\".join([u.split(\",\")[0][:2] for u in seq])\n",
    "                print(f\"  {abbrev:<25} mean_rank={mean_rank[idx]:.1f}, var={variance[idx]:.1f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 4: For each sequence, compute \"discrimination score\"\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 4: Compute discrimination score for each sequence\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Discrimination score for sequence s, target speaker A:\n",
    "  = (mean rank of s for other speakers) - (mean rank of s for speaker A)\n",
    "  \n",
    "High score = sequence is good for A but bad for others = discriminating!\n",
    "\"\"\")\n",
    "\n",
    "def compute_discrimination_scores(theta):\n",
    "    \"\"\"\n",
    "    For each sequence and each speaker, compute how much better \n",
    "    this sequence ranks for that speaker vs others.\n",
    "    \"\"\"\n",
    "    mean_ranks = mean_ranks_by_theta[theta]\n",
    "    \n",
    "    scores = {}\n",
    "    for target_speaker in speaker_types:\n",
    "        target_rank = mean_ranks[target_speaker].values\n",
    "        other_speakers = [s for s in speaker_types if s != target_speaker]\n",
    "        other_ranks = mean_ranks[other_speakers].values  # (n_seq, n_other)\n",
    "        mean_other_rank = np.mean(other_ranks, axis=1)\n",
    "        \n",
    "        # Discrimination = how much worse others rank this sequence\n",
    "        scores[target_speaker] = mean_other_rank - target_rank\n",
    "    \n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "# Compute for selected thetas\n",
    "discrimination_by_theta = {}\n",
    "for theta in theta_values:\n",
    "    discrimination_by_theta[theta] = compute_discrimination_scores(theta)\n",
    "\n",
    "# Show top discriminating sequences for each speaker at θ = 0.5\n",
    "theta = 0.5\n",
    "print(f\"\\n--- θ = {theta}: Top discriminating sequences per speaker ---\")\n",
    "\n",
    "disc_df = discrimination_by_theta[theta]\n",
    "mean_ranks = mean_ranks_by_theta[theta]\n",
    "rank_vars = rank_variance_by_theta[theta]\n",
    "\n",
    "for speaker in ['inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']:\n",
    "    print(f\"\\n{speaker}:\")\n",
    "    \n",
    "    # Get top 10 by discrimination score\n",
    "    top_disc_idx = np.argsort(-disc_df[speaker].values)[:10]\n",
    "    \n",
    "    print(f\"  {'Sequence':<30} {'Disc Score':<12} {'Mean Rank':<12} {'Variance':<12}\")\n",
    "    for idx in top_disc_idx:\n",
    "        seq = sequence_labels[idx]\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] for u in seq])\n",
    "        disc = disc_df[speaker].values[idx]\n",
    "        mr = mean_ranks[speaker].values[idx]\n",
    "        var = rank_vars[speaker].values[idx]\n",
    "        print(f\"  {abbrev:<30} {disc:<12.1f} {mr:<12.1f} {var:<12.1f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 5: Combined score: discrimination + stability + good rank\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 5: Combined score (discrimination × stability × good rank)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "We want sequences that are:\n",
    "  1. Highly discriminating (high disc score)\n",
    "  2. Stable across alphas (low variance)\n",
    "  3. Actually likely for the target speaker (low mean rank)\n",
    "  \n",
    "Combined score = disc_score / (1 + sqrt(variance)) / (1 + log(mean_rank))\n",
    "\"\"\")\n",
    "\n",
    "def compute_combined_scores(theta):\n",
    "    \"\"\"Compute combined discrimination-stability-rank score.\"\"\"\n",
    "    disc_df = discrimination_by_theta[theta]\n",
    "    mean_ranks = mean_ranks_by_theta[theta]\n",
    "    rank_vars = rank_variance_by_theta[theta]\n",
    "    \n",
    "    combined = {}\n",
    "    for speaker in speaker_types:\n",
    "        disc = disc_df[speaker].values\n",
    "        mr = mean_ranks[speaker].values\n",
    "        var = rank_vars[speaker].values\n",
    "        \n",
    "        # Combined score (higher is better)\n",
    "        # Reward: high discrimination, low variance, low mean rank\n",
    "        combined[speaker] = disc / (1 + np.sqrt(var)) / (1 + np.log1p(mr))\n",
    "    \n",
    "    return pd.DataFrame(combined)\n",
    "\n",
    "# Show for θ = 0.5\n",
    "theta = 0.5\n",
    "combined_df = compute_combined_scores(theta)\n",
    "\n",
    "print(f\"\\n--- θ = {theta}: Top sequences by combined score ---\")\n",
    "\n",
    "for speaker in ['inf_T', 'inf_F', 'persp_T', 'persp_F', 'persm_T', 'persm_F']:\n",
    "    print(f\"\\n{speaker}:\")\n",
    "    \n",
    "    top_idx = np.argsort(-combined_df[speaker].values)[:10]\n",
    "    \n",
    "    disc_df = discrimination_by_theta[theta]\n",
    "    mean_ranks = mean_ranks_by_theta[theta]\n",
    "    rank_vars = rank_variance_by_theta[theta]\n",
    "    \n",
    "    print(f\"  {'Sequence':<30} {'Combined':<10} {'Disc':<10} {'MeanRank':<10} {'Var':<10}\")\n",
    "    for idx in top_idx:\n",
    "        seq = sequence_labels[idx]\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] for u in seq])\n",
    "        comb = combined_df[speaker].values[idx]\n",
    "        disc = disc_df[speaker].values[idx]\n",
    "        mr = mean_ranks[speaker].values[idx]\n",
    "        var = rank_vars[speaker].values[idx]\n",
    "        print(f\"  {abbrev:<30} {comb:<10.3f} {disc:<10.1f} {mr:<10.1f} {var:<10.1f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 6: PSI-level analysis (collapsing T and F)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 6: PSI-level discrimination (inf vs persp vs persm)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Now treating inf_T and inf_F as one \"inf\" model, etc.\n",
    "Find sequences that discriminate between PSI types.\n",
    "\"\"\")\n",
    "\n",
    "def compute_psi_mean_rank(theta, psi):\n",
    "    \"\"\"Average mean rank across T and F variants.\"\"\"\n",
    "    speakers = psi_speakers[psi]\n",
    "    ranks = [mean_ranks_by_theta[theta][s].values for s in speakers]\n",
    "    return np.mean(ranks, axis=0)\n",
    "\n",
    "def compute_psi_discrimination(theta):\n",
    "    \"\"\"Discrimination scores at PSI level.\"\"\"\n",
    "    psi_ranks = {psi: compute_psi_mean_rank(theta, psi) for psi in ['inf', 'persp', 'persm']}\n",
    "    \n",
    "    # Also include literal\n",
    "    psi_ranks['literal'] = mean_ranks_by_theta[theta]['literal'].values\n",
    "    \n",
    "    scores = {}\n",
    "    for target in ['literal', 'inf', 'persp', 'persm']:\n",
    "        target_rank = psi_ranks[target]\n",
    "        others = [p for p in ['literal', 'inf', 'persp', 'persm'] if p != target]\n",
    "        other_ranks = np.array([psi_ranks[p] for p in others])\n",
    "        mean_other = np.mean(other_ranks, axis=0)\n",
    "        scores[target] = mean_other - target_rank\n",
    "    \n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "# Show PSI-level discrimination for θ = 0.5\n",
    "theta = 0.5\n",
    "psi_disc = compute_psi_discrimination(theta)\n",
    "\n",
    "print(f\"\\n--- θ = {theta}: Top PSI-discriminating sequences ---\")\n",
    "\n",
    "for psi in ['inf', 'persp', 'persm']:\n",
    "    print(f\"\\n{psi.upper()}:\")\n",
    "    \n",
    "    top_idx = np.argsort(-psi_disc[psi].values)[:10]\n",
    "    \n",
    "    print(f\"  {'Sequence':<30} {'PSI Disc':<12} {'inf rank':<12} {'persp rank':<12} {'persm rank':<12}\")\n",
    "    for idx in top_idx:\n",
    "        seq = sequence_labels[idx]\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] for u in seq])\n",
    "        disc = psi_disc[psi].values[idx]\n",
    "        inf_r = compute_psi_mean_rank(theta, 'inf')[idx]\n",
    "        persp_r = compute_psi_mean_rank(theta, 'persp')[idx]\n",
    "        persm_r = compute_psi_mean_rank(theta, 'persm')[idx]\n",
    "        print(f\"  {abbrev:<30} {disc:<12.1f} {inf_r:<12.1f} {persp_r:<12.1f} {persm_r:<12.1f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 7: Find \"maximally discriminating\" sets of sequences\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 7: Sequences that discriminate BETWEEN all PSI types\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Find sequences where inf, persp, and persm have VERY DIFFERENT ranks.\n",
    "Metric: variance of ranks across the three PSI types (higher = more discriminating)\n",
    "\"\"\")\n",
    "\n",
    "def compute_psi_rank_variance(theta):\n",
    "    \"\"\"For each sequence, compute variance of ranks across PSI types.\"\"\"\n",
    "    psi_ranks = np.array([\n",
    "        compute_psi_mean_rank(theta, 'inf'),\n",
    "        compute_psi_mean_rank(theta, 'persp'),\n",
    "        compute_psi_mean_rank(theta, 'persm')\n",
    "    ])  # (3, n_sequences)\n",
    "    \n",
    "    return np.var(psi_ranks, axis=0)\n",
    "\n",
    "for theta in [0.3, 0.5, 0.7]:\n",
    "    print(f\"\\n--- θ = {theta} ---\")\n",
    "    \n",
    "    psi_var = compute_psi_rank_variance(theta)\n",
    "    \n",
    "    # Top sequences by PSI rank variance\n",
    "    top_idx = np.argsort(-psi_var)[:15]\n",
    "    \n",
    "    print(f\"  {'Sequence':<35} {'Rank Var':<12} {'inf':<8} {'persp':<8} {'persm':<8}\")\n",
    "    for idx in top_idx:\n",
    "        seq = sequence_labels[idx]\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] for u in seq])\n",
    "        var = psi_var[idx]\n",
    "        inf_r = compute_psi_mean_rank(theta, 'inf')[idx]\n",
    "        persp_r = compute_psi_mean_rank(theta, 'persp')[idx]\n",
    "        persm_r = compute_psi_mean_rank(theta, 'persm')[idx]\n",
    "        print(f\"  {abbrev:<35} {var:<12.0f} {inf_r:<8.0f} {persp_r:<8.0f} {persm_r:<8.0f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 8: Summary table of best discriminating sequences per theta\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 8: Summary - Best discriminating sequences for each theta\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "For each theta, show the TOP 5 sequences that maximize rank variance across PSI types.\n",
    "These are sequences where the three PSI models disagree most about likelihood.\n",
    "\"\"\")\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for theta in theta_values:\n",
    "    psi_var = compute_psi_rank_variance(theta)\n",
    "    top_idx = np.argsort(-psi_var)[:5]\n",
    "    \n",
    "    for rank, idx in enumerate(top_idx, 1):\n",
    "        seq = sequence_labels[idx]\n",
    "        summary_data.append({\n",
    "            'theta': theta,\n",
    "            'rank': rank,\n",
    "            'sequence': seq,\n",
    "            'psi_var': psi_var[idx],\n",
    "            'inf_rank': compute_psi_mean_rank(theta, 'inf')[idx],\n",
    "            'persp_rank': compute_psi_mean_rank(theta, 'persp')[idx],\n",
    "            'persm_rank': compute_psi_mean_rank(theta, 'persm')[idx]\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display nicely\n",
    "for theta in theta_values:\n",
    "    subset = summary_df[summary_df['theta'] == theta]\n",
    "    print(f\"\\nθ = {theta}:\")\n",
    "    for _, row in subset.iterrows():\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] for u in row['sequence']])\n",
    "        print(f\"  {row['rank']}. {abbrev:<30} var={row['psi_var']:.0f}  inf={row['inf_rank']:.0f} persp={row['persp_rank']:.0f} persm={row['persm_rank']:.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796ccb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30d6d205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kangke/projects/prag_net/data/prag_net_listener_n1/rsa_optimal_exp_core.py:2049: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  Returns P(theta) \\propto exp( sum_{psi, alpha} log_joint(theta,psi,alpha) ).\n",
      "/Users/kangke/projects/prag_net/data/prag_net_listener_n1/rsa_optimal_exp_core.py:2062: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  Returns P(psi) \\propto exp( sum_{theta, alpha} log_joint(theta,psi,alpha) ).\n",
      "/Users/kangke/projects/prag_net/data/prag_net_listener_n1/rsa_optimal_exp_core.py:2072: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  Returns P(alpha) \\propto exp( sum_{theta, psi} log_joint(theta,psi,alpha)).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPLETE SELF-CONTAINED DISCRIMINATION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PART A: Computing P(seq | θ, speaker, α) matrices\n",
      "======================================================================\n",
      "\n",
      "--- A1: Creating World ---\n",
      "Utterances (8): ['all,successful', 'all,unsuccessful', 'most,successful', 'most,unsuccessful', 'some,successful', 'some,unsuccessful', 'no,successful', 'no,unsuccessful']\n",
      "Theta values (11): [np.float64(0.0), np.float64(0.1), np.float64(0.2), np.float64(0.3), np.float64(0.4), np.float64(0.5), np.float64(0.6), np.float64(0.7), np.float64(0.8), np.float64(0.9), np.float64(1.0)]\n",
      "Alpha values: [5.482, 6.988, 8.909, 11.36, 14.48]\n",
      "Sequences: 32768\n",
      "Rounds: 5\n",
      "\n",
      "--- A2: Defining helper functions ---\n",
      "Helper functions defined.\n",
      "\n",
      "--- A3: Computing log P(seq | θ) matrices ---\n",
      "\n",
      "Literal speaker...\n",
      "  Done.\n",
      "\n",
      "Pragmatic speakers (update_internal=False)...\n",
      "  inf_F...\n",
      "  persp_F...\n",
      "  persm_F...\n",
      "\n",
      "Pragmatic speakers (update_internal=True)...\n",
      "  inf_T...\n",
      "  persp_T...\n",
      "  persm_T...\n",
      "\n",
      "Total matrices computed: 31\n",
      "\n",
      "Verifying normalization (should sum to 1 for each θ):\n",
      "  ('literal', None): min=1.000000, max=1.000000\n",
      "  ('inf_F', 5.482): min=1.000000, max=1.000000\n",
      "  ('inf_F', 6.988): min=1.000000, max=1.000000\n",
      "  ('inf_F', 8.909): min=1.000000, max=1.000000\n",
      "  ('inf_F', 11.36): min=1.000000, max=1.000000\n",
      "\n",
      "======================================================================\n",
      "PART B: Computing averaged P(seq | θ, ψ) matrices\n",
      "======================================================================\n",
      "\n",
      "For each ψ ∈ {inf, persp, persm}, compute:\n",
      "  P(seq | θ, ψ) = average over {T, F} × {alphas}\n",
      "\n",
      "\n",
      "Computing for ψ = inf...\n",
      "  Averaged over 10 models\n",
      "\n",
      "Computing for ψ = persp...\n",
      "  Averaged over 10 models\n",
      "\n",
      "Computing for ψ = persm...\n",
      "  Averaged over 10 models\n",
      "\n",
      "Verifying averaged matrices:\n",
      "  inf: min=1.000000, max=1.000000\n",
      "  persp: min=1.000000, max=1.000000\n",
      "  persm: min=1.000000, max=1.000000\n",
      "  literal: min=1.000000, max=1.000000\n",
      "\n",
      "======================================================================\n",
      "PART C: Defining listener models and computing posteriors\n",
      "======================================================================\n",
      "\n",
      "--- C1: Defining listener models ---\n",
      "\n",
      "Cooperative Listener:\n",
      "  - Assumes speaker has ψ = inf\n",
      "  - P_coop(seq | θ) = P(seq | θ, ψ=inf)\n",
      "\n",
      "Uncertain Listener:\n",
      "  - Uniform prior over ψ ∈ {inf, persp, persm}\n",
      "  - P_uncertain(seq | θ) = (1/3) * Σ_ψ P(seq | θ, ψ)\n",
      "\n",
      "Cooperative P(seq|θ) shape: (32768, 11)\n",
      "Uncertain P(seq|θ) shape: (32768, 11)\n",
      "\n",
      "--- C2: Computing posteriors P(θ | seq) ---\n",
      "Cooperative posterior shape: (32768, 11)\n",
      "Uncertain posterior shape: (32768, 11)\n",
      "\n",
      "Verifying posterior normalization:\n",
      "  Cooperative: min=1.000000, max=1.000000\n",
      "  Uncertain: min=1.000000, max=1.000000\n",
      "\n",
      "======================================================================\n",
      "PART D: Computing discrimination metrics\n",
      "======================================================================\n",
      "\n",
      "--- D1: Computing JS divergence ---\n",
      "Computing JS divergence between cooperative and uncertain listeners...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JS divergence (coop vs uncertain):\n",
      "  Min: -0.000000\n",
      "  Max: 0.673912\n",
      "  Mean: 0.018739\n",
      "  Median: 0.000121\n",
      "\n",
      "--- D2: Computing E[θ] and other metrics ---\n",
      "E[θ] difference: min=0.0000, max=0.3024, mean=0.0150\n",
      "\n",
      "--- D3: Computing pairwise PSI JS divergences ---\n",
      "  JS(inf vs persp): min=-0.0000, max=0.9498, mean=0.0721\n",
      "  JS(inf vs persm): min=-0.0000, max=0.9498, mean=0.0721\n",
      "  JS(persp vs persm): min=-0.0000, max=0.9953, mean=0.1540\n",
      "\n",
      "======================================================================\n",
      "PART E: Computing normalcy metrics\n",
      "======================================================================\n",
      "\n",
      "Normalcy metrics:\n",
      "1. max_P_overall: Maximum P(seq | θ, ψ) over all θ, ψ\n",
      "2. marginal_P: P(seq) marginalized over θ, ψ with flat priors\n",
      "3. min_max_P: Minimum (over ψ) of max (over θ) P(seq | θ, ψ)\n",
      "\n",
      "max_P_overall: min=5.601328e-10, max=0.771490, median=1.354431e-06\n",
      "marginal_P: min=5.108069e-11, max=0.032919, median=1.035942e-07\n",
      "min_max_P: min=1.250232e-17, max=0.000473, median=3.354473e-10\n",
      "\n",
      "======================================================================\n",
      "PART F: Creating comprehensive results DataFrame\n",
      "======================================================================\n",
      "Results DataFrame shape: (32768, 24)\n",
      "Columns: ['sequence_idx', 'sequence', 'js_coop_vs_uncertain', 'E_theta_coop', 'E_theta_uncertain', 'E_theta_diff', 'Var_theta_coop', 'Var_theta_uncertain', 'max_P_overall', 'marginal_P', 'min_max_P', 'max_P_inf', 'max_P_persp', 'max_P_persm', 'js_inf_vs_persp', 'js_inf_vs_persm', 'js_persp_vs_persm', 'n_all', 'n_most', 'n_some', 'n_no', 'n_successful', 'n_unsuccessful', 'n_unique_utterances']\n",
      "\n",
      "======================================================================\n",
      "PART G: Selecting top discriminating sequences\n",
      "======================================================================\n",
      "\n",
      "Top discriminating sequences at different normalcy thresholds:\n",
      "\n",
      "--- Top 50% by marginal_P (threshold=1.035942e-07, n=16384) ---\n",
      "Rank  JS       E[θ] diff  marginal_P   Sequence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     0.6739   0.3024     3.291926e-02 sos,sos,sos,sos,sos\n",
      "2     0.6739   0.3024     3.291926e-02 sou,sou,sou,sou,sou\n",
      "3     0.4799   0.2384     6.885619e-04 mos,sou,sos,sos,sos\n",
      "4     0.4799   0.2384     6.885619e-04 mou,sos,sou,sou,sou\n",
      "5     0.4713   0.2387     7.681045e-04 mos,sos,sou,sos,sos\n",
      "6     0.4713   0.2387     7.681045e-04 mou,sou,sos,sou,sou\n",
      "7     0.4643   0.2387     8.627065e-04 mos,sos,sos,sou,sos\n",
      "8     0.4643   0.2387     8.627065e-04 mou,sou,sou,sos,sou\n",
      "9     0.4640   0.2520     5.252586e-04 mou,sou,sou,sos,sos\n",
      "10    0.4640   0.2520     5.252586e-04 mos,sos,sos,sou,sou\n",
      "\n",
      "--- Top 25% by marginal_P (threshold=4.206249e-06, n=8192) ---\n",
      "Rank  JS       E[θ] diff  marginal_P   Sequence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     0.6739   0.3024     3.291926e-02 sos,sos,sos,sos,sos\n",
      "2     0.6739   0.3024     3.291926e-02 sou,sou,sou,sou,sou\n",
      "3     0.4799   0.2384     6.885619e-04 mos,sou,sos,sos,sos\n",
      "4     0.4799   0.2384     6.885619e-04 mou,sos,sou,sou,sou\n",
      "5     0.4713   0.2387     7.681045e-04 mos,sos,sou,sos,sos\n",
      "6     0.4713   0.2387     7.681045e-04 mou,sou,sos,sou,sou\n",
      "7     0.4643   0.2387     8.627065e-04 mos,sos,sos,sou,sos\n",
      "8     0.4643   0.2387     8.627065e-04 mou,sou,sou,sos,sou\n",
      "9     0.4640   0.2520     5.252586e-04 mou,sou,sou,sos,sos\n",
      "10    0.4640   0.2520     5.252586e-04 mos,sos,sos,sou,sou\n",
      "\n",
      "--- Top 10% by marginal_P (threshold=4.330608e-05, n=3278) ---\n",
      "Rank  JS       E[θ] diff  marginal_P   Sequence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     0.6739   0.3024     3.291926e-02 sos,sos,sos,sos,sos\n",
      "2     0.6739   0.3024     3.291926e-02 sou,sou,sou,sou,sou\n",
      "3     0.4799   0.2384     6.885619e-04 mos,sou,sos,sos,sos\n",
      "4     0.4799   0.2384     6.885619e-04 mou,sos,sou,sou,sou\n",
      "5     0.4713   0.2387     7.681045e-04 mos,sos,sou,sos,sos\n",
      "6     0.4713   0.2387     7.681045e-04 mou,sou,sos,sou,sou\n",
      "7     0.4643   0.2387     8.627065e-04 mos,sos,sos,sou,sos\n",
      "8     0.4643   0.2387     8.627065e-04 mou,sou,sou,sos,sou\n",
      "9     0.4640   0.2520     5.252586e-04 mou,sou,sou,sos,sos\n",
      "10    0.4640   0.2520     5.252586e-04 mos,sos,sos,sou,sou\n",
      "\n",
      "--- Top 5% by marginal_P (threshold=9.470609e-05, n=1644) ---\n",
      "Rank  JS       E[θ] diff  marginal_P   Sequence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     0.6739   0.3024     3.291926e-02 sos,sos,sos,sos,sos\n",
      "2     0.6739   0.3024     3.291926e-02 sou,sou,sou,sou,sou\n",
      "3     0.4799   0.2384     6.885619e-04 mos,sou,sos,sos,sos\n",
      "4     0.4799   0.2384     6.885619e-04 mou,sos,sou,sou,sou\n",
      "5     0.4713   0.2387     7.681045e-04 mos,sos,sou,sos,sos\n",
      "6     0.4713   0.2387     7.681045e-04 mou,sou,sos,sou,sou\n",
      "7     0.4643   0.2387     8.627065e-04 mos,sos,sos,sou,sos\n",
      "8     0.4643   0.2387     8.627065e-04 mou,sou,sou,sos,sou\n",
      "9     0.4640   0.2520     5.252586e-04 mou,sou,sou,sos,sos\n",
      "10    0.4640   0.2520     5.252586e-04 mos,sos,sos,sou,sou\n",
      "\n",
      "\n",
      "======================================================================\n",
      "PART H: Finding Pareto-optimal sequences\n",
      "======================================================================\n",
      "Number of Pareto-optimal sequences: 80\n",
      "\n",
      "Top 20 Pareto-optimal sequences (sorted by JS):\n",
      "Rank  JS       marginal_P   E[θ] diff  Sequence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     0.0000   5.108069e-11 0.0011     nos,sou,als,nou,nos\n",
      "2     0.0000   5.108069e-11 0.0011     alu,sou,nou,als,alu\n",
      "3     0.0000   5.108069e-11 0.0011     alu,sou,als,nou,alu\n",
      "4     0.0000   5.108069e-11 0.0011     alu,sou,als,als,nos\n",
      "5     0.0000   5.108069e-11 0.0011     alu,sou,als,als,alu\n",
      "6     0.0000   5.108069e-11 0.0011     alu,sou,nou,als,nos\n",
      "7     0.0000   5.108069e-11 0.0011     alu,sou,nou,nou,alu\n",
      "8     0.0000   5.108069e-11 0.0011     nos,sou,als,als,alu\n",
      "9     0.0000   5.108069e-11 0.0011     nos,sou,als,als,nos\n",
      "10    0.0000   5.108069e-11 0.0011     nos,sou,als,nou,alu\n",
      "11    0.0000   5.108069e-11 0.0011     alu,sou,als,nou,nos\n",
      "12    0.0000   5.108069e-11 0.0011     nos,sou,nou,als,alu\n",
      "13    0.0000   5.108069e-11 0.0011     nos,sou,nou,als,nos\n",
      "14    0.0000   5.108069e-11 0.0011     nos,sou,nou,nou,alu\n",
      "15    0.0000   5.108069e-11 0.0011     nos,sou,nou,nou,nos\n",
      "16    0.0000   5.108069e-11 0.0011     alu,sou,nou,nou,nos\n",
      "17    0.0000   6.272066e-11 0.0005     nos,als,als,nos,sos\n",
      "18    0.0000   6.272066e-11 0.0005     alu,nou,nou,nos,sos\n",
      "19    0.0000   6.272066e-11 0.0005     alu,nou,nou,alu,sos\n",
      "20    0.0000   6.272066e-11 0.0005     alu,als,als,alu,sos\n",
      "\n",
      "======================================================================\n",
      "PART I: Detailed analysis of top candidates\n",
      "======================================================================\n",
      "Analyzing top 0 Pareto-optimal sequences with high normalcy:\n",
      "\n",
      "\n",
      "======================================================================\n",
      "PART J: Saving results\n",
      "======================================================================\n",
      "Saved: discrimination_analysis_results.csv\n",
      "Saved: pareto_optimal_sequences.csv\n",
      "Saved: top_candidates_posteriors.csv\n",
      "Saved: listener_models.npz\n",
      "\n",
      "======================================================================\n",
      "PART K: Summary\n",
      "======================================================================\n",
      "\n",
      "SUMMARY\n",
      "=======\n",
      "\n",
      "Total sequences analyzed: 32768\n",
      "\n",
      "Discrimination (JS between coop and uncertain listeners):\n",
      "  - Min: -0.0000\n",
      "  - Max: 0.6739\n",
      "  - Mean: 0.0187\n",
      "  - Median: 0.0001\n",
      "  - 90th percentile: 0.0516\n",
      "  - 99th percentile: 0.2673\n",
      "\n",
      "Normalcy (marginal probability):\n",
      "  - Min: 5.108069e-11\n",
      "  - Max: 3.291926e-02\n",
      "  - Median: 1.035942e-07\n",
      "\n",
      "E[θ] difference:\n",
      "  - Max: 0.3024\n",
      "  - Correlation with JS: 0.8653\n",
      "\n",
      "Pareto-optimal sequences: 80\n",
      "  - With high normalcy (top 25%): 0\n",
      "\n",
      "Top recommended sequences for experiment:\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COMPLETE SELF-CONTAINED DISCRIMINATION ANALYSIS SCRIPT\n",
    "# =============================================================================\n",
    "#\n",
    "# This script:\n",
    "# 1. Sets up the RSA world and computes all P(seq | θ, speaker, α) matrices\n",
    "# 2. Defines listener models (cooperative vs uncertain)\n",
    "# 3. Computes discrimination metrics between listeners\n",
    "# 4. Finds optimal sequences for experimental use\n",
    "#\n",
    "# Only imports from the core RSA module and standard libraries.\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from scipy.special import logsumexp\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "\n",
    "# Import from the RSA module (assumes rsa_optimal_exp_core.py is available)\n",
    "from rsa_optimal_exp_core import (\n",
    "    World, \n",
    "    LiteralListener, \n",
    "    PragmaticSpeaker_obs,\n",
    "    log_M_product,\n",
    "    USE_PRECISE_LOGSPACE\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPLETE SELF-CONTAINED DISCRIMINATION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =============================================================================\n",
    "# PART A: SETUP AND COMPUTE P(seq | θ, speaker, α) MATRICES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART A: Computing P(seq | θ, speaker, α) matrices\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# A1: Create World\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- A1: Creating World ---\")\n",
    "\n",
    "world = World(n=1, m=5)\n",
    "\n",
    "utterances = world.utterances\n",
    "theta_values = world.theta_values\n",
    "n_utterances = len(utterances)\n",
    "n_theta = len(theta_values)\n",
    "n_rounds = 5\n",
    "n_sequences = n_utterances ** n_rounds\n",
    "\n",
    "# P(O|θ) matrix\n",
    "log_P_O_given_theta = world.obs_log_likelihood_theta.values  # (n_obs, n_theta)\n",
    "\n",
    "# All sequences\n",
    "all_sequences = list(itertools.product(range(n_utterances), repeat=n_rounds))\n",
    "sequence_labels = [tuple(utterances[i] for i in seq) for seq in all_sequences]\n",
    "\n",
    "# Alpha values (mid-range for stability)\n",
    "alpha_values = [5.482, 6.988, 8.909, 11.36, 14.48]\n",
    "n_alpha = len(alpha_values)\n",
    "\n",
    "print(f\"Utterances ({n_utterances}): {utterances}\")\n",
    "print(f\"Theta values ({n_theta}): {list(theta_values)}\")\n",
    "print(f\"Alpha values: {alpha_values}\")\n",
    "print(f\"Sequences: {n_sequences}\")\n",
    "print(f\"Rounds: {n_rounds}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# A2: Helper function\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- A2: Defining helper functions ---\")\n",
    "\n",
    "def get_log_P_u_given_theta(speaker, log_P_O_given_theta):\n",
    "    \"\"\"Marginalize P(u|O) over O to get P(u|θ).\"\"\"\n",
    "    log_P_u_given_O = speaker.utterance_log_prob_obs.values\n",
    "    return log_M_product(log_P_u_given_O, log_P_O_given_theta, precise=USE_PRECISE_LOGSPACE)\n",
    "\n",
    "print(\"Helper functions defined.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# A3: Compute log P(seq | θ) for all speakers\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- A3: Computing log P(seq | θ) matrices ---\")\n",
    "\n",
    "# Storage: (speaker_type, alpha) -> np.array of shape (n_sequences, n_theta)\n",
    "log_P_seq_given_theta = {}\n",
    "\n",
    "# LITERAL SPEAKER\n",
    "print(\"\\nLiteral speaker...\")\n",
    "literal_listener = LiteralListener(world)\n",
    "log_P_u_given_theta_literal = literal_listener.utterance_log_likelihood_theta.values\n",
    "\n",
    "log_P_seq_theta_literal = np.zeros((n_sequences, n_theta))\n",
    "for seq_idx, seq in enumerate(all_sequences):\n",
    "    for r in range(n_rounds):\n",
    "        log_P_seq_theta_literal[seq_idx, :] += log_P_u_given_theta_literal[seq[r], :]\n",
    "\n",
    "log_P_seq_given_theta[('literal', None)] = log_P_seq_theta_literal\n",
    "print(\"  Done.\")\n",
    "\n",
    "# PRAGMATIC SPEAKERS with update_internal=False\n",
    "print(\"\\nPragmatic speakers (update_internal=False)...\")\n",
    "\n",
    "psi_map_F = {\n",
    "    'inf_F': 'inf',\n",
    "    'persp_F': 'pers+',\n",
    "    'persm_F': 'pers-'\n",
    "}\n",
    "\n",
    "for speaker_type, psi in psi_map_F.items():\n",
    "    omega = 'coop' if psi == 'inf' else 'strat'\n",
    "    print(f\"  {speaker_type}...\")\n",
    "    \n",
    "    for alpha in alpha_values:\n",
    "        speaker = PragmaticSpeaker_obs(\n",
    "            world=world, omega=omega, psi=psi,\n",
    "            update_internal=False, alpha=alpha, beta=0.0\n",
    "        )\n",
    "        log_P_u_given_theta = get_log_P_u_given_theta(speaker, log_P_O_given_theta)\n",
    "        \n",
    "        log_P_seq_theta = np.zeros((n_sequences, n_theta))\n",
    "        for seq_idx, seq in enumerate(all_sequences):\n",
    "            for r in range(n_rounds):\n",
    "                log_P_seq_theta[seq_idx, :] += log_P_u_given_theta[seq[r], :]\n",
    "        \n",
    "        log_P_seq_given_theta[(speaker_type, alpha)] = log_P_seq_theta\n",
    "\n",
    "# PRAGMATIC SPEAKERS with update_internal=True\n",
    "print(\"\\nPragmatic speakers (update_internal=True)...\")\n",
    "\n",
    "psi_map_T = {\n",
    "    'inf_T': 'inf',\n",
    "    'persp_T': 'pers+',\n",
    "    'persm_T': 'pers-'\n",
    "}\n",
    "\n",
    "for speaker_type, psi in psi_map_T.items():\n",
    "    omega = 'coop' if psi == 'inf' else 'strat'\n",
    "    print(f\"  {speaker_type}...\")\n",
    "    \n",
    "    for alpha in alpha_values:\n",
    "        # Precompute P(u|θ) for all histories\n",
    "        history_log_P_u_given_theta = {}\n",
    "        \n",
    "        for hist_len in range(n_rounds):\n",
    "            if hist_len == 0:\n",
    "                histories = [()]\n",
    "            else:\n",
    "                histories = list(itertools.product(range(n_utterances), repeat=hist_len))\n",
    "            \n",
    "            for history in histories:\n",
    "                history_utterances = [utterances[i] for i in history]\n",
    "                speaker = PragmaticSpeaker_obs(\n",
    "                    world=world, omega=omega, psi=psi,\n",
    "                    update_internal=True, alpha=alpha, beta=0.0\n",
    "                )\n",
    "                for u in history_utterances:\n",
    "                    speaker.literal_listener.listen_and_update(u)\n",
    "                    speaker.utterance_log_prob_obs = speaker._compute_utterance_log_prob_obs(alpha)\n",
    "                \n",
    "                history_log_P_u_given_theta[history] = get_log_P_u_given_theta(speaker, log_P_O_given_theta)\n",
    "        \n",
    "        # Compute P(seq|θ)\n",
    "        log_P_seq_theta = np.zeros((n_sequences, n_theta))\n",
    "        for seq_idx, seq in enumerate(all_sequences):\n",
    "            for r in range(n_rounds):\n",
    "                history = seq[:r]\n",
    "                log_P_seq_theta[seq_idx, :] += history_log_P_u_given_theta[history][seq[r], :]\n",
    "        \n",
    "        log_P_seq_given_theta[(speaker_type, alpha)] = log_P_seq_theta\n",
    "\n",
    "print(f\"\\nTotal matrices computed: {len(log_P_seq_given_theta)}\")\n",
    "\n",
    "# Verify normalization\n",
    "print(\"\\nVerifying normalization (should sum to 1 for each θ):\")\n",
    "for key, log_P in list(log_P_seq_given_theta.items())[:5]:\n",
    "    P = np.exp(log_P)\n",
    "    sums = P.sum(axis=0)\n",
    "    print(f\"  {key}: min={sums.min():.6f}, max={sums.max():.6f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART B: COMPUTE AVERAGED P(seq | θ, ψ) MATRICES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART B: Computing averaged P(seq | θ, ψ) matrices\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "For each ψ ∈ {inf, persp, persm}, compute:\n",
    "  P(seq | θ, ψ) = average over {T, F} × {alphas}\n",
    "\"\"\")\n",
    "\n",
    "# Speaker groupings\n",
    "psi_to_speakers = {\n",
    "    'inf': ['inf_T', 'inf_F'],\n",
    "    'persp': ['persp_T', 'persp_F'],\n",
    "    'persm': ['persm_T', 'persm_F']\n",
    "}\n",
    "\n",
    "# Storage: psi -> log P(seq | θ, ψ) matrix\n",
    "log_P_seq_given_theta_psi = {}\n",
    "\n",
    "for psi, speakers in psi_to_speakers.items():\n",
    "    print(f\"\\nComputing for ψ = {psi}...\")\n",
    "    \n",
    "    # Collect all log P matrices for this psi\n",
    "    all_log_P = []\n",
    "    for speaker in speakers:\n",
    "        for alpha in alpha_values:\n",
    "            key = (speaker, alpha)\n",
    "            if key in log_P_seq_given_theta:\n",
    "                all_log_P.append(log_P_seq_given_theta[key])\n",
    "    \n",
    "    all_log_P = np.array(all_log_P)  # (n_models, n_sequences, n_theta)\n",
    "    n_models = len(all_log_P)\n",
    "    \n",
    "    # Average in probability space: logsumexp - log(n)\n",
    "    log_P_avg = logsumexp(all_log_P, axis=0) - np.log(n_models)\n",
    "    \n",
    "    log_P_seq_given_theta_psi[psi] = log_P_avg\n",
    "    print(f\"  Averaged over {n_models} models\")\n",
    "\n",
    "# Also add literal\n",
    "log_P_seq_given_theta_psi['literal'] = log_P_seq_given_theta[('literal', None)]\n",
    "\n",
    "# Verify\n",
    "print(\"\\nVerifying averaged matrices:\")\n",
    "for psi, log_P in log_P_seq_given_theta_psi.items():\n",
    "    P = np.exp(log_P)\n",
    "    sums = P.sum(axis=0)\n",
    "    print(f\"  {psi}: min={sums.min():.6f}, max={sums.max():.6f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART C: DEFINE LISTENER MODELS AND COMPUTE POSTERIORS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART C: Defining listener models and computing posteriors\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Flat prior over theta\n",
    "log_prior_theta = np.full(n_theta, -np.log(n_theta))\n",
    "prior_theta = np.exp(log_prior_theta)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# C1: Define listener P(seq | θ) functions\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- C1: Defining listener models ---\")\n",
    "\n",
    "print(\"\"\"\n",
    "Cooperative Listener:\n",
    "  - Assumes speaker has ψ = inf\n",
    "  - P_coop(seq | θ) = P(seq | θ, ψ=inf)\n",
    "\n",
    "Uncertain Listener:\n",
    "  - Uniform prior over ψ ∈ {inf, persp, persm}\n",
    "  - P_uncertain(seq | θ) = (1/3) * Σ_ψ P(seq | θ, ψ)\n",
    "\"\"\")\n",
    "\n",
    "# Cooperative: just use inf\n",
    "log_P_seq_given_theta_coop = log_P_seq_given_theta_psi['inf']\n",
    "\n",
    "# Uncertain: average over three psi types\n",
    "log_P_psi_list = [\n",
    "    log_P_seq_given_theta_psi['inf'],\n",
    "    log_P_seq_given_theta_psi['persp'],\n",
    "    log_P_seq_given_theta_psi['persm']\n",
    "]\n",
    "log_P_psi_array = np.array(log_P_psi_list)\n",
    "log_P_seq_given_theta_uncertain = logsumexp(log_P_psi_array, axis=0) - np.log(3)\n",
    "\n",
    "print(f\"Cooperative P(seq|θ) shape: {log_P_seq_given_theta_coop.shape}\")\n",
    "print(f\"Uncertain P(seq|θ) shape: {log_P_seq_given_theta_uncertain.shape}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# C2: Compute posteriors P(θ | seq)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- C2: Computing posteriors P(θ | seq) ---\")\n",
    "\n",
    "def compute_posterior(log_P_seq_given_theta, log_prior_theta):\n",
    "    \"\"\"\n",
    "    Compute P(θ | seq) for all sequences.\n",
    "    \n",
    "    Returns normalized posterior probabilities, shape (n_sequences, n_theta)\n",
    "    \"\"\"\n",
    "    # log P(θ | seq) ∝ log P(seq | θ) + log P(θ)\n",
    "    log_unnorm = log_P_seq_given_theta + log_prior_theta\n",
    "    \n",
    "    # Normalize: subtract logsumexp over theta\n",
    "    log_norm = logsumexp(log_unnorm, axis=1, keepdims=True)\n",
    "    log_posterior = log_unnorm - log_norm\n",
    "    \n",
    "    return np.exp(log_posterior)\n",
    "\n",
    "# Compute posteriors for each listener type\n",
    "P_theta_given_seq_coop = compute_posterior(log_P_seq_given_theta_coop, log_prior_theta)\n",
    "P_theta_given_seq_uncertain = compute_posterior(log_P_seq_given_theta_uncertain, log_prior_theta)\n",
    "\n",
    "# Also compute for each PSI separately (useful for detailed analysis)\n",
    "P_theta_given_seq_inf = compute_posterior(log_P_seq_given_theta_psi['inf'], log_prior_theta)\n",
    "P_theta_given_seq_persp = compute_posterior(log_P_seq_given_theta_psi['persp'], log_prior_theta)\n",
    "P_theta_given_seq_persm = compute_posterior(log_P_seq_given_theta_psi['persm'], log_prior_theta)\n",
    "\n",
    "print(f\"Cooperative posterior shape: {P_theta_given_seq_coop.shape}\")\n",
    "print(f\"Uncertain posterior shape: {P_theta_given_seq_uncertain.shape}\")\n",
    "\n",
    "# Verify normalization\n",
    "print(\"\\nVerifying posterior normalization:\")\n",
    "print(f\"  Cooperative: min={P_theta_given_seq_coop.sum(axis=1).min():.6f}, max={P_theta_given_seq_coop.sum(axis=1).max():.6f}\")\n",
    "print(f\"  Uncertain: min={P_theta_given_seq_uncertain.sum(axis=1).min():.6f}, max={P_theta_given_seq_uncertain.sum(axis=1).max():.6f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART D: COMPUTE DISCRIMINATION METRICS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART D: Computing discrimination metrics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# D1: JS Divergence with numerical stability\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- D1: Computing JS divergence ---\")\n",
    "\n",
    "def js_divergence_safe(P, Q, eps=1e-10):\n",
    "    \"\"\"\n",
    "    Compute JS divergence with numerical stability.\n",
    "    \n",
    "    Adds small epsilon to avoid log(0) and handles edge cases.\n",
    "    \"\"\"\n",
    "    # Add epsilon and renormalize\n",
    "    P_safe = P + eps\n",
    "    P_safe = P_safe / P_safe.sum()\n",
    "    \n",
    "    Q_safe = Q + eps\n",
    "    Q_safe = Q_safe / Q_safe.sum()\n",
    "    \n",
    "    # Mixture distribution\n",
    "    M = 0.5 * (P_safe + Q_safe)\n",
    "    \n",
    "    # KL divergences\n",
    "    kl_pm = np.sum(P_safe * np.log2(P_safe / M))\n",
    "    kl_qm = np.sum(Q_safe * np.log2(Q_safe / M))\n",
    "    \n",
    "    # JS divergence\n",
    "    js = 0.5 * (kl_pm + kl_qm)\n",
    "    \n",
    "    return js\n",
    "\n",
    "def compute_js_divergence_batch_safe(P1, P2, eps=1e-10):\n",
    "    \"\"\"\n",
    "    Compute JS divergence for each row (sequence) with numerical stability.\n",
    "    \"\"\"\n",
    "    n_seq = P1.shape[0]\n",
    "    js_div = np.zeros(n_seq)\n",
    "    \n",
    "    for i in range(n_seq):\n",
    "        js_div[i] = js_divergence_safe(P1[i], P2[i], eps=eps)\n",
    "    \n",
    "    return js_div\n",
    "\n",
    "print(\"Computing JS divergence between cooperative and uncertain listeners...\")\n",
    "\n",
    "# Parallel computation\n",
    "chunk_size = 1000\n",
    "n_chunks = (n_sequences + chunk_size - 1) // chunk_size\n",
    "chunks = [(i * chunk_size, min((i + 1) * chunk_size, n_sequences)) for i in range(n_chunks)]\n",
    "\n",
    "def compute_js_chunk(start_idx, end_idx):\n",
    "    return compute_js_divergence_batch_safe(\n",
    "        P_theta_given_seq_coop[start_idx:end_idx],\n",
    "        P_theta_given_seq_uncertain[start_idx:end_idx]\n",
    "    )\n",
    "\n",
    "js_results = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(compute_js_chunk)(start, end) for start, end in chunks\n",
    ")\n",
    "\n",
    "js_divergence_coop_vs_uncertain = np.concatenate(js_results)\n",
    "\n",
    "print(f\"\\nJS divergence (coop vs uncertain):\")\n",
    "print(f\"  Min: {js_divergence_coop_vs_uncertain.min():.6f}\")\n",
    "print(f\"  Max: {js_divergence_coop_vs_uncertain.max():.6f}\")\n",
    "print(f\"  Mean: {js_divergence_coop_vs_uncertain.mean():.6f}\")\n",
    "print(f\"  Median: {np.median(js_divergence_coop_vs_uncertain):.6f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# D2: E[θ] and other summary statistics\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- D2: Computing E[θ] and other metrics ---\")\n",
    "\n",
    "# E[θ | seq] for each listener\n",
    "E_theta_coop = (P_theta_given_seq_coop * theta_values).sum(axis=1)\n",
    "E_theta_uncertain = (P_theta_given_seq_uncertain * theta_values).sum(axis=1)\n",
    "E_theta_diff = np.abs(E_theta_coop - E_theta_uncertain)\n",
    "\n",
    "# Variance\n",
    "Var_theta_coop = (P_theta_given_seq_coop * (theta_values ** 2)).sum(axis=1) - E_theta_coop ** 2\n",
    "Var_theta_uncertain = (P_theta_given_seq_uncertain * (theta_values ** 2)).sum(axis=1) - E_theta_uncertain ** 2\n",
    "\n",
    "print(f\"E[θ] difference: min={E_theta_diff.min():.4f}, max={E_theta_diff.max():.4f}, mean={E_theta_diff.mean():.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# D3: Pairwise PSI JS divergences\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- D3: Computing pairwise PSI JS divergences ---\")\n",
    "\n",
    "def compute_js_parallel(P1, P2, name):\n",
    "    \"\"\"Compute JS divergence in parallel.\"\"\"\n",
    "    def compute_chunk(start, end):\n",
    "        return compute_js_divergence_batch_safe(P1[start:end], P2[start:end])\n",
    "    \n",
    "    results = Parallel(n_jobs=-1, verbose=0)(\n",
    "        delayed(compute_chunk)(start, end) for start, end in chunks\n",
    "    )\n",
    "    js = np.concatenate(results)\n",
    "    print(f\"  {name}: min={js.min():.4f}, max={js.max():.4f}, mean={js.mean():.4f}\")\n",
    "    return js\n",
    "\n",
    "js_inf_vs_persp = compute_js_parallel(P_theta_given_seq_inf, P_theta_given_seq_persp, \"JS(inf vs persp)\")\n",
    "js_inf_vs_persm = compute_js_parallel(P_theta_given_seq_inf, P_theta_given_seq_persm, \"JS(inf vs persm)\")\n",
    "js_persp_vs_persm = compute_js_parallel(P_theta_given_seq_persp, P_theta_given_seq_persm, \"JS(persp vs persm)\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART E: COMPUTE NORMALCY METRICS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART E: Computing normalcy metrics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Normalcy metrics:\n",
    "1. max_P_overall: Maximum P(seq | θ, ψ) over all θ, ψ\n",
    "2. marginal_P: P(seq) marginalized over θ, ψ with flat priors\n",
    "3. min_max_P: Minimum (over ψ) of max (over θ) P(seq | θ, ψ)\n",
    "\"\"\")\n",
    "\n",
    "# Compute max P(seq | θ, ψ) for each ψ\n",
    "max_P_per_psi = {}\n",
    "for psi in ['inf', 'persp', 'persm']:\n",
    "    log_P = log_P_seq_given_theta_psi[psi]\n",
    "    max_P_per_psi[psi] = np.exp(log_P).max(axis=1)\n",
    "\n",
    "# Metric 1: Max over all (θ, ψ)\n",
    "max_P_overall = np.maximum.reduce([max_P_per_psi[psi] for psi in ['inf', 'persp', 'persm']])\n",
    "\n",
    "# Metric 2: Marginal P(seq) with flat priors\n",
    "log_marginal_per_psi = {}\n",
    "for psi in ['inf', 'persp', 'persm']:\n",
    "    log_P = log_P_seq_given_theta_psi[psi]\n",
    "    log_marginal_per_psi[psi] = logsumexp(log_P + log_prior_theta, axis=1)\n",
    "\n",
    "log_marginal_array = np.array([log_marginal_per_psi[psi] for psi in ['inf', 'persp', 'persm']])\n",
    "log_marginal_P = logsumexp(log_marginal_array, axis=0) - np.log(3)\n",
    "marginal_P = np.exp(log_marginal_P)\n",
    "\n",
    "# Metric 3: Min (over ψ) of max (over θ)\n",
    "min_max_P = np.minimum.reduce([max_P_per_psi[psi] for psi in ['inf', 'persp', 'persm']])\n",
    "\n",
    "print(f\"max_P_overall: min={max_P_overall.min():.6e}, max={max_P_overall.max():.6f}, median={np.median(max_P_overall):.6e}\")\n",
    "print(f\"marginal_P: min={marginal_P.min():.6e}, max={marginal_P.max():.6f}, median={np.median(marginal_P):.6e}\")\n",
    "print(f\"min_max_P: min={min_max_P.min():.6e}, max={min_max_P.max():.6f}, median={np.median(min_max_P):.6e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART F: CREATE RESULTS DATAFRAME\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART F: Creating comprehensive results DataFrame\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sequence characteristics\n",
    "def count_utterance_types(seq):\n",
    "    \"\"\"Count different characteristics of the sequence.\"\"\"\n",
    "    n_all = sum(1 for u in seq if u.startswith('all,'))\n",
    "    n_most = sum(1 for u in seq if u.startswith('most,'))\n",
    "    n_some = sum(1 for u in seq if u.startswith('some,'))\n",
    "    n_no = sum(1 for u in seq if u.startswith('no,'))\n",
    "    n_successful = sum(1 for u in seq if u.endswith(',successful'))\n",
    "    n_unsuccessful = sum(1 for u in seq if u.endswith(',unsuccessful'))\n",
    "    n_unique = len(set(seq))\n",
    "    return n_all, n_most, n_some, n_no, n_successful, n_unsuccessful, n_unique\n",
    "\n",
    "seq_chars = [count_utterance_types(seq) for seq in sequence_labels]\n",
    "\n",
    "results_discrimination = pd.DataFrame({\n",
    "    'sequence_idx': list(range(n_sequences)),\n",
    "    'sequence': sequence_labels,\n",
    "    \n",
    "    # Main discrimination metric\n",
    "    'js_coop_vs_uncertain': js_divergence_coop_vs_uncertain,\n",
    "    \n",
    "    # E[θ] metrics\n",
    "    'E_theta_coop': E_theta_coop,\n",
    "    'E_theta_uncertain': E_theta_uncertain,\n",
    "    'E_theta_diff': E_theta_diff,\n",
    "    \n",
    "    # Variance metrics\n",
    "    'Var_theta_coop': Var_theta_coop,\n",
    "    'Var_theta_uncertain': Var_theta_uncertain,\n",
    "    \n",
    "    # Normalcy metrics\n",
    "    'max_P_overall': max_P_overall,\n",
    "    'marginal_P': marginal_P,\n",
    "    'min_max_P': min_max_P,\n",
    "    'max_P_inf': max_P_per_psi['inf'],\n",
    "    'max_P_persp': max_P_per_psi['persp'],\n",
    "    'max_P_persm': max_P_per_psi['persm'],\n",
    "    \n",
    "    # Pairwise PSI JS divergences\n",
    "    'js_inf_vs_persp': js_inf_vs_persp,\n",
    "    'js_inf_vs_persm': js_inf_vs_persm,\n",
    "    'js_persp_vs_persm': js_persp_vs_persm,\n",
    "    \n",
    "    # Sequence characteristics\n",
    "    'n_all': [c[0] for c in seq_chars],\n",
    "    'n_most': [c[1] for c in seq_chars],\n",
    "    'n_some': [c[2] for c in seq_chars],\n",
    "    'n_no': [c[3] for c in seq_chars],\n",
    "    'n_successful': [c[4] for c in seq_chars],\n",
    "    'n_unsuccessful': [c[5] for c in seq_chars],\n",
    "    'n_unique_utterances': [c[6] for c in seq_chars],\n",
    "})\n",
    "\n",
    "print(f\"Results DataFrame shape: {results_discrimination.shape}\")\n",
    "print(f\"Columns: {list(results_discrimination.columns)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART G: SELECT TOP DISCRIMINATING SEQUENCES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART G: Selecting top discriminating sequences\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Different normalcy thresholds\n",
    "normalcy_percentiles = [50, 25, 10, 5]\n",
    "\n",
    "print(\"\\nTop discriminating sequences at different normalcy thresholds:\\n\")\n",
    "\n",
    "for pct in normalcy_percentiles:\n",
    "    threshold = np.percentile(marginal_P, 100 - pct)\n",
    "    mask = results_discrimination['marginal_P'] >= threshold\n",
    "    filtered = results_discrimination[mask].copy()\n",
    "    \n",
    "    print(f\"--- Top {pct}% by marginal_P (threshold={threshold:.6e}, n={mask.sum()}) ---\")\n",
    "    \n",
    "    top_disc = filtered.nlargest(10, 'js_coop_vs_uncertain')\n",
    "    \n",
    "    print(f\"{'Rank':<5} {'JS':<8} {'E[θ] diff':<10} {'marginal_P':<12} {'Sequence'}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for rank, (_, row) in enumerate(top_disc.iterrows(), 1):\n",
    "        seq = row['sequence']\n",
    "        # Abbreviate: mos = most,successful, mou = most,unsuccessful, etc.\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "        print(f\"{rank:<5} {row['js_coop_vs_uncertain']:<8.4f} {row['E_theta_diff']:<10.4f} {row['marginal_P']:<12.6e} {abbrev}\")\n",
    "    print()\n",
    "\n",
    "# =============================================================================\n",
    "# PART H: PARETO-OPTIMAL SEQUENCES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART H: Finding Pareto-optimal sequences\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def find_pareto_frontier(df, col1, col2):\n",
    "    \"\"\"Find Pareto-optimal points (maximize both columns).\"\"\"\n",
    "    values = df[[col1, col2]].values\n",
    "    values = -values  # Convert to minimization\n",
    "    \n",
    "    n = len(values)\n",
    "    is_pareto = np.ones(n, dtype=bool)\n",
    "    \n",
    "    for i in range(n):\n",
    "        if is_pareto[i]:\n",
    "            dominated = np.all(values <= values[i], axis=1) & np.any(values < values[i], axis=1)\n",
    "            dominated[i] = False\n",
    "            is_pareto[dominated] = False\n",
    "    \n",
    "    return df.index[is_pareto].tolist()\n",
    "\n",
    "pareto_idx = find_pareto_frontier(results_discrimination, 'js_coop_vs_uncertain', 'marginal_P')\n",
    "print(f\"Number of Pareto-optimal sequences: {len(pareto_idx)}\")\n",
    "\n",
    "pareto_df = results_discrimination.loc[pareto_idx].sort_values('js_coop_vs_uncertain', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 Pareto-optimal sequences (sorted by JS):\")\n",
    "print(f\"{'Rank':<5} {'JS':<8} {'marginal_P':<12} {'E[θ] diff':<10} {'Sequence'}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for rank, (_, row) in enumerate(pareto_df.head(20).iterrows(), 1):\n",
    "    seq = row['sequence']\n",
    "    abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "    print(f\"{rank:<5} {row['js_coop_vs_uncertain']:<8.4f} {row['marginal_P']:<12.6e} {row['E_theta_diff']:<10.4f} {abbrev}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART I: DETAILED ANALYSIS OF TOP CANDIDATES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART I: Detailed analysis of top candidates\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select top candidates: high JS AND high normalcy\n",
    "# Filter to top 25% normalcy first\n",
    "pareto_normal = pareto_df[pareto_df['marginal_P'] >= np.percentile(marginal_P, 75)]\n",
    "top_candidates = pareto_normal.head(5)\n",
    "\n",
    "print(f\"Analyzing top {len(top_candidates)} Pareto-optimal sequences with high normalcy:\\n\")\n",
    "\n",
    "for rank, (idx, row) in enumerate(top_candidates.iterrows(), 1):\n",
    "    seq = row['sequence']\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Candidate {rank}: {seq}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nDiscrimination metrics:\")\n",
    "    print(f\"  JS(coop vs uncertain): {row['js_coop_vs_uncertain']:.4f}\")\n",
    "    print(f\"  E[θ] difference: {row['E_theta_diff']:.4f}\")\n",
    "    print(f\"  E[θ|seq] for coop listener: {row['E_theta_coop']:.4f}\")\n",
    "    print(f\"  E[θ|seq] for uncertain listener: {row['E_theta_uncertain']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nNormalcy metrics:\")\n",
    "    print(f\"  Marginal P(seq): {row['marginal_P']:.6e}\")\n",
    "    print(f\"  Max P under inf: {row['max_P_inf']:.6e}\")\n",
    "    print(f\"  Max P under persp: {row['max_P_persp']:.6e}\")\n",
    "    print(f\"  Max P under persm: {row['max_P_persm']:.6e}\")\n",
    "    \n",
    "    print(f\"\\nPairwise PSI JS divergences:\")\n",
    "    print(f\"  JS(inf vs persp): {row['js_inf_vs_persp']:.4f}\")\n",
    "    print(f\"  JS(inf vs persm): {row['js_inf_vs_persm']:.4f}\")\n",
    "    print(f\"  JS(persp vs persm): {row['js_persp_vs_persm']:.4f}\")\n",
    "    \n",
    "    # Show posterior distributions\n",
    "    print(f\"\\nPosterior P(θ | seq):\")\n",
    "    print(f\"  {'θ':<6} {'P_coop':<12} {'P_uncertain':<12} {'P_inf':<12} {'P_persp':<12} {'P_persm':<12}\")\n",
    "    \n",
    "    p_coop = P_theta_given_seq_coop[idx]\n",
    "    p_unc = P_theta_given_seq_uncertain[idx]\n",
    "    p_inf = P_theta_given_seq_inf[idx]\n",
    "    p_persp = P_theta_given_seq_persp[idx]\n",
    "    p_persm = P_theta_given_seq_persm[idx]\n",
    "    \n",
    "    for i, theta in enumerate(theta_values):\n",
    "        print(f\"  {theta:<6.1f} {p_coop[i]:<12.4f} {p_unc[i]:<12.4f} {p_inf[i]:<12.4f} {p_persp[i]:<12.4f} {p_persm[i]:<12.4f}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# =============================================================================\n",
    "# PART J: SAVE RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART J: Saving results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save full results\n",
    "results_discrimination.to_csv('discrimination_analysis_results.csv', index=False)\n",
    "print(\"Saved: discrimination_analysis_results.csv\")\n",
    "\n",
    "# Save Pareto frontier\n",
    "pareto_df.to_csv('pareto_optimal_sequences.csv', index=False)\n",
    "print(\"Saved: pareto_optimal_sequences.csv\")\n",
    "\n",
    "# Save posteriors for top candidates\n",
    "top_candidates_idx = top_candidates.index.tolist()\n",
    "posteriors_data = {'theta': list(theta_values)}\n",
    "for i, idx in enumerate(top_candidates_idx[:10]):\n",
    "    posteriors_data[f'coop_{i}'] = P_theta_given_seq_coop[idx]\n",
    "    posteriors_data[f'uncertain_{i}'] = P_theta_given_seq_uncertain[idx]\n",
    "    posteriors_data[f'inf_{i}'] = P_theta_given_seq_inf[idx]\n",
    "    posteriors_data[f'persp_{i}'] = P_theta_given_seq_persp[idx]\n",
    "    posteriors_data[f'persm_{i}'] = P_theta_given_seq_persm[idx]\n",
    "\n",
    "posteriors_df = pd.DataFrame(posteriors_data)\n",
    "posteriors_df.to_csv('top_candidates_posteriors.csv', index=False)\n",
    "print(\"Saved: top_candidates_posteriors.csv\")\n",
    "\n",
    "# Save listener models\n",
    "np.savez(\n",
    "    'listener_models.npz',\n",
    "    log_P_seq_given_theta_coop=log_P_seq_given_theta_coop,\n",
    "    log_P_seq_given_theta_uncertain=log_P_seq_given_theta_uncertain,\n",
    "    log_P_seq_given_theta_inf=log_P_seq_given_theta_psi['inf'],\n",
    "    log_P_seq_given_theta_persp=log_P_seq_given_theta_psi['persp'],\n",
    "    log_P_seq_given_theta_persm=log_P_seq_given_theta_psi['persm'],\n",
    "    theta_values=theta_values,\n",
    "    sequences=np.array(sequence_labels, dtype=object)\n",
    ")\n",
    "print(\"Saved: listener_models.npz\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART K: SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART K: Summary\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "SUMMARY\n",
    "=======\n",
    "\n",
    "Total sequences analyzed: {n_sequences}\n",
    "\n",
    "Discrimination (JS between coop and uncertain listeners):\n",
    "  - Min: {js_divergence_coop_vs_uncertain.min():.4f}\n",
    "  - Max: {js_divergence_coop_vs_uncertain.max():.4f}\n",
    "  - Mean: {js_divergence_coop_vs_uncertain.mean():.4f}\n",
    "  - Median: {np.median(js_divergence_coop_vs_uncertain):.4f}\n",
    "  - 90th percentile: {np.percentile(js_divergence_coop_vs_uncertain, 90):.4f}\n",
    "  - 99th percentile: {np.percentile(js_divergence_coop_vs_uncertain, 99):.4f}\n",
    "\n",
    "Normalcy (marginal probability):\n",
    "  - Min: {marginal_P.min():.6e}\n",
    "  - Max: {marginal_P.max():.6e}\n",
    "  - Median: {np.median(marginal_P):.6e}\n",
    "\n",
    "E[θ] difference:\n",
    "  - Max: {E_theta_diff.max():.4f}\n",
    "  - Correlation with JS: {np.corrcoef(js_divergence_coop_vs_uncertain, E_theta_diff)[0,1]:.4f}\n",
    "\n",
    "Pareto-optimal sequences: {len(pareto_idx)}\n",
    "  - With high normalcy (top 25%): {len(pareto_normal)}\n",
    "\n",
    "Top recommended sequences for experiment:\n",
    "\"\"\")\n",
    "\n",
    "for rank, (_, row) in enumerate(pareto_normal.head(5).iterrows(), 1):\n",
    "    seq = row['sequence']\n",
    "    print(f\"  {rank}. {seq}\")\n",
    "    print(f\"     JS={row['js_coop_vs_uncertain']:.4f}, P={row['marginal_P']:.6e}, E[θ] diff={row['E_theta_diff']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "096e4ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CORRECTED ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "--- Corrected Pareto Frontier ---\n",
      "Number of Pareto-optimal sequences: 1\n",
      "\n",
      "Top 20 Pareto-optimal sequences (sorted by JS, descending):\n",
      "Rank  JS       marginal_P   E[θ] diff  Sequence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     0.6739   3.291926e-02 0.3024     sos,sos,sos,sos,sos\n",
      "\n",
      "======================================================================\n",
      "WHY DO THESE SEQUENCES DISCRIMINATE?\n",
      "======================================================================\n",
      "\n",
      "--- Sequence: some,successful × 5 ---\n",
      "\n",
      "P(seq | θ, ψ) for each speaker type:\n",
      "θ      INF          PERSP        PERSM        UNCERTAIN   \n",
      "0.0    0.000000     0.000000     0.000000     0.000000    \n",
      "0.1    0.000000     0.005436     0.000000     0.001812    \n",
      "0.2    0.000000     0.048322     0.000000     0.016107    \n",
      "0.3    0.000000     0.081926     0.000001     0.027309    \n",
      "0.4    0.000000     0.059962     0.000004     0.019989    \n",
      "0.5    0.000000     0.023934     0.000022     0.007986    \n",
      "0.6    0.000000     0.005808     0.000136     0.001982    \n",
      "0.7    0.000000     0.000967     0.000953     0.000640    \n",
      "0.8    0.000000     0.000126     0.008139     0.002755    \n",
      "0.9    0.000000     0.000010     0.079098     0.026369    \n",
      "1.0    0.000000     0.000000     0.771490     0.257163    \n",
      "\n",
      "Posterior P(θ | seq) for each listener:\n",
      "θ      COOP (inf)   UNCERTAIN    Difference  \n",
      "0.0    0.0000       0.0000       +0.0000     \n",
      "0.1    0.0026       0.0050       -0.0024     \n",
      "0.2    0.0307       0.0445       -0.0138     \n",
      "0.3    0.0892       0.0754       +0.0138     \n",
      "0.4    0.1516       0.0552       +0.0964     \n",
      "0.5    0.2025       0.0221       +0.1805     \n",
      "0.6    0.2301       0.0055       +0.2246     \n",
      "0.7    0.1955       0.0018       +0.1938     \n",
      "0.8    0.0889       0.0076       +0.0813     \n",
      "0.9    0.0088       0.0728       -0.0640     \n",
      "1.0    0.0000       0.7102       -0.7102     \n",
      "\n",
      "E[θ|seq]: Coop=0.5491, Uncertain=0.8515, Diff=-0.3024\n",
      "\n",
      "--- Sequence: some,unsuccessful × 5 ---\n",
      "\n",
      "P(seq | θ, ψ) for each speaker type:\n",
      "θ      INF          PERSP        PERSM        UNCERTAIN   \n",
      "0.0    0.000000     0.771490     0.000000     0.257163    \n",
      "0.1    0.000000     0.079098     0.000010     0.026369    \n",
      "0.2    0.000000     0.008139     0.000126     0.002755    \n",
      "0.3    0.000000     0.000953     0.000967     0.000640    \n",
      "0.4    0.000000     0.000136     0.005808     0.001982    \n",
      "0.5    0.000000     0.000022     0.023934     0.007986    \n",
      "0.6    0.000000     0.000004     0.059962     0.019989    \n",
      "0.7    0.000000     0.000001     0.081926     0.027309    \n",
      "0.8    0.000000     0.000000     0.048322     0.016107    \n",
      "0.9    0.000000     0.000000     0.005436     0.001812    \n",
      "1.0    0.000000     0.000000     0.000000     0.000000    \n",
      "\n",
      "Posterior P(θ | seq) for each listener:\n",
      "θ      COOP (inf)   UNCERTAIN    Difference  \n",
      "0.0    0.0000       0.7102       -0.7102     \n",
      "0.1    0.0088       0.0728       -0.0640     \n",
      "0.2    0.0889       0.0076       +0.0813     \n",
      "0.3    0.1955       0.0018       +0.1938     \n",
      "0.4    0.2301       0.0055       +0.2246     \n",
      "0.5    0.2025       0.0221       +0.1805     \n",
      "0.6    0.1516       0.0552       +0.0964     \n",
      "0.7    0.0892       0.0754       +0.0138     \n",
      "0.8    0.0307       0.0445       -0.0138     \n",
      "0.9    0.0026       0.0050       -0.0024     \n",
      "1.0    0.0000       0.0000       +0.0000     \n",
      "\n",
      "E[θ|seq]: Coop=0.4509, Uncertain=0.1485, Diff=+0.3024\n",
      "\n",
      "======================================================================\n",
      "NORMAL vs WEIRD SEQUENCES\n",
      "======================================================================\n",
      "\n",
      "Top 1% normalcy (P ≈ 4.10e-04):\n",
      "  Example: als,als,mos,mos,mos\n",
      "  JS=0.0223, E[θ] diff=0.0168\n",
      "\n",
      "Top 10% normalcy (P ≈ 4.33e-05):\n",
      "  Example: als,mos,mos,mou,mou\n",
      "  JS=0.0000, E[θ] diff=0.0000\n",
      "\n",
      "Median normalcy (P ≈ 1.04e-07):\n",
      "  Example: als,als,alu,mou,mos\n",
      "  JS=0.0000, E[θ] diff=0.0000\n",
      "\n",
      "Bottom 10% normalcy (P ≈ 1.72e-09):\n",
      "  Example: als,als,als,sos,alu\n",
      "  JS=0.0046, E[θ] diff=0.0147\n",
      "\n",
      "======================================================================\n",
      "RECOMMENDED SEQUENCES FOR EXPERIMENT\n",
      "======================================================================\n",
      "\n",
      "Selection criteria:\n",
      "1. High JS divergence (> 0.3) - good discrimination\n",
      "2. High marginal probability (top 10%) - not \"weird\"\n",
      "3. Meaningful E[θ] difference (> 0.1)\n",
      "\n",
      "\n",
      "Found 120 candidates meeting all criteria:\n",
      "\n",
      "Rank  JS       E[θ] diff  P            Sequence\n",
      "------------------------------------------------------------------------------------------\n",
      "1     0.6739   0.3024     3.291926e-02 ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "2     0.6739   0.3024     3.291926e-02 ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "3     0.4799   0.2384     6.885619e-04 ('most,successful', 'some,unsuccessful', 'some,successful', 'some,successful', 'some,successful')\n",
      "4     0.4799   0.2384     6.885619e-04 ('most,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "5     0.4713   0.2387     7.681045e-04 ('most,successful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,successful')\n",
      "6     0.4713   0.2387     7.681045e-04 ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "7     0.4643   0.2387     8.627065e-04 ('most,successful', 'some,successful', 'some,successful', 'some,unsuccessful', 'some,successful')\n",
      "8     0.4643   0.2387     8.627065e-04 ('most,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful')\n",
      "9     0.4640   0.2520     5.252586e-04 ('most,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,successful')\n",
      "10    0.4640   0.2520     5.252586e-04 ('most,successful', 'some,successful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "... and 110 more\n",
      "\n",
      "======================================================================\n",
      "DETAILED ANALYSIS: TOP CANDIDATE\n",
      "======================================================================\n",
      "\n",
      "Sequence: ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "\n",
      "This sequence consists of: some,successful repeated 5 times\n",
      "\n",
      "1. DISCRIMINATION METRICS:\n",
      "   JS(coop vs uncertain) = 0.6739\n",
      "   E[θ] difference = 0.3024\n",
      "\n",
      "2. NORMALCY METRICS:\n",
      "   Marginal P(seq) = 3.2919e-02 (top 100.0%)\n",
      "   Max P under inf = 5.0615e-08\n",
      "   Max P under persp = 8.1926e-02\n",
      "   Max P under persm = 7.7149e-01\n",
      "\n",
      "3. PAIRWISE PSI DIVERGENCES:\n",
      "   JS(inf vs persp) = 0.3480\n",
      "   JS(inf vs persm) = 0.9498\n",
      "   JS(persp vs persm) = 0.9953\n",
      "\n",
      "4. POSTERIOR DISTRIBUTIONS:\n",
      "   θ      P_coop     P_uncertain  P_inf      P_persp    P_persm   \n",
      "   ----------------------------------------------------------------------\n",
      "   0.0    0.0000     0.0000       0.0000     0.0000     0.0000    \n",
      "   0.1    0.0026     0.0050       0.0026     0.0240     0.0000    \n",
      "   0.2    0.0307     0.0445       0.0307     0.2134     0.0000    \n",
      "   0.3    0.0892     0.0754       0.0892     0.3617     0.0000    \n",
      "   0.4    0.1516     0.0552       0.1516     0.2647     0.0000    \n",
      "   0.5    0.2025     0.0221       0.2025     0.1057     0.0000    \n",
      "   0.6    0.2301     0.0055       0.2301     0.0256     0.0002    \n",
      "   0.7    0.1955     0.0018       0.1955     0.0043     0.0011    \n",
      "   0.8    0.0889     0.0076       0.0889     0.0006     0.0095    \n",
      "   0.9    0.0088     0.0728       0.0088     0.0000     0.0920    \n",
      "   1.0    0.0000     0.7102       0.0000     0.0000     0.8972    \n",
      "\n",
      "5. INTERPRETATION:\n",
      "   Cooperative listener (assuming inf speaker):\n",
      "     E[θ|seq] = 0.549\n",
      "   Uncertain listener (uniform over ψ):\n",
      "     E[θ|seq] = 0.851\n",
      "   \n",
      "   The cooperative listener infers a LOWER θ\n",
      "   because they assume an informative speaker.\n",
      "\n",
      "======================================================================\n",
      "SAVING FINAL RECOMMENDATIONS\n",
      "======================================================================\n",
      "Saved: recommended_sequences.csv\n",
      "Saved: pareto_optimal_sequences_corrected.csv\n",
      "\n",
      "======================================================================\n",
      "SUMMARY OF RECOMMENDATIONS\n",
      "======================================================================\n",
      "\n",
      "TOP RECOMMENDED SEQUENCES FOR EXPERIMENT:\n",
      "\n",
      "1. ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
      "   - JS = 0.674, E[θ] diff = 0.302, P = 3.3%\n",
      "   - Interpretation: Cooperative listener thinks θ is HIGH (informative speaker \n",
      "     would say this at high θ), but uncertain listener hedges.\n",
      "\n",
      "2. ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "   - JS = 0.674, E[θ] diff = 0.302, P = 3.3%\n",
      "   - Interpretation: Symmetric to #1 but for low θ.\n",
      "\n",
      "3-10. Sequences with 1 \"most\" and 4 \"some\" utterances\n",
      "   - JS ≈ 0.46-0.48, E[θ] diff ≈ 0.24\n",
      "   - More varied, still highly discriminating\n",
      "\n",
      "EXPERIMENT DESIGN NOTES:\n",
      "- Use sequences #1 and #2 as primary stimuli (highest discrimination)\n",
      "- Include some from #3-10 for variety\n",
      "- Both cooperative and uncertain listeners will see the SAME sequence\n",
      "- Measure their posterior beliefs about θ\n",
      "- Compare to model predictions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FIX: Corrected Pareto frontier and additional analyses\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CORRECTED ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Fix 1: Corrected Pareto frontier function\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def find_pareto_frontier_correct(df, col1, col2):\n",
    "    \"\"\"\n",
    "    Find Pareto-optimal points (maximize both columns).\n",
    "    \n",
    "    A point is Pareto-optimal if no other point is better in BOTH dimensions.\n",
    "    \"\"\"\n",
    "    values = df[[col1, col2]].values\n",
    "    n = len(values)\n",
    "    is_pareto = np.ones(n, dtype=bool)\n",
    "    \n",
    "    for i in range(n):\n",
    "        if is_pareto[i]:\n",
    "            # Point j dominates point i if j is >= i in all dimensions and > i in at least one\n",
    "            # We want to KEEP point i if no other point dominates it\n",
    "            # Here we find points that are dominated BY point i (i.e., i >= them in all, i > them in some)\n",
    "            # But we need the reverse: mark i as not Pareto if some j dominates i\n",
    "            \n",
    "            for j in range(n):\n",
    "                if i != j and is_pareto[j]:\n",
    "                    # Check if j dominates i (j >= i in all dims, j > i in at least one)\n",
    "                    if (values[j, 0] >= values[i, 0] and values[j, 1] >= values[i, 1] and\n",
    "                        (values[j, 0] > values[i, 0] or values[j, 1] > values[i, 1])):\n",
    "                        is_pareto[i] = False\n",
    "                        break\n",
    "    \n",
    "    return df.index[is_pareto].tolist()\n",
    "\n",
    "# Faster vectorized version\n",
    "def find_pareto_frontier_fast(df, col1, col2):\n",
    "    \"\"\"\n",
    "    Find Pareto-optimal points (maximize both columns) - vectorized version.\n",
    "    \"\"\"\n",
    "    values = df[[col1, col2]].values\n",
    "    n = len(values)\n",
    "    is_pareto = np.ones(n, dtype=bool)\n",
    "    \n",
    "    for i in range(n):\n",
    "        if is_pareto[i]:\n",
    "            # Check if any other point dominates point i\n",
    "            # j dominates i if: j >= i in all dims AND j > i in at least one\n",
    "            all_geq = np.all(values >= values[i], axis=1)  # j >= i in all dims\n",
    "            any_greater = np.any(values > values[i], axis=1)  # j > i in at least one dim\n",
    "            dominates_i = all_geq & any_greater\n",
    "            dominates_i[i] = False  # Point doesn't dominate itself\n",
    "            \n",
    "            if np.any(dominates_i):\n",
    "                is_pareto[i] = False\n",
    "    \n",
    "    return df.index[is_pareto].tolist()\n",
    "\n",
    "print(\"\\n--- Corrected Pareto Frontier ---\")\n",
    "pareto_idx_correct = find_pareto_frontier_fast(results_discrimination, 'js_coop_vs_uncertain', 'marginal_P')\n",
    "print(f\"Number of Pareto-optimal sequences: {len(pareto_idx_correct)}\")\n",
    "\n",
    "pareto_df_correct = results_discrimination.loc[pareto_idx_correct].sort_values('js_coop_vs_uncertain', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 Pareto-optimal sequences (sorted by JS, descending):\")\n",
    "print(f\"{'Rank':<5} {'JS':<8} {'marginal_P':<12} {'E[θ] diff':<10} {'Sequence'}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for rank, (_, row) in enumerate(pareto_df_correct.head(20).iterrows(), 1):\n",
    "    seq = row['sequence']\n",
    "    abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "    print(f\"{rank:<5} {row['js_coop_vs_uncertain']:<8.4f} {row['marginal_P']:<12.6e} {row['E_theta_diff']:<10.4f} {abbrev}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Analysis 2: Understanding WHY these sequences discriminate\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WHY DO THESE SEQUENCES DISCRIMINATE?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Look at the top 2 sequences\n",
    "top_seqs = ['some,successful', 'some,unsuccessful']\n",
    "\n",
    "for base_utt in top_seqs:\n",
    "    # Find the sequence that's all this utterance\n",
    "    seq_tuple = tuple([base_utt] * 5)\n",
    "    idx = sequence_labels.index(seq_tuple)\n",
    "    \n",
    "    print(f\"\\n--- Sequence: {base_utt} × 5 ---\")\n",
    "    \n",
    "    # Show P(seq | θ) for each speaker model\n",
    "    print(f\"\\nP(seq | θ, ψ) for each speaker type:\")\n",
    "    print(f\"{'θ':<6} {'INF':<12} {'PERSP':<12} {'PERSM':<12} {'UNCERTAIN':<12}\")\n",
    "    \n",
    "    log_P_inf = log_P_seq_given_theta_psi['inf'][idx]\n",
    "    log_P_persp = log_P_seq_given_theta_psi['persp'][idx]\n",
    "    log_P_persm = log_P_seq_given_theta_psi['persm'][idx]\n",
    "    log_P_unc = log_P_seq_given_theta_uncertain[idx]\n",
    "    \n",
    "    for i, theta in enumerate(theta_values):\n",
    "        P_inf = np.exp(log_P_inf[i])\n",
    "        P_persp = np.exp(log_P_persp[i])\n",
    "        P_persm = np.exp(log_P_persm[i])\n",
    "        P_unc = np.exp(log_P_unc[i])\n",
    "        print(f\"{theta:<6.1f} {P_inf:<12.6f} {P_persp:<12.6f} {P_persm:<12.6f} {P_unc:<12.6f}\")\n",
    "    \n",
    "    # Show the resulting posteriors\n",
    "    print(f\"\\nPosterior P(θ | seq) for each listener:\")\n",
    "    print(f\"{'θ':<6} {'COOP (inf)':<12} {'UNCERTAIN':<12} {'Difference':<12}\")\n",
    "    \n",
    "    p_coop = P_theta_given_seq_coop[idx]\n",
    "    p_unc = P_theta_given_seq_uncertain[idx]\n",
    "    \n",
    "    for i, theta in enumerate(theta_values):\n",
    "        diff = p_coop[i] - p_unc[i]\n",
    "        print(f\"{theta:<6.1f} {p_coop[i]:<12.4f} {p_unc[i]:<12.4f} {diff:<+12.4f}\")\n",
    "    \n",
    "    E_coop = (p_coop * theta_values).sum()\n",
    "    E_unc = (p_unc * theta_values).sum()\n",
    "    print(f\"\\nE[θ|seq]: Coop={E_coop:.4f}, Uncertain={E_unc:.4f}, Diff={E_coop - E_unc:+.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Analysis 3: What makes a sequence \"normal\" vs \"weird\"?\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NORMAL vs WEIRD SEQUENCES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Show examples at different normalcy levels\n",
    "normalcy_examples = [\n",
    "    (np.percentile(marginal_P, 99), \"Top 1% normalcy\"),\n",
    "    (np.percentile(marginal_P, 90), \"Top 10% normalcy\"),\n",
    "    (np.percentile(marginal_P, 50), \"Median normalcy\"),\n",
    "    (np.percentile(marginal_P, 10), \"Bottom 10% normalcy\"),\n",
    "]\n",
    "\n",
    "for threshold, label in normalcy_examples:\n",
    "    close_to_threshold = np.abs(results_discrimination['marginal_P'] - threshold) < threshold * 0.1\n",
    "    if close_to_threshold.sum() > 0:\n",
    "        example = results_discrimination[close_to_threshold].iloc[0]\n",
    "        seq = example['sequence']\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "        print(f\"\\n{label} (P ≈ {threshold:.2e}):\")\n",
    "        print(f\"  Example: {abbrev}\")\n",
    "        print(f\"  JS={example['js_coop_vs_uncertain']:.4f}, E[θ] diff={example['E_theta_diff']:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Analysis 4: Recommended sequences for experiment\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDED SEQUENCES FOR EXPERIMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Selection criteria:\n",
    "1. High JS divergence (> 0.3) - good discrimination\n",
    "2. High marginal probability (top 10%) - not \"weird\"\n",
    "3. Meaningful E[θ] difference (> 0.1)\n",
    "\"\"\")\n",
    "\n",
    "# Filter by criteria\n",
    "candidates = results_discrimination[\n",
    "    (results_discrimination['js_coop_vs_uncertain'] > 0.3) &\n",
    "    (results_discrimination['marginal_P'] >= np.percentile(marginal_P, 90)) &\n",
    "    (results_discrimination['E_theta_diff'] > 0.1)\n",
    "].sort_values('js_coop_vs_uncertain', ascending=False)\n",
    "\n",
    "print(f\"\\nFound {len(candidates)} candidates meeting all criteria:\\n\")\n",
    "\n",
    "print(f\"{'Rank':<5} {'JS':<8} {'E[θ] diff':<10} {'P':<12} {'Sequence'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for rank, (idx, row) in enumerate(candidates.iterrows(), 1):\n",
    "    seq = row['sequence']\n",
    "    # Full sequence display\n",
    "    print(f\"{rank:<5} {row['js_coop_vs_uncertain']:<8.4f} {row['E_theta_diff']:<10.4f} {row['marginal_P']:<12.6e} {seq}\")\n",
    "    \n",
    "    if rank >= 10:\n",
    "        if len(candidates) > 10:\n",
    "            print(f\"... and {len(candidates) - 10} more\")\n",
    "        break\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Analysis 5: Detailed breakdown of top candidate\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED ANALYSIS: TOP CANDIDATE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if len(candidates) > 0:\n",
    "    top_idx = candidates.index[0]\n",
    "    top_row = candidates.iloc[0]\n",
    "    top_seq = top_row['sequence']\n",
    "    \n",
    "    print(f\"\\nSequence: {top_seq}\")\n",
    "    print(f\"\\nThis sequence consists of: {top_seq[0]} repeated 5 times\")\n",
    "    \n",
    "    print(f\"\\n1. DISCRIMINATION METRICS:\")\n",
    "    print(f\"   JS(coop vs uncertain) = {top_row['js_coop_vs_uncertain']:.4f}\")\n",
    "    print(f\"   E[θ] difference = {top_row['E_theta_diff']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n2. NORMALCY METRICS:\")\n",
    "    print(f\"   Marginal P(seq) = {top_row['marginal_P']:.4e} (top {100*(marginal_P < top_row['marginal_P']).mean():.1f}%)\")\n",
    "    print(f\"   Max P under inf = {top_row['max_P_inf']:.4e}\")\n",
    "    print(f\"   Max P under persp = {top_row['max_P_persp']:.4e}\")\n",
    "    print(f\"   Max P under persm = {top_row['max_P_persm']:.4e}\")\n",
    "    \n",
    "    print(f\"\\n3. PAIRWISE PSI DIVERGENCES:\")\n",
    "    print(f\"   JS(inf vs persp) = {top_row['js_inf_vs_persp']:.4f}\")\n",
    "    print(f\"   JS(inf vs persm) = {top_row['js_inf_vs_persm']:.4f}\")\n",
    "    print(f\"   JS(persp vs persm) = {top_row['js_persp_vs_persm']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n4. POSTERIOR DISTRIBUTIONS:\")\n",
    "    print(f\"   {'θ':<6} {'P_coop':<10} {'P_uncertain':<12} {'P_inf':<10} {'P_persp':<10} {'P_persm':<10}\")\n",
    "    print(\"   \" + \"-\"*70)\n",
    "    \n",
    "    for i, theta in enumerate(theta_values):\n",
    "        print(f\"   {theta:<6.1f} {P_theta_given_seq_coop[top_idx, i]:<10.4f} \"\n",
    "              f\"{P_theta_given_seq_uncertain[top_idx, i]:<12.4f} \"\n",
    "              f\"{P_theta_given_seq_inf[top_idx, i]:<10.4f} \"\n",
    "              f\"{P_theta_given_seq_persp[top_idx, i]:<10.4f} \"\n",
    "              f\"{P_theta_given_seq_persm[top_idx, i]:<10.4f}\")\n",
    "    \n",
    "    print(f\"\\n5. INTERPRETATION:\")\n",
    "    E_coop = (P_theta_given_seq_coop[top_idx] * theta_values).sum()\n",
    "    E_unc = (P_theta_given_seq_uncertain[top_idx] * theta_values).sum()\n",
    "    \n",
    "    print(f\"   Cooperative listener (assuming inf speaker):\")\n",
    "    print(f\"     E[θ|seq] = {E_coop:.3f}\")\n",
    "    print(f\"   Uncertain listener (uniform over ψ):\")\n",
    "    print(f\"     E[θ|seq] = {E_unc:.3f}\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   The cooperative listener infers a {'HIGHER' if E_coop > E_unc else 'LOWER'} θ\")\n",
    "    print(f\"   because they assume an informative speaker.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Analysis 6: Save final recommendations\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING FINAL RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save recommended sequences\n",
    "if len(candidates) > 0:\n",
    "    candidates.to_csv('recommended_sequences.csv', index=False)\n",
    "    print(\"Saved: recommended_sequences.csv\")\n",
    "\n",
    "# Save corrected Pareto frontier\n",
    "pareto_df_correct.to_csv('pareto_optimal_sequences_corrected.csv', index=False)\n",
    "print(\"Saved: pareto_optimal_sequences_corrected.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY OF RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "TOP RECOMMENDED SEQUENCES FOR EXPERIMENT:\n",
    "\n",
    "1. ('some,successful', 'some,successful', 'some,successful', 'some,successful', 'some,successful')\n",
    "   - JS = 0.674, E[θ] diff = 0.302, P = 3.3%\n",
    "   - Interpretation: Cooperative listener thinks θ is HIGH (informative speaker \n",
    "     would say this at high θ), but uncertain listener hedges.\n",
    "\n",
    "2. ('some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
    "   - JS = 0.674, E[θ] diff = 0.302, P = 3.3%\n",
    "   - Interpretation: Symmetric to #1 but for low θ.\n",
    "\n",
    "3-10. Sequences with 1 \"most\" and 4 \"some\" utterances\n",
    "   - JS ≈ 0.46-0.48, E[θ] diff ≈ 0.24\n",
    "   - More varied, still highly discriminating\n",
    "\n",
    "EXPERIMENT DESIGN NOTES:\n",
    "- Use sequences #1 and #2 as primary stimuli (highest discrimination)\n",
    "- Include some from #3-10 for variety\n",
    "- Both cooperative and uncertain listeners will see the SAME sequence\n",
    "- Measure their posterior beliefs about θ\n",
    "- Compare to model predictions\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "856d51e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NON-REPETITIVE, SPEAKER-CHARACTERISTIC SEQUENCES\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Part 1: Computing repetitiveness metrics\n",
      "======================================================================\n",
      "Repetitiveness distribution:\n",
      "n_adjacent_repeats\n",
      "0    19208\n",
      "1    10976\n",
      "2     2352\n",
      "3      224\n",
      "4        8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "By adjacent repeats, mean JS divergence:\n",
      "  0 adjacent repeats: n=19208, mean JS=0.0135\n",
      "  1 adjacent repeats: n=10976, mean JS=0.0229\n",
      "  2 adjacent repeats: n=2352, mean JS=0.0376\n",
      "  3 adjacent repeats: n=224, mean JS=0.0658\n",
      "  4 adjacent repeats: n=8, mean JS=0.1687\n",
      "\n",
      "======================================================================\n",
      "Part 2: Categorizing by dominant speaker type\n",
      "======================================================================\n",
      "\n",
      "For each sequence, determine which speaker type finds it MOST likely.\n",
      "- \"inf-characteristic\": max_P_inf > max_P_persp AND max_P_inf > max_P_persm\n",
      "- \"persp-characteristic\": max_P_persp is highest\n",
      "- \"persm-characteristic\": max_P_persm is highest\n",
      "\n",
      "\n",
      "Distribution of dominant speaker:\n",
      "dominant_speaker\n",
      "inf      23642\n",
      "persp     4563\n",
      "persm     4563\n",
      "Name: count, dtype: int64\n",
      "\n",
      "By dominant speaker and adjacent repeats:\n",
      "\n",
      "INF:\n",
      "n_adjacent_repeats\n",
      "0    14336\n",
      "1     7618\n",
      "2     1538\n",
      "3      144\n",
      "4        6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "PERSP:\n",
      "n_adjacent_repeats\n",
      "0    2436\n",
      "1    1679\n",
      "2     407\n",
      "3      40\n",
      "4       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "PERSM:\n",
      "n_adjacent_repeats\n",
      "0    2436\n",
      "1    1679\n",
      "2     407\n",
      "3      40\n",
      "4       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "Part 3: Non-repetitive, discriminating sequences\n",
      "======================================================================\n",
      "Found 594 candidates with:\n",
      "  - n_adjacent_repeats <= 2\n",
      "  - JS > 0.1\n",
      "  - marginal_P >= 4.33e-05 (top 10%)\n",
      "\n",
      "Top 20 non-repetitive discriminating sequences:\n",
      "Rank  JS      E[θ]Δ    AdjRep  Speaker  Sequence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     0.4799  0.2384   2       persp    mos,sou,sos,sos,sos\n",
      "2     0.4799  0.2384   2       persm    mou,sos,sou,sou,sou\n",
      "3     0.4713  0.2387   1       persp    mos,sos,sou,sos,sos\n",
      "4     0.4713  0.2387   1       persm    mou,sou,sos,sou,sou\n",
      "5     0.4643  0.2387   1       persp    mos,sos,sos,sou,sos\n",
      "6     0.4643  0.2387   1       persm    mou,sou,sou,sos,sou\n",
      "7     0.4640  0.2520   2       persm    mou,sou,sou,sos,sos\n",
      "8     0.4640  0.2520   2       persp    mos,sos,sos,sou,sou\n",
      "9     0.4599  0.2389   2       persm    mou,sou,sou,sou,sos\n",
      "10    0.4599  0.2389   2       persp    mos,sos,sos,sos,sou\n",
      "11    0.4582  0.2487   0       persm    mou,sou,sos,sou,sos\n",
      "12    0.4582  0.2487   0       persp    mos,sos,sou,sos,sou\n",
      "13    0.4547  0.2475   1       persm    mou,sou,sos,sos,sou\n",
      "14    0.4547  0.2475   1       persp    mos,sos,sou,sou,sos\n",
      "15    0.4524  0.0302   2       persp    sos,sou,sou,sou,sos\n",
      "16    0.4524  0.0302   2       persm    sou,sos,sos,sos,sou\n",
      "17    0.4513  0.2440   1       persp    mos,sou,sos,sos,sou\n",
      "18    0.4513  0.2440   1       persm    mou,sos,sou,sou,sos\n",
      "19    0.4479  0.2427   0       persp    mos,sou,sos,sou,sos\n",
      "20    0.4479  0.2427   0       persm    mou,sos,sou,sos,sou\n",
      "\n",
      "======================================================================\n",
      "Part 4: Top sequences by dominant speaker type\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "TOP INF-CHARACTERISTIC SEQUENCES (non-repetitive)\n",
      "============================================================\n",
      "Found 30 sequences\n",
      "\n",
      "Rank  JS      E[θ]Δ    AdjRep  max_P      Sequence\n",
      "------------------------------------------------------------------------------------------\n",
      "1     0.1467  0.0329   0       2.4626e-03 mos,nou,als,nou,als\n",
      "2     0.1467  0.0329   1       2.4626e-03 mos,als,nou,nou,als\n",
      "3     0.1467  0.0329   2       2.4626e-03 mos,nou,nou,nou,als\n",
      "4     0.1467  0.0329   2       2.4626e-03 mos,als,als,als,nou\n",
      "5     0.1467  0.0329   2       2.4626e-03 mos,nou,als,als,als\n",
      "6     0.1467  0.0329   2       2.4626e-03 mos,als,als,nou,nou\n",
      "7     0.1467  0.0329   0       2.4626e-03 mos,als,nou,als,nou\n",
      "8     0.1467  0.0329   1       2.4626e-03 mos,als,nou,als,als\n",
      "9     0.1467  0.0329   2       2.4626e-03 mos,als,nou,nou,nou\n",
      "10    0.1467  0.0329   1       2.4626e-03 mos,als,als,nou,als\n",
      "\n",
      "============================================================\n",
      "TOP PERSP-CHARACTERISTIC SEQUENCES (non-repetitive)\n",
      "============================================================\n",
      "Found 282 sequences\n",
      "\n",
      "Rank  JS      E[θ]Δ    AdjRep  max_P      Sequence\n",
      "------------------------------------------------------------------------------------------\n",
      "1     0.4799  0.2384   2       5.7598e-03 mos,sou,sos,sos,sos\n",
      "2     0.4713  0.2387   1       6.5091e-03 mos,sos,sou,sos,sos\n",
      "3     0.4643  0.2387   1       7.3939e-03 mos,sos,sos,sou,sos\n",
      "4     0.4640  0.2520   2       3.8982e-03 mos,sos,sos,sou,sou\n",
      "5     0.4599  0.2389   2       8.4089e-03 mos,sos,sos,sos,sou\n",
      "6     0.4582  0.2487   0       3.3263e-03 mos,sos,sou,sos,sou\n",
      "7     0.4547  0.2475   1       3.2244e-03 mos,sos,sou,sou,sos\n",
      "8     0.4524  0.0302   2       2.6970e-02 sos,sou,sou,sou,sos\n",
      "9     0.4513  0.2440   1       2.8546e-03 mos,sou,sos,sos,sou\n",
      "10    0.4479  0.2427   0       2.7762e-03 mos,sou,sos,sou,sos\n",
      "\n",
      "============================================================\n",
      "TOP PERSM-CHARACTERISTIC SEQUENCES (non-repetitive)\n",
      "============================================================\n",
      "Found 282 sequences\n",
      "\n",
      "Rank  JS      E[θ]Δ    AdjRep  max_P      Sequence\n",
      "------------------------------------------------------------------------------------------\n",
      "1     0.4799  0.2384   2       5.7598e-03 mou,sos,sou,sou,sou\n",
      "2     0.4713  0.2387   1       6.5091e-03 mou,sou,sos,sou,sou\n",
      "3     0.4643  0.2387   1       7.3939e-03 mou,sou,sou,sos,sou\n",
      "4     0.4640  0.2520   2       3.8982e-03 mou,sou,sou,sos,sos\n",
      "5     0.4599  0.2389   2       8.4089e-03 mou,sou,sou,sou,sos\n",
      "6     0.4582  0.2487   0       3.3263e-03 mou,sou,sos,sou,sos\n",
      "7     0.4547  0.2475   1       3.2244e-03 mou,sou,sos,sos,sou\n",
      "8     0.4524  0.0302   2       2.6970e-02 sou,sos,sos,sos,sou\n",
      "9     0.4513  0.2440   1       2.8546e-03 mou,sos,sou,sou,sos\n",
      "10    0.4479  0.2427   0       2.7762e-03 mou,sos,sou,sos,sou\n",
      "\n",
      "======================================================================\n",
      "Part 5: Finding INF-characteristic sequences (relaxed criteria)\n",
      "======================================================================\n",
      "\n",
      "INF-characteristic sequences are rare among top discriminators.\n",
      "Let's see what's available with relaxed criteria.\n",
      "\n",
      "INF-dominant sequences with ≤2 adjacent repeats: 23492\n",
      "\n",
      "Top 15 by JS divergence:\n",
      "Rank  JS      E[θ]Δ    AdjRep  marginal_P   Sequence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     0.1467  0.0329   2       1.8503e-04   mos,nou,nou,nou,als\n",
      "2     0.1467  0.0329   1       1.8503e-04   mos,als,als,nou,als\n",
      "3     0.1467  0.0329   1       1.8503e-04   mos,als,nou,nou,als\n",
      "4     0.1467  0.0329   1       1.8503e-04   mos,nou,nou,als,nou\n",
      "5     0.1467  0.0329   0       1.8503e-04   mos,als,nou,als,nou\n",
      "6     0.1467  0.0329   2       1.8503e-04   mos,nou,als,als,als\n",
      "7     0.1467  0.0329   1       1.8503e-04   mos,nou,als,nou,nou\n",
      "8     0.1467  0.0329   2       1.8503e-04   mos,nou,nou,als,als\n",
      "9     0.1467  0.0329   0       1.8503e-04   mos,nou,als,nou,als\n",
      "10    0.1467  0.0329   2       1.8503e-04   mos,als,als,als,nou\n",
      "11    0.1467  0.0329   2       1.8503e-04   mos,als,nou,nou,nou\n",
      "12    0.1467  0.0329   2       1.8503e-04   mos,als,als,nou,nou\n",
      "13    0.1467  0.0329   1       1.8503e-04   mos,als,nou,als,als\n",
      "14    0.1467  0.0329   1       1.8503e-04   mos,nou,als,als,nou\n",
      "15    0.1467  0.0329   1       1.8503e-04   mou,alu,nos,nos,alu\n",
      "\n",
      "======================================================================\n",
      "Part 6: Detailed analysis of best sequences per speaker type\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "BEST PERSP-CHARACTERISTIC (non-repetitive)\n",
      "============================================================\n",
      "\n",
      "Sequence: ('most,successful', 'some,unsuccessful', 'some,successful', 'some,successful', 'some,successful')\n",
      "Adjacent repeats: 2\n",
      "Dominant speaker: persp\n",
      "\n",
      "Discrimination:\n",
      "  JS(coop vs uncertain) = 0.4799\n",
      "  E[θ] diff = 0.2384\n",
      "  E[θ|seq, coop] = 0.6851\n",
      "  E[θ|seq, uncertain] = 0.4467\n",
      "\n",
      "Normalcy:\n",
      "  marginal_P = 6.8856e-04\n",
      "  max_P_inf = 1.0118e-05\n",
      "  max_P_persp = 5.7598e-03\n",
      "  max_P_persm = 1.4142e-03\n",
      "\n",
      "Posterior P(θ|seq):\n",
      "  θ      Coop       Uncertain  INF        PERSP      PERSM     \n",
      "  ------------------------------------------------------------\n",
      "  0.0    0.0000     0.0000     0.0000     0.0000     0.0000    \n",
      "  0.1    0.0000     0.0065     0.0000     0.0072     0.0000    \n",
      "  0.2    0.0004     0.1006     0.0004     0.1109     0.0000    \n",
      "  0.3    0.0028     0.2412     0.0028     0.2660     0.0001    \n",
      "  0.4    0.0150     0.2536     0.0150     0.2795     0.0007    \n",
      "  0.5    0.0771     0.1691     0.0771     0.1860     0.0039    \n",
      "  0.6    0.2427     0.0884     0.2427     0.0954     0.0173    \n",
      "  0.7    0.3851     0.0432     0.3851     0.0404     0.0664    \n",
      "  0.8    0.2478     0.0334     0.2478     0.0128     0.2338    \n",
      "  0.9    0.0292     0.0640     0.0292     0.0019     0.6778    \n",
      "  1.0    0.0000     0.0000     0.0000     0.0000     0.0000    \n",
      "\n",
      "============================================================\n",
      "BEST PERSM-CHARACTERISTIC (non-repetitive)\n",
      "============================================================\n",
      "\n",
      "Sequence: ('most,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "Adjacent repeats: 2\n",
      "Dominant speaker: persm\n",
      "\n",
      "Discrimination:\n",
      "  JS(coop vs uncertain) = 0.4799\n",
      "  E[θ] diff = 0.2384\n",
      "  E[θ|seq, coop] = 0.3149\n",
      "  E[θ|seq, uncertain] = 0.5533\n",
      "\n",
      "Normalcy:\n",
      "  marginal_P = 6.8856e-04\n",
      "  max_P_inf = 1.0118e-05\n",
      "  max_P_persp = 1.4142e-03\n",
      "  max_P_persm = 5.7598e-03\n",
      "\n",
      "Posterior P(θ|seq):\n",
      "  θ      Coop       Uncertain  INF        PERSP      PERSM     \n",
      "  ------------------------------------------------------------\n",
      "  0.0    0.0000     0.0000     0.0000     0.0000     0.0000    \n",
      "  0.1    0.0292     0.0640     0.0292     0.6778     0.0019    \n",
      "  0.2    0.2478     0.0334     0.2478     0.2338     0.0128    \n",
      "  0.3    0.3851     0.0432     0.3851     0.0664     0.0404    \n",
      "  0.4    0.2427     0.0884     0.2427     0.0173     0.0954    \n",
      "  0.5    0.0771     0.1691     0.0771     0.0039     0.1860    \n",
      "  0.6    0.0150     0.2536     0.0150     0.0007     0.2795    \n",
      "  0.7    0.0028     0.2412     0.0028     0.0001     0.2660    \n",
      "  0.8    0.0004     0.1006     0.0004     0.0000     0.1109    \n",
      "  0.9    0.0000     0.0065     0.0000     0.0000     0.0072    \n",
      "  1.0    0.0000     0.0000     0.0000     0.0000     0.0000    \n",
      "\n",
      "============================================================\n",
      "BEST INF-CHARACTERISTIC (relaxed normalcy)\n",
      "============================================================\n",
      "\n",
      "Sequence: ('most,successful', 'all,successful', 'all,successful', 'all,successful', 'no,unsuccessful')\n",
      "Adjacent repeats: 2\n",
      "Dominant speaker: inf\n",
      "\n",
      "Discrimination:\n",
      "  JS(coop vs uncertain) = 0.1467\n",
      "  E[θ] diff = 0.0329\n",
      "  E[θ|seq, coop] = 0.8860\n",
      "  E[θ|seq, uncertain] = 0.9189\n",
      "\n",
      "Normalcy:\n",
      "  marginal_P = 1.8503e-04\n",
      "  max_P_inf = 2.4626e-03\n",
      "  max_P_persp = 1.7580e-03\n",
      "  max_P_persm = 1.6244e-11\n",
      "\n",
      "Posterior P(θ|seq):\n",
      "  θ      Coop       Uncertain  INF        PERSP      PERSM     \n",
      "  ------------------------------------------------------------\n",
      "  0.0    0.0000     0.0000     0.0000     0.0000     0.0000    \n",
      "  0.1    0.0000     0.0000     0.0000     0.0000     0.0000    \n",
      "  0.2    0.0000     0.0000     0.0000     0.0000     0.0000    \n",
      "  0.3    0.0000     0.0000     0.0000     0.0000     0.0000    \n",
      "  0.4    0.0000     0.0000     0.0000     0.0000     0.0000    \n",
      "  0.5    0.0000     0.0000     0.0000     0.0000     0.0000    \n",
      "  0.6    0.0004     0.0003     0.0004     0.0002     0.0000    \n",
      "  0.7    0.0094     0.0065     0.0094     0.0040     0.0002    \n",
      "  0.8    0.1250     0.0875     0.1250     0.0544     0.0045    \n",
      "  0.9    0.8602     0.6154     0.8602     0.3993     0.0733    \n",
      "  1.0    0.0050     0.2902     0.0050     0.5421     0.9219    \n",
      "\n",
      "======================================================================\n",
      "Part 7: Summary - Recommended sequences for experiment\n",
      "======================================================================\n",
      "\n",
      "SELECTION CRITERIA:\n",
      "- Non-repetitive (≤2 adjacent same utterances)\n",
      "- Discriminating (JS > threshold)\n",
      "- Normal (top 10% by marginal probability, where possible)\n",
      "- Representative of each speaker type\n",
      "\n",
      "\n",
      "RECOMMENDED SEQUENCES:\n",
      "\n",
      "\n",
      "--- PERSP-characteristic ---\n",
      "  mos,sou,sos,sos,sos\n",
      "    JS=0.4799, E[θ] diff=0.2384, AdjRep=2, P=6.89e-04\n",
      "    Coop E[θ]=0.685, Uncertain E[θ]=0.447\n",
      "  mos,sos,sou,sos,sos\n",
      "    JS=0.4713, E[θ] diff=0.2387, AdjRep=1, P=7.68e-04\n",
      "    Coop E[θ]=0.684, Uncertain E[θ]=0.446\n",
      "  mos,sos,sos,sou,sos\n",
      "    JS=0.4643, E[θ] diff=0.2387, AdjRep=1, P=8.63e-04\n",
      "    Coop E[θ]=0.684, Uncertain E[θ]=0.445\n",
      "  mos,sos,sos,sou,sou\n",
      "    JS=0.4640, E[θ] diff=0.2520, AdjRep=2, P=5.25e-04\n",
      "    Coop E[θ]=0.688, Uncertain E[θ]=0.436\n",
      "  mos,sos,sos,sos,sou\n",
      "    JS=0.4599, E[θ] diff=0.2389, AdjRep=2, P=9.71e-04\n",
      "    Coop E[θ]=0.684, Uncertain E[θ]=0.445\n",
      "\n",
      "--- PERSM-characteristic ---\n",
      "  mou,sos,sou,sou,sou\n",
      "    JS=0.4799, E[θ] diff=0.2384, AdjRep=2, P=6.89e-04\n",
      "    Coop E[θ]=0.315, Uncertain E[θ]=0.553\n",
      "  mou,sou,sos,sou,sou\n",
      "    JS=0.4713, E[θ] diff=0.2387, AdjRep=1, P=7.68e-04\n",
      "    Coop E[θ]=0.316, Uncertain E[θ]=0.554\n",
      "  mou,sou,sou,sos,sou\n",
      "    JS=0.4643, E[θ] diff=0.2387, AdjRep=1, P=8.63e-04\n",
      "    Coop E[θ]=0.316, Uncertain E[θ]=0.555\n",
      "  mou,sou,sou,sos,sos\n",
      "    JS=0.4640, E[θ] diff=0.2520, AdjRep=2, P=5.25e-04\n",
      "    Coop E[θ]=0.312, Uncertain E[θ]=0.564\n",
      "  mou,sou,sou,sou,sos\n",
      "    JS=0.4599, E[θ] diff=0.2389, AdjRep=2, P=9.71e-04\n",
      "    Coop E[θ]=0.316, Uncertain E[θ]=0.555\n",
      "\n",
      "--- INF-characteristic ---\n",
      "  mos,nou,nou,nou,als\n",
      "    JS=0.1467, E[θ] diff=0.0329, AdjRep=2, P=1.85e-04\n",
      "    Coop E[θ]=0.886, Uncertain E[θ]=0.919\n",
      "  mos,als,als,nou,als\n",
      "    JS=0.1467, E[θ] diff=0.0329, AdjRep=1, P=1.85e-04\n",
      "    Coop E[θ]=0.886, Uncertain E[θ]=0.919\n",
      "  mos,als,nou,nou,als\n",
      "    JS=0.1467, E[θ] diff=0.0329, AdjRep=1, P=1.85e-04\n",
      "    Coop E[θ]=0.886, Uncertain E[θ]=0.919\n",
      "  mos,nou,nou,als,nou\n",
      "    JS=0.1467, E[θ] diff=0.0329, AdjRep=1, P=1.85e-04\n",
      "    Coop E[θ]=0.886, Uncertain E[θ]=0.919\n",
      "  mos,als,nou,als,nou\n",
      "    JS=0.1467, E[θ] diff=0.0329, AdjRep=0, P=1.85e-04\n",
      "    Coop E[θ]=0.886, Uncertain E[θ]=0.919\n",
      "\n",
      "Saved: recommended_sequences_by_speaker.csv\n",
      "Saved: discrimination_analysis_results_full.csv\n",
      "\n",
      "======================================================================\n",
      "Part 8: Trade-off analysis\n",
      "======================================================================\n",
      "\n",
      "Examining the trade-off between:\n",
      "- Discrimination (JS divergence)\n",
      "- Non-repetitiveness (adjacent repeats)\n",
      "- Normalcy (marginal probability)\n",
      "\n",
      "\n",
      "Mean JS by adjacent repeats and dominant speaker:\n",
      "AdjRep   INF          PERSP        PERSM        All         \n",
      "--------------------------------------------------------\n",
      "0        0.0021       0.0468       0.0468       0.0135      \n",
      "1        0.0023       0.0695       0.0695       0.0229      \n",
      "2        0.0035       0.1020       0.1020       0.0376      \n",
      "3        0.0058       0.1737       0.1737       0.0658      \n",
      "4        0.0003       0.6739       0.6739       0.1687      \n",
      "\n",
      "Max JS by adjacent repeats and dominant speaker:\n",
      "AdjRep   INF          PERSP        PERSM        All         \n",
      "--------------------------------------------------------\n",
      "0        0.1467       0.4582       0.4582       0.4582      \n",
      "1        0.1467       0.4713       0.4713       0.4713      \n",
      "2        0.1467       0.4799       0.4799       0.4799      \n",
      "3        0.1467       0.4493       0.4493       0.4493      \n",
      "4        0.0008       0.6739       0.6739       0.6739      \n",
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "KEY FINDINGS:\n",
      "\n",
      "1. DISCRIMINATION vs REPETITIVENESS TRADE-OFF:\n",
      "   - Highest JS divergence comes from highly repetitive sequences\n",
      "   - But non-repetitive sequences (≤2 adj repeats) can still achieve JS > 0.3\n",
      "\n",
      "2. SPEAKER-CHARACTERISTIC PATTERNS:\n",
      "   - PERSP-characteristic: Many high-discrimination options available\n",
      "   - PERSM-characteristic: Symmetric to PERSP (mirror sequences)\n",
      "   - INF-characteristic: Harder to find - INF rarely dominates\n",
      "\n",
      "3. WHY INF-CHARACTERISTIC IS RARE:\n",
      "   - Informative speaker uses strong quantifiers (\"all\", \"most\", \"no\")\n",
      "   - These are also used by persuasive speakers at extreme θ\n",
      "   - So sequences with strong quantifiers are often dominated by PERSP or PERSM\n",
      "\n",
      "4. RECOMMENDED EXPERIMENT DESIGN:\n",
      "   - Include PERSP and PERSM characteristic sequences (good discrimination)\n",
      "   - INF-characteristic may need relaxed criteria or different approach\n",
      "   - Balance variety across sequences to avoid participant fatigue\n",
      "\n",
      "SAVED FILES:\n",
      "- recommended_sequences_by_speaker.csv: Top sequences per speaker type\n",
      "- discrimination_analysis_results_full.csv: Full results with all metrics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ANALYSIS: NON-REPETITIVE, SPEAKER-CHARACTERISTIC SEQUENCES\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"NON-REPETITIVE, SPEAKER-CHARACTERISTIC SEQUENCES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 1: Add repetitiveness metrics to results\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 1: Computing repetitiveness metrics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def count_adjacent_repeats(seq):\n",
    "    \"\"\"Count how many adjacent pairs are the same utterance (0-4).\"\"\"\n",
    "    count = 0\n",
    "    for i in range(len(seq) - 1):\n",
    "        if seq[i] == seq[i + 1]:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_total_repeats(seq):\n",
    "    \"\"\"Count total repetitions: 5 - number of unique utterances.\"\"\"\n",
    "    return 5 - len(set(seq))\n",
    "\n",
    "def get_dominant_quantifier(seq):\n",
    "    \"\"\"Get the most common quantifier in the sequence.\"\"\"\n",
    "    quantifiers = [u.split(',')[0] for u in seq]\n",
    "    from collections import Counter\n",
    "    counts = Counter(quantifiers)\n",
    "    return counts.most_common(1)[0][0]\n",
    "\n",
    "def get_dominant_outcome(seq):\n",
    "    \"\"\"Get the most common outcome in the sequence.\"\"\"\n",
    "    outcomes = [u.split(',')[1] for u in seq]\n",
    "    from collections import Counter\n",
    "    counts = Counter(outcomes)\n",
    "    return counts.most_common(1)[0][0]\n",
    "\n",
    "# Add metrics to results DataFrame\n",
    "results_discrimination['n_adjacent_repeats'] = [\n",
    "    count_adjacent_repeats(seq) for seq in results_discrimination['sequence']\n",
    "]\n",
    "results_discrimination['n_total_repeats'] = [\n",
    "    count_total_repeats(seq) for seq in results_discrimination['sequence']\n",
    "]\n",
    "results_discrimination['dominant_quantifier'] = [\n",
    "    get_dominant_quantifier(seq) for seq in results_discrimination['sequence']\n",
    "]\n",
    "results_discrimination['dominant_outcome'] = [\n",
    "    get_dominant_outcome(seq) for seq in results_discrimination['sequence']\n",
    "]\n",
    "\n",
    "print(\"Repetitiveness distribution:\")\n",
    "print(results_discrimination['n_adjacent_repeats'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nBy adjacent repeats, mean JS divergence:\")\n",
    "for n_rep in range(5):\n",
    "    subset = results_discrimination[results_discrimination['n_adjacent_repeats'] == n_rep]\n",
    "    print(f\"  {n_rep} adjacent repeats: n={len(subset)}, mean JS={subset['js_coop_vs_uncertain'].mean():.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 2: Categorize by dominant speaker type\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 2: Categorizing by dominant speaker type\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "For each sequence, determine which speaker type finds it MOST likely.\n",
    "- \"inf-characteristic\": max_P_inf > max_P_persp AND max_P_inf > max_P_persm\n",
    "- \"persp-characteristic\": max_P_persp is highest\n",
    "- \"persm-characteristic\": max_P_persm is highest\n",
    "\"\"\")\n",
    "\n",
    "def categorize_by_speaker(row):\n",
    "    \"\"\"Determine which speaker type this sequence is most characteristic of.\"\"\"\n",
    "    max_inf = row['max_P_inf']\n",
    "    max_persp = row['max_P_persp']\n",
    "    max_persm = row['max_P_persm']\n",
    "    \n",
    "    if max_inf >= max_persp and max_inf >= max_persm:\n",
    "        return 'inf'\n",
    "    elif max_persp >= max_inf and max_persp >= max_persm:\n",
    "        return 'persp'\n",
    "    else:\n",
    "        return 'persm'\n",
    "\n",
    "def get_speaker_dominance_ratio(row):\n",
    "    \"\"\"How much more likely is this for the dominant speaker vs others?\"\"\"\n",
    "    max_inf = row['max_P_inf']\n",
    "    max_persp = row['max_P_persp']\n",
    "    max_persm = row['max_P_persm']\n",
    "    \n",
    "    max_val = max(max_inf, max_persp, max_persm)\n",
    "    second_max = sorted([max_inf, max_persp, max_persm])[-2]\n",
    "    \n",
    "    if second_max > 0:\n",
    "        return max_val / second_max\n",
    "    else:\n",
    "        return float('inf')\n",
    "\n",
    "results_discrimination['dominant_speaker'] = results_discrimination.apply(categorize_by_speaker, axis=1)\n",
    "results_discrimination['speaker_dominance_ratio'] = results_discrimination.apply(get_speaker_dominance_ratio, axis=1)\n",
    "\n",
    "print(\"\\nDistribution of dominant speaker:\")\n",
    "print(results_discrimination['dominant_speaker'].value_counts())\n",
    "\n",
    "print(\"\\nBy dominant speaker and adjacent repeats:\")\n",
    "for speaker in ['inf', 'persp', 'persm']:\n",
    "    print(f\"\\n{speaker.upper()}:\")\n",
    "    subset = results_discrimination[results_discrimination['dominant_speaker'] == speaker]\n",
    "    print(subset['n_adjacent_repeats'].value_counts().sort_index())\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 3: Filter for non-repetitive, discriminating sequences\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 3: Non-repetitive, discriminating sequences\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Criteria:\n",
    "# - n_adjacent_repeats <= 2 (at most 2 adjacent same utterances)\n",
    "# - js_coop_vs_uncertain > 0.1 (meaningful discrimination)\n",
    "# - marginal_P >= 10th percentile (not too weird)\n",
    "\n",
    "threshold_normalcy = np.percentile(marginal_P, 90)\n",
    "\n",
    "candidates_nonrep = results_discrimination[\n",
    "    (results_discrimination['n_adjacent_repeats'] <= 2) &\n",
    "    (results_discrimination['js_coop_vs_uncertain'] > 0.1) &\n",
    "    (results_discrimination['marginal_P'] >= threshold_normalcy)\n",
    "].copy()\n",
    "\n",
    "print(f\"Found {len(candidates_nonrep)} candidates with:\")\n",
    "print(f\"  - n_adjacent_repeats <= 2\")\n",
    "print(f\"  - JS > 0.1\")\n",
    "print(f\"  - marginal_P >= {threshold_normalcy:.2e} (top 10%)\")\n",
    "\n",
    "# Sort by JS divergence\n",
    "candidates_nonrep = candidates_nonrep.sort_values('js_coop_vs_uncertain', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 non-repetitive discriminating sequences:\")\n",
    "print(f\"{'Rank':<5} {'JS':<7} {'E[θ]Δ':<8} {'AdjRep':<7} {'Speaker':<8} {'Sequence'}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for rank, (idx, row) in enumerate(candidates_nonrep.head(20).iterrows(), 1):\n",
    "    seq = row['sequence']\n",
    "    abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "    print(f\"{rank:<5} {row['js_coop_vs_uncertain']:<7.4f} {row['E_theta_diff']:<8.4f} \"\n",
    "          f\"{row['n_adjacent_repeats']:<7} {row['dominant_speaker']:<8} {abbrev}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 4: Breakdown by dominant speaker type\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 4: Top sequences by dominant speaker type\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for speaker in ['inf', 'persp', 'persm']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TOP {speaker.upper()}-CHARACTERISTIC SEQUENCES (non-repetitive)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    subset = candidates_nonrep[candidates_nonrep['dominant_speaker'] == speaker]\n",
    "    subset = subset.sort_values('js_coop_vs_uncertain', ascending=False)\n",
    "    \n",
    "    print(f\"Found {len(subset)} sequences\")\n",
    "    \n",
    "    if len(subset) == 0:\n",
    "        print(\"  (none found with current criteria)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'Rank':<5} {'JS':<7} {'E[θ]Δ':<8} {'AdjRep':<7} {'max_P':<10} {'Sequence'}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for rank, (idx, row) in enumerate(subset.head(10).iterrows(), 1):\n",
    "        seq = row['sequence']\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "        max_p = row[f'max_P_{speaker}']\n",
    "        print(f\"{rank:<5} {row['js_coop_vs_uncertain']:<7.4f} {row['E_theta_diff']:<8.4f} \"\n",
    "              f\"{row['n_adjacent_repeats']:<7} {max_p:<10.4e} {abbrev}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 5: Relax criteria to find INF-characteristic sequences\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 5: Finding INF-characteristic sequences (relaxed criteria)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "INF-characteristic sequences are rare among top discriminators.\n",
    "Let's see what's available with relaxed criteria.\n",
    "\"\"\")\n",
    "\n",
    "# More relaxed: just require inf is dominant\n",
    "inf_sequences = results_discrimination[\n",
    "    (results_discrimination['dominant_speaker'] == 'inf') &\n",
    "    (results_discrimination['n_adjacent_repeats'] <= 2)\n",
    "].sort_values('js_coop_vs_uncertain', ascending=False)\n",
    "\n",
    "print(f\"INF-dominant sequences with ≤2 adjacent repeats: {len(inf_sequences)}\")\n",
    "print(f\"\\nTop 15 by JS divergence:\")\n",
    "print(f\"{'Rank':<5} {'JS':<7} {'E[θ]Δ':<8} {'AdjRep':<7} {'marginal_P':<12} {'Sequence'}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for rank, (idx, row) in enumerate(inf_sequences.head(15).iterrows(), 1):\n",
    "    seq = row['sequence']\n",
    "    abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "    print(f\"{rank:<5} {row['js_coop_vs_uncertain']:<7.4f} {row['E_theta_diff']:<8.4f} \"\n",
    "          f\"{row['n_adjacent_repeats']:<7} {row['marginal_P']:<12.4e} {abbrev}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 6: Detailed analysis of best non-repetitive sequences per speaker\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 6: Detailed analysis of best sequences per speaker type\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def analyze_sequence_detail(idx, row):\n",
    "    \"\"\"Print detailed analysis for a sequence.\"\"\"\n",
    "    seq = row['sequence']\n",
    "    \n",
    "    print(f\"\\nSequence: {seq}\")\n",
    "    print(f\"Adjacent repeats: {row['n_adjacent_repeats']}\")\n",
    "    print(f\"Dominant speaker: {row['dominant_speaker']}\")\n",
    "    \n",
    "    print(f\"\\nDiscrimination:\")\n",
    "    print(f\"  JS(coop vs uncertain) = {row['js_coop_vs_uncertain']:.4f}\")\n",
    "    print(f\"  E[θ] diff = {row['E_theta_diff']:.4f}\")\n",
    "    print(f\"  E[θ|seq, coop] = {row['E_theta_coop']:.4f}\")\n",
    "    print(f\"  E[θ|seq, uncertain] = {row['E_theta_uncertain']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nNormalcy:\")\n",
    "    print(f\"  marginal_P = {row['marginal_P']:.4e}\")\n",
    "    print(f\"  max_P_inf = {row['max_P_inf']:.4e}\")\n",
    "    print(f\"  max_P_persp = {row['max_P_persp']:.4e}\")\n",
    "    print(f\"  max_P_persm = {row['max_P_persm']:.4e}\")\n",
    "    \n",
    "    print(f\"\\nPosterior P(θ|seq):\")\n",
    "    print(f\"  {'θ':<6} {'Coop':<10} {'Uncertain':<10} {'INF':<10} {'PERSP':<10} {'PERSM':<10}\")\n",
    "    print(\"  \" + \"-\"*60)\n",
    "    \n",
    "    for i, theta in enumerate(theta_values):\n",
    "        print(f\"  {theta:<6.1f} {P_theta_given_seq_coop[idx, i]:<10.4f} \"\n",
    "              f\"{P_theta_given_seq_uncertain[idx, i]:<10.4f} \"\n",
    "              f\"{P_theta_given_seq_inf[idx, i]:<10.4f} \"\n",
    "              f\"{P_theta_given_seq_persp[idx, i]:<10.4f} \"\n",
    "              f\"{P_theta_given_seq_persm[idx, i]:<10.4f}\")\n",
    "\n",
    "# Best PERSP-characteristic (non-repetitive)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST PERSP-CHARACTERISTIC (non-repetitive)\")\n",
    "print(\"=\"*60)\n",
    "persp_subset = candidates_nonrep[candidates_nonrep['dominant_speaker'] == 'persp']\n",
    "if len(persp_subset) > 0:\n",
    "    best_idx = persp_subset['js_coop_vs_uncertain'].idxmax()\n",
    "    analyze_sequence_detail(best_idx, persp_subset.loc[best_idx])\n",
    "\n",
    "# Best PERSM-characteristic (non-repetitive)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST PERSM-CHARACTERISTIC (non-repetitive)\")\n",
    "print(\"=\"*60)\n",
    "persm_subset = candidates_nonrep[candidates_nonrep['dominant_speaker'] == 'persm']\n",
    "if len(persm_subset) > 0:\n",
    "    best_idx = persm_subset['js_coop_vs_uncertain'].idxmax()\n",
    "    analyze_sequence_detail(best_idx, persm_subset.loc[best_idx])\n",
    "\n",
    "# Best INF-characteristic (with relaxed normalcy)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST INF-CHARACTERISTIC (relaxed normalcy)\")\n",
    "print(\"=\"*60)\n",
    "inf_subset = results_discrimination[\n",
    "    (results_discrimination['dominant_speaker'] == 'inf') &\n",
    "    (results_discrimination['n_adjacent_repeats'] <= 2) &\n",
    "    (results_discrimination['js_coop_vs_uncertain'] > 0.01)\n",
    "]\n",
    "if len(inf_subset) > 0:\n",
    "    best_idx = inf_subset['js_coop_vs_uncertain'].idxmax()\n",
    "    analyze_sequence_detail(best_idx, inf_subset.loc[best_idx])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 7: Summary table for experiment\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 7: Summary - Recommended sequences for experiment\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "SELECTION CRITERIA:\n",
    "- Non-repetitive (≤2 adjacent same utterances)\n",
    "- Discriminating (JS > threshold)\n",
    "- Normal (top 10% by marginal probability, where possible)\n",
    "- Representative of each speaker type\n",
    "\"\"\")\n",
    "\n",
    "# Collect recommendations\n",
    "recommendations = []\n",
    "\n",
    "# PERSP-characteristic\n",
    "persp_recs = candidates_nonrep[candidates_nonrep['dominant_speaker'] == 'persp'].head(5)\n",
    "for _, row in persp_recs.iterrows():\n",
    "    recommendations.append({\n",
    "        'category': 'PERSP-characteristic',\n",
    "        'sequence': row['sequence'],\n",
    "        'js': row['js_coop_vs_uncertain'],\n",
    "        'E_theta_diff': row['E_theta_diff'],\n",
    "        'n_adj_rep': row['n_adjacent_repeats'],\n",
    "        'marginal_P': row['marginal_P'],\n",
    "        'E_theta_coop': row['E_theta_coop'],\n",
    "        'E_theta_uncertain': row['E_theta_uncertain']\n",
    "    })\n",
    "\n",
    "# PERSM-characteristic\n",
    "persm_recs = candidates_nonrep[candidates_nonrep['dominant_speaker'] == 'persm'].head(5)\n",
    "for _, row in persm_recs.iterrows():\n",
    "    recommendations.append({\n",
    "        'category': 'PERSM-characteristic',\n",
    "        'sequence': row['sequence'],\n",
    "        'js': row['js_coop_vs_uncertain'],\n",
    "        'E_theta_diff': row['E_theta_diff'],\n",
    "        'n_adj_rep': row['n_adjacent_repeats'],\n",
    "        'marginal_P': row['marginal_P'],\n",
    "        'E_theta_coop': row['E_theta_coop'],\n",
    "        'E_theta_uncertain': row['E_theta_uncertain']\n",
    "    })\n",
    "\n",
    "# INF-characteristic (relaxed criteria)\n",
    "inf_recs = inf_sequences.head(5)\n",
    "for _, row in inf_recs.iterrows():\n",
    "    recommendations.append({\n",
    "        'category': 'INF-characteristic',\n",
    "        'sequence': row['sequence'],\n",
    "        'js': row['js_coop_vs_uncertain'],\n",
    "        'E_theta_diff': row['E_theta_diff'],\n",
    "        'n_adj_rep': row['n_adjacent_repeats'],\n",
    "        'marginal_P': row['marginal_P'],\n",
    "        'E_theta_coop': row['E_theta_coop'],\n",
    "        'E_theta_uncertain': row['E_theta_uncertain']\n",
    "    })\n",
    "\n",
    "rec_df = pd.DataFrame(recommendations)\n",
    "\n",
    "print(\"\\nRECOMMENDED SEQUENCES:\\n\")\n",
    "\n",
    "for category in ['PERSP-characteristic', 'PERSM-characteristic', 'INF-characteristic']:\n",
    "    print(f\"\\n--- {category} ---\")\n",
    "    subset = rec_df[rec_df['category'] == category]\n",
    "    \n",
    "    for i, row in subset.iterrows():\n",
    "        seq = row['sequence']\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "        print(f\"  {abbrev}\")\n",
    "        print(f\"    JS={row['js']:.4f}, E[θ] diff={row['E_theta_diff']:.4f}, \"\n",
    "              f\"AdjRep={row['n_adj_rep']}, P={row['marginal_P']:.2e}\")\n",
    "        print(f\"    Coop E[θ]={row['E_theta_coop']:.3f}, Uncertain E[θ]={row['E_theta_uncertain']:.3f}\")\n",
    "\n",
    "# Save recommendations\n",
    "rec_df.to_csv('recommended_sequences_by_speaker.csv', index=False)\n",
    "print(\"\\nSaved: recommended_sequences_by_speaker.csv\")\n",
    "\n",
    "# Also update the full results\n",
    "results_discrimination.to_csv('discrimination_analysis_results_full.csv', index=False)\n",
    "print(\"Saved: discrimination_analysis_results_full.csv\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 8: Visualize the trade-off\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Part 8: Trade-off analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Examining the trade-off between:\n",
    "- Discrimination (JS divergence)\n",
    "- Non-repetitiveness (adjacent repeats)\n",
    "- Normalcy (marginal probability)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nMean JS by adjacent repeats and dominant speaker:\")\n",
    "print(f\"{'AdjRep':<8} {'INF':<12} {'PERSP':<12} {'PERSM':<12} {'All':<12}\")\n",
    "print(\"-\" * 56)\n",
    "\n",
    "for n_rep in range(5):\n",
    "    js_inf = results_discrimination[\n",
    "        (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "        (results_discrimination['dominant_speaker'] == 'inf')\n",
    "    ]['js_coop_vs_uncertain'].mean()\n",
    "    \n",
    "    js_persp = results_discrimination[\n",
    "        (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "        (results_discrimination['dominant_speaker'] == 'persp')\n",
    "    ]['js_coop_vs_uncertain'].mean()\n",
    "    \n",
    "    js_persm = results_discrimination[\n",
    "        (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "        (results_discrimination['dominant_speaker'] == 'persm')\n",
    "    ]['js_coop_vs_uncertain'].mean()\n",
    "    \n",
    "    js_all = results_discrimination[\n",
    "        results_discrimination['n_adjacent_repeats'] == n_rep\n",
    "    ]['js_coop_vs_uncertain'].mean()\n",
    "    \n",
    "    print(f\"{n_rep:<8} {js_inf:<12.4f} {js_persp:<12.4f} {js_persm:<12.4f} {js_all:<12.4f}\")\n",
    "\n",
    "print(\"\\nMax JS by adjacent repeats and dominant speaker:\")\n",
    "print(f\"{'AdjRep':<8} {'INF':<12} {'PERSP':<12} {'PERSM':<12} {'All':<12}\")\n",
    "print(\"-\" * 56)\n",
    "\n",
    "for n_rep in range(5):\n",
    "    js_inf = results_discrimination[\n",
    "        (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "        (results_discrimination['dominant_speaker'] == 'inf')\n",
    "    ]['js_coop_vs_uncertain'].max()\n",
    "    \n",
    "    js_persp = results_discrimination[\n",
    "        (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "        (results_discrimination['dominant_speaker'] == 'persp')\n",
    "    ]['js_coop_vs_uncertain'].max()\n",
    "    \n",
    "    js_persm = results_discrimination[\n",
    "        (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "        (results_discrimination['dominant_speaker'] == 'persm')\n",
    "    ]['js_coop_vs_uncertain'].max()\n",
    "    \n",
    "    js_all = results_discrimination[\n",
    "        results_discrimination['n_adjacent_repeats'] == n_rep\n",
    "    ]['js_coop_vs_uncertain'].max()\n",
    "    \n",
    "    print(f\"{n_rep:<8} {js_inf:<12.4f} {js_persp:<12.4f} {js_persm:<12.4f} {js_all:<12.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 9: Final summary\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "KEY FINDINGS:\n",
    "\n",
    "1. DISCRIMINATION vs REPETITIVENESS TRADE-OFF:\n",
    "   - Highest JS divergence comes from highly repetitive sequences\n",
    "   - But non-repetitive sequences (≤2 adj repeats) can still achieve JS > 0.3\n",
    "\n",
    "2. SPEAKER-CHARACTERISTIC PATTERNS:\n",
    "   - PERSP-characteristic: Many high-discrimination options available\n",
    "   - PERSM-characteristic: Symmetric to PERSP (mirror sequences)\n",
    "   - INF-characteristic: Harder to find - INF rarely dominates\n",
    "\n",
    "3. WHY INF-CHARACTERISTIC IS RARE:\n",
    "   - Informative speaker uses strong quantifiers (\"all\", \"most\", \"no\")\n",
    "   - These are also used by persuasive speakers at extreme θ\n",
    "   - So sequences with strong quantifiers are often dominated by PERSP or PERSM\n",
    "\n",
    "4. RECOMMENDED EXPERIMENT DESIGN:\n",
    "   - Include PERSP and PERSM characteristic sequences (good discrimination)\n",
    "   - INF-characteristic may need relaxed criteria or different approach\n",
    "   - Balance variety across sequences to avoid participant fatigue\n",
    "\n",
    "SAVED FILES:\n",
    "- recommended_sequences_by_speaker.csv: Top sequences per speaker type\n",
    "- discrimination_analysis_results_full.csv: Full results with all metrics\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "208217f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ADJACENT REPEATS × DOMINANT SPEAKER ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TABLE 1: COUNT\n",
      "======================================================================\n",
      "\n",
      "AdjRep             INF       PERSP       PERSM       TOTAL\n",
      "----------------------------------------------------------\n",
      "0                14336        2436        2436       19208\n",
      "1                 7618        1679        1679       10976\n",
      "2                 1538         407         407        2352\n",
      "3                  144          40          40         224\n",
      "4                    6           1           1           8\n",
      "----------------------------------------------------------\n",
      "TOTAL            23642        4563        4563       32768\n",
      "\n",
      "======================================================================\n",
      "TABLE 2: MEAN JS DIVERGENCE\n",
      "======================================================================\n",
      "\n",
      "AdjRep             INF       PERSP       PERSM         ALL\n",
      "----------------------------------------------------------\n",
      "0               0.0021      0.0468      0.0468      0.0135\n",
      "1               0.0023      0.0695      0.0695      0.0229\n",
      "2               0.0035      0.1020      0.1020      0.0376\n",
      "3               0.0058      0.1737      0.1737      0.0658\n",
      "4               0.0003      0.6739      0.6739      0.1687\n",
      "----------------------------------------------------------\n",
      "ALL             0.0023      0.0614      0.0614      0.0187\n",
      "\n",
      "======================================================================\n",
      "TABLE 3: MAX JS DIVERGENCE\n",
      "======================================================================\n",
      "\n",
      "AdjRep             INF       PERSP       PERSM         ALL\n",
      "----------------------------------------------------------\n",
      "0               0.1467      0.4582      0.4582      0.4582\n",
      "1               0.1467      0.4713      0.4713      0.4713\n",
      "2               0.1467      0.4799      0.4799      0.4799\n",
      "3               0.1467      0.4493      0.4493      0.4493\n",
      "4               0.0008      0.6739      0.6739      0.6739\n",
      "----------------------------------------------------------\n",
      "ALL             0.1467      0.6739      0.6739      0.6739\n",
      "\n",
      "======================================================================\n",
      "TABLE 4: COMBINED (Count / Mean JS / Max JS)\n",
      "======================================================================\n",
      "\n",
      "AdjRep               INF                          PERSP                         PERSM             \n",
      "             Count      Mean       Max     Count      Mean       Max     Count      Mean       Max\n",
      "--------------------------------------------------------------------------------------------------\n",
      "0            14336    0.0021    0.1467      2436    0.0468    0.4582      2436    0.0468    0.4582\n",
      "1             7618    0.0023    0.1467      1679    0.0695    0.4713      1679    0.0695    0.4713\n",
      "2             1538    0.0035    0.1467       407    0.1020    0.4799       407    0.1020    0.4799\n",
      "3              144    0.0058    0.1467        40    0.1737    0.4493        40    0.1737    0.4493\n",
      "4                6    0.0003    0.0008         1    0.6739    0.6739         1    0.6739    0.6739\n",
      "--------------------------------------------------------------------------------------------------\n",
      "TOTAL        23642    0.0023    0.1467      4563    0.0614    0.6739      4563    0.0614    0.6739\n",
      "\n",
      "======================================================================\n",
      "Saving tables to CSV...\n",
      "======================================================================\n",
      "Saved: adj_repeats_x_speaker_table.csv\n",
      "\n",
      "Pivot table (Count):\n",
      "dominant_speaker      inf  persm  persp\n",
      "n_adjacent_repeats                     \n",
      "0                   14336   2436   2436\n",
      "1                    7618   1679   1679\n",
      "2                    1538    407    407\n",
      "3                     144     40     40\n",
      "4                       6      1      1\n",
      "\n",
      "Pivot table (Mean JS):\n",
      "dominant_speaker       inf   persm   persp\n",
      "n_adjacent_repeats                        \n",
      "0                   0.0021  0.0468  0.0468\n",
      "1                   0.0023  0.0695  0.0695\n",
      "2                   0.0035  0.1020  0.1020\n",
      "3                   0.0058  0.1737  0.1737\n",
      "4                   0.0003  0.6739  0.6739\n",
      "\n",
      "Pivot table (Max JS):\n",
      "dominant_speaker       inf   persm   persp\n",
      "n_adjacent_repeats                        \n",
      "0                   0.1467  0.4582  0.4582\n",
      "1                   0.1467  0.4713  0.4713\n",
      "2                   0.1467  0.4799  0.4799\n",
      "3                   0.1467  0.4493  0.4493\n",
      "4                   0.0008  0.6739  0.6739\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Adjacent Repeats × Dominant Speaker Table\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ADJACENT REPEATS × DOMINANT SPEAKER ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create the cross-tabulation\n",
    "adj_reps = [0, 1, 2, 3, 4]\n",
    "speakers = ['inf', 'persp', 'persm']\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Table 1: COUNT\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE 1: COUNT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'AdjRep':<10}\", end=\"\")\n",
    "for speaker in speakers:\n",
    "    print(f\"{speaker.upper():>12}\", end=\"\")\n",
    "print(f\"{'TOTAL':>12}\")\n",
    "print(\"-\" * 58)\n",
    "\n",
    "row_totals = []\n",
    "for n_rep in adj_reps:\n",
    "    print(f\"{n_rep:<10}\", end=\"\")\n",
    "    row_total = 0\n",
    "    for speaker in speakers:\n",
    "        count = len(results_discrimination[\n",
    "            (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "            (results_discrimination['dominant_speaker'] == speaker)\n",
    "        ])\n",
    "        print(f\"{count:>12}\", end=\"\")\n",
    "        row_total += count\n",
    "    print(f\"{row_total:>12}\")\n",
    "    row_totals.append(row_total)\n",
    "\n",
    "# Column totals\n",
    "print(\"-\" * 58)\n",
    "print(f\"{'TOTAL':<10}\", end=\"\")\n",
    "for speaker in speakers:\n",
    "    col_total = len(results_discrimination[results_discrimination['dominant_speaker'] == speaker])\n",
    "    print(f\"{col_total:>12}\", end=\"\")\n",
    "print(f\"{sum(row_totals):>12}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Table 2: MEAN JS DIVERGENCE\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE 2: MEAN JS DIVERGENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'AdjRep':<10}\", end=\"\")\n",
    "for speaker in speakers:\n",
    "    print(f\"{speaker.upper():>12}\", end=\"\")\n",
    "print(f\"{'ALL':>12}\")\n",
    "print(\"-\" * 58)\n",
    "\n",
    "for n_rep in adj_reps:\n",
    "    print(f\"{n_rep:<10}\", end=\"\")\n",
    "    for speaker in speakers:\n",
    "        subset = results_discrimination[\n",
    "            (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "            (results_discrimination['dominant_speaker'] == speaker)\n",
    "        ]\n",
    "        if len(subset) > 0:\n",
    "            mean_js = subset['js_coop_vs_uncertain'].mean()\n",
    "            print(f\"{mean_js:>12.4f}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"{'N/A':>12}\", end=\"\")\n",
    "    \n",
    "    # All speakers for this n_rep\n",
    "    all_subset = results_discrimination[results_discrimination['n_adjacent_repeats'] == n_rep]\n",
    "    mean_js_all = all_subset['js_coop_vs_uncertain'].mean()\n",
    "    print(f\"{mean_js_all:>12.4f}\")\n",
    "\n",
    "# Row for all adjacent repeats\n",
    "print(\"-\" * 58)\n",
    "print(f\"{'ALL':<10}\", end=\"\")\n",
    "for speaker in speakers:\n",
    "    subset = results_discrimination[results_discrimination['dominant_speaker'] == speaker]\n",
    "    mean_js = subset['js_coop_vs_uncertain'].mean()\n",
    "    print(f\"{mean_js:>12.4f}\", end=\"\")\n",
    "overall_mean = results_discrimination['js_coop_vs_uncertain'].mean()\n",
    "print(f\"{overall_mean:>12.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Table 3: MAX JS DIVERGENCE\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE 3: MAX JS DIVERGENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'AdjRep':<10}\", end=\"\")\n",
    "for speaker in speakers:\n",
    "    print(f\"{speaker.upper():>12}\", end=\"\")\n",
    "print(f\"{'ALL':>12}\")\n",
    "print(\"-\" * 58)\n",
    "\n",
    "for n_rep in adj_reps:\n",
    "    print(f\"{n_rep:<10}\", end=\"\")\n",
    "    for speaker in speakers:\n",
    "        subset = results_discrimination[\n",
    "            (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "            (results_discrimination['dominant_speaker'] == speaker)\n",
    "        ]\n",
    "        if len(subset) > 0:\n",
    "            max_js = subset['js_coop_vs_uncertain'].max()\n",
    "            print(f\"{max_js:>12.4f}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"{'N/A':>12}\", end=\"\")\n",
    "    \n",
    "    # All speakers for this n_rep\n",
    "    all_subset = results_discrimination[results_discrimination['n_adjacent_repeats'] == n_rep]\n",
    "    max_js_all = all_subset['js_coop_vs_uncertain'].max()\n",
    "    print(f\"{max_js_all:>12.4f}\")\n",
    "\n",
    "# Row for all adjacent repeats\n",
    "print(\"-\" * 58)\n",
    "print(f\"{'ALL':<10}\", end=\"\")\n",
    "for speaker in speakers:\n",
    "    subset = results_discrimination[results_discrimination['dominant_speaker'] == speaker]\n",
    "    max_js = subset['js_coop_vs_uncertain'].max()\n",
    "    print(f\"{max_js:>12.4f}\", end=\"\")\n",
    "overall_max = results_discrimination['js_coop_vs_uncertain'].max()\n",
    "print(f\"{overall_max:>12.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Table 4: COMBINED (for easy reading)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE 4: COMBINED (Count / Mean JS / Max JS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'AdjRep':<8}\", end=\"\")\n",
    "for speaker in speakers:\n",
    "    print(f\"{speaker.upper():^30}\", end=\"\")\n",
    "print()\n",
    "\n",
    "print(f\"{'':8}\", end=\"\")\n",
    "for speaker in speakers:\n",
    "    print(f\"{'Count':>10}{'Mean':>10}{'Max':>10}\", end=\"\")\n",
    "print()\n",
    "print(\"-\" * 98)\n",
    "\n",
    "for n_rep in adj_reps:\n",
    "    print(f\"{n_rep:<8}\", end=\"\")\n",
    "    for speaker in speakers:\n",
    "        subset = results_discrimination[\n",
    "            (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "            (results_discrimination['dominant_speaker'] == speaker)\n",
    "        ]\n",
    "        count = len(subset)\n",
    "        if count > 0:\n",
    "            mean_js = subset['js_coop_vs_uncertain'].mean()\n",
    "            max_js = subset['js_coop_vs_uncertain'].max()\n",
    "            print(f\"{count:>10}{mean_js:>10.4f}{max_js:>10.4f}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"{0:>10}{'N/A':>10}{'N/A':>10}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "print(\"-\" * 98)\n",
    "print(f\"{'TOTAL':<8}\", end=\"\")\n",
    "for speaker in speakers:\n",
    "    subset = results_discrimination[results_discrimination['dominant_speaker'] == speaker]\n",
    "    count = len(subset)\n",
    "    mean_js = subset['js_coop_vs_uncertain'].mean()\n",
    "    max_js = subset['js_coop_vs_uncertain'].max()\n",
    "    print(f\"{count:>10}{mean_js:>10.4f}{max_js:>10.4f}\", end=\"\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Save as CSV for easy reference\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Saving tables to CSV...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create a comprehensive DataFrame\n",
    "table_data = []\n",
    "for n_rep in adj_reps:\n",
    "    for speaker in speakers:\n",
    "        subset = results_discrimination[\n",
    "            (results_discrimination['n_adjacent_repeats'] == n_rep) & \n",
    "            (results_discrimination['dominant_speaker'] == speaker)\n",
    "        ]\n",
    "        count = len(subset)\n",
    "        mean_js = subset['js_coop_vs_uncertain'].mean() if count > 0 else np.nan\n",
    "        max_js = subset['js_coop_vs_uncertain'].max() if count > 0 else np.nan\n",
    "        median_js = subset['js_coop_vs_uncertain'].median() if count > 0 else np.nan\n",
    "        mean_E_diff = subset['E_theta_diff'].mean() if count > 0 else np.nan\n",
    "        \n",
    "        table_data.append({\n",
    "            'n_adjacent_repeats': n_rep,\n",
    "            'dominant_speaker': speaker,\n",
    "            'count': count,\n",
    "            'mean_js': mean_js,\n",
    "            'max_js': max_js,\n",
    "            'median_js': median_js,\n",
    "            'mean_E_theta_diff': mean_E_diff\n",
    "        })\n",
    "\n",
    "table_df = pd.DataFrame(table_data)\n",
    "table_df.to_csv('adj_repeats_x_speaker_table.csv', index=False)\n",
    "print(\"Saved: adj_repeats_x_speaker_table.csv\")\n",
    "\n",
    "# Also create a pivot table version\n",
    "print(\"\\nPivot table (Count):\")\n",
    "pivot_count = table_df.pivot(index='n_adjacent_repeats', columns='dominant_speaker', values='count')\n",
    "print(pivot_count)\n",
    "\n",
    "print(\"\\nPivot table (Mean JS):\")\n",
    "pivot_mean = table_df.pivot(index='n_adjacent_repeats', columns='dominant_speaker', values='mean_js')\n",
    "print(pivot_mean.round(4))\n",
    "\n",
    "print(\"\\nPivot table (Max JS):\")\n",
    "pivot_max = table_df.pivot(index='n_adjacent_repeats', columns='dominant_speaker', values='max_js')\n",
    "print(pivot_max.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bed9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BEST SEQUENCES: AdjRep ≤ 1, High JS, High Normalcy\n",
      "======================================================================\n",
      "\n",
      "Filtering criteria:\n",
      "  - Adjacent repeats ≤ 1\n",
      "  - Marginal P ≥ 4.33e-05 (top 10%)\n",
      "  - Total sequences meeting criteria: 2418\n",
      "\n",
      "======================================================================\n",
      "TOP SEQUENCES BY DOMINANT SPEAKER\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "TOP PERSP-CHARACTERISTIC (AdjRep ≤ 1, Top 10% normalcy)\n",
      "============================================================\n",
      "\n",
      "Rank  JS       E[θ]Δ    Rep   P(seq)       E[θ]coop   E[θ]unc    Sequence\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "1     0.4713   0.2387   1     7.68e-04     0.6845     0.4458     mos,sos,sou,sos,sos\n",
      "2     0.4643   0.2387   1     8.63e-04     0.6840     0.4453     mos,sos,sos,sou,sos\n",
      "3     0.4582   0.2487   0     4.50e-04     0.6881     0.4395     mos,sos,sou,sos,sou\n",
      "4     0.4547   0.2475   1     4.34e-04     0.6869     0.4394     mos,sos,sou,sou,sos\n",
      "5     0.4513   0.2440   1     3.87e-04     0.6883     0.4442     mos,sou,sos,sos,sou\n",
      "6     0.4479   0.2427   0     3.75e-04     0.6871     0.4445     mos,sou,sos,sou,sos\n",
      "7     0.4468   0.2374   1     5.35e-04     0.6673     0.4299     sos,mos,sos,sou,sou\n",
      "8     0.4466   0.0456   1     3.19e-03     0.5058     0.4602     sos,sou,sou,sos,sou\n",
      "9     0.4422   0.2155   1     7.80e-04     0.6630     0.4475     sos,mos,sou,sos,sos\n",
      "10    0.4422   0.0033   0     3.19e-03     0.4839     0.4872     sou,sos,sou,sos,sou\n",
      "\n",
      "============================================================\n",
      "TOP PERSM-CHARACTERISTIC (AdjRep ≤ 1, Top 10% normalcy)\n",
      "============================================================\n",
      "\n",
      "Rank  JS       E[θ]Δ    Rep   P(seq)       E[θ]coop   E[θ]unc    Sequence\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "1     0.4713   0.2387   1     7.68e-04     0.3155     0.5542     mou,sou,sos,sou,sou\n",
      "2     0.4643   0.2387   1     8.63e-04     0.3160     0.5547     mou,sou,sou,sos,sou\n",
      "3     0.4582   0.2487   0     4.50e-04     0.3119     0.5605     mou,sou,sos,sou,sos\n",
      "4     0.4547   0.2475   1     4.34e-04     0.3131     0.5606     mou,sou,sos,sos,sou\n",
      "5     0.4513   0.2440   1     3.87e-04     0.3117     0.5558     mou,sos,sou,sou,sos\n",
      "6     0.4479   0.2427   0     3.75e-04     0.3129     0.5555     mou,sos,sou,sos,sou\n",
      "7     0.4468   0.2374   1     5.35e-04     0.3327     0.5701     sou,mou,sou,sos,sos\n",
      "8     0.4466   0.0456   1     3.19e-03     0.4942     0.5398     sou,sos,sos,sou,sos\n",
      "9     0.4422   0.2155   1     7.80e-04     0.3370     0.5525     sou,mou,sos,sou,sou\n",
      "10    0.4422   0.0033   0     3.19e-03     0.5161     0.5128     sos,sou,sos,sou,sos\n",
      "\n",
      "============================================================\n",
      "TOP INF-CHARACTERISTIC (AdjRep ≤ 1, Top 10% normalcy)\n",
      "============================================================\n",
      "\n",
      "Rank  JS       E[θ]Δ    Rep   P(seq)       E[θ]coop   E[θ]unc    Sequence\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "1     0.1467   0.0329   1     1.85e-04     0.8860     0.9189     mos,nou,nou,als,nou\n",
      "2     0.1467   0.0329   1     1.85e-04     0.8860     0.9189     mos,als,nou,als,als\n",
      "3     0.1467   0.0329   1     1.85e-04     0.8860     0.9189     mos,nou,als,nou,nou\n",
      "4     0.1467   0.0329   1     1.85e-04     0.8860     0.9189     mos,nou,als,als,nou\n",
      "5     0.1467   0.0329   1     1.85e-04     0.8860     0.9189     mos,als,als,nou,als\n",
      "6     0.1467   0.0329   0     1.85e-04     0.8860     0.9189     mos,nou,als,nou,als\n",
      "7     0.1467   0.0329   1     1.85e-04     0.8860     0.9189     mos,als,nou,nou,als\n",
      "8     0.1467   0.0329   0     1.85e-04     0.8860     0.9189     mos,als,nou,als,nou\n",
      "9     0.1467   0.0329   0     1.85e-04     0.1140     0.0811     mou,nos,alu,nos,alu\n",
      "10    0.1467   0.0329   1     1.85e-04     0.1140     0.0811     mou,nos,alu,nos,nos\n",
      "\n",
      "======================================================================\n",
      "OVERALL TOP 20 SEQUENCES (AdjRep ≤ 1, Top 10% normalcy)\n",
      "======================================================================\n",
      "\n",
      "Rank  JS       E[θ]Δ    Rep   Speaker  P(seq)       Sequence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     0.4713   0.2387   1     persp    7.68e-04     mos,sos,sou,sos,sos\n",
      "2     0.4713   0.2387   1     persm    7.68e-04     mou,sou,sos,sou,sou\n",
      "3     0.4643   0.2387   1     persp    8.63e-04     mos,sos,sos,sou,sos\n",
      "4     0.4643   0.2387   1     persm    8.63e-04     mou,sou,sou,sos,sou\n",
      "5     0.4582   0.2487   0     persm    4.50e-04     mou,sou,sos,sou,sos\n",
      "6     0.4582   0.2487   0     persp    4.50e-04     mos,sos,sou,sos,sou\n",
      "7     0.4547   0.2475   1     persm    4.34e-04     mou,sou,sos,sos,sou\n",
      "8     0.4547   0.2475   1     persp    4.34e-04     mos,sos,sou,sou,sos\n",
      "9     0.4513   0.2440   1     persp    3.87e-04     mos,sou,sos,sos,sou\n",
      "10    0.4513   0.2440   1     persm    3.87e-04     mou,sos,sou,sou,sos\n",
      "11    0.4479   0.2427   0     persp    3.75e-04     mos,sou,sos,sou,sos\n",
      "12    0.4479   0.2427   0     persm    3.75e-04     mou,sos,sou,sos,sou\n",
      "13    0.4468   0.2374   1     persp    5.35e-04     sos,mos,sos,sou,sou\n",
      "14    0.4468   0.2374   1     persm    5.35e-04     sou,mou,sou,sos,sos\n",
      "15    0.4466   0.0456   1     persp    3.19e-03     sos,sou,sou,sos,sou\n",
      "16    0.4466   0.0456   1     persm    3.19e-03     sou,sos,sos,sou,sos\n",
      "17    0.4422   0.2155   1     persp    7.80e-04     sos,mos,sou,sos,sos\n",
      "18    0.4422   0.2155   1     persm    7.80e-04     sou,mou,sos,sou,sou\n",
      "19    0.4422   0.0033   0     persm    3.19e-03     sos,sou,sos,sou,sos\n",
      "20    0.4422   0.0033   0     persp    3.19e-03     sou,sos,sou,sos,sou\n",
      "\n",
      "======================================================================\n",
      "TOP CANDIDATES - FULL SEQUENCE NAMES\n",
      "======================================================================\n",
      "\n",
      "--- PERSP-characteristic (Coop estimates HIGHER θ) ---\n",
      "\n",
      "1. ('most,successful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,successful')\n",
      "   JS=0.4713, Coop E[θ]=0.684, Uncertain E[θ]=0.446, Diff=+0.239\n",
      "\n",
      "2. ('most,successful', 'some,successful', 'some,successful', 'some,unsuccessful', 'some,successful')\n",
      "   JS=0.4643, Coop E[θ]=0.684, Uncertain E[θ]=0.445, Diff=+0.239\n",
      "\n",
      "3. ('most,successful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful')\n",
      "   JS=0.4582, Coop E[θ]=0.688, Uncertain E[θ]=0.439, Diff=+0.249\n",
      "\n",
      "4. ('most,successful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful')\n",
      "   JS=0.4547, Coop E[θ]=0.687, Uncertain E[θ]=0.439, Diff=+0.248\n",
      "\n",
      "5. ('most,successful', 'some,unsuccessful', 'some,successful', 'some,successful', 'some,unsuccessful')\n",
      "   JS=0.4513, Coop E[θ]=0.688, Uncertain E[θ]=0.444, Diff=+0.244\n",
      "\n",
      "\n",
      "--- PERSM-characteristic (Coop estimates LOWER θ) ---\n",
      "\n",
      "1. ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "   JS=0.4713, Coop E[θ]=0.316, Uncertain E[θ]=0.554, Diff=+0.239\n",
      "\n",
      "2. ('most,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful')\n",
      "   JS=0.4643, Coop E[θ]=0.316, Uncertain E[θ]=0.555, Diff=+0.239\n",
      "\n",
      "3. ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful')\n",
      "   JS=0.4582, Coop E[θ]=0.312, Uncertain E[θ]=0.561, Diff=+0.249\n",
      "\n",
      "4. ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,successful', 'some,unsuccessful')\n",
      "   JS=0.4547, Coop E[θ]=0.313, Uncertain E[θ]=0.561, Diff=+0.248\n",
      "\n",
      "5. ('most,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful')\n",
      "   JS=0.4513, Coop E[θ]=0.312, Uncertain E[θ]=0.556, Diff=+0.244\n",
      "\n",
      "\n",
      "--- INF-characteristic (Both estimate similar θ) ---\n",
      "\n",
      "1. ('most,successful', 'no,unsuccessful', 'no,unsuccessful', 'all,successful', 'no,unsuccessful')\n",
      "   JS=0.1467, Coop E[θ]=0.886, Uncertain E[θ]=0.919, Diff=+0.033\n",
      "   marginal_P=1.85e-04\n",
      "\n",
      "2. ('most,successful', 'all,successful', 'no,unsuccessful', 'all,successful', 'all,successful')\n",
      "   JS=0.1467, Coop E[θ]=0.886, Uncertain E[θ]=0.919, Diff=+0.033\n",
      "   marginal_P=1.85e-04\n",
      "\n",
      "3. ('most,successful', 'no,unsuccessful', 'all,successful', 'no,unsuccessful', 'no,unsuccessful')\n",
      "   JS=0.1467, Coop E[θ]=0.886, Uncertain E[θ]=0.919, Diff=+0.033\n",
      "   marginal_P=1.85e-04\n",
      "\n",
      "4. ('most,successful', 'no,unsuccessful', 'all,successful', 'all,successful', 'no,unsuccessful')\n",
      "   JS=0.1467, Coop E[θ]=0.886, Uncertain E[θ]=0.919, Diff=+0.033\n",
      "   marginal_P=1.85e-04\n",
      "\n",
      "5. ('most,successful', 'all,successful', 'all,successful', 'no,unsuccessful', 'all,successful')\n",
      "   JS=0.1467, Coop E[θ]=0.886, Uncertain E[θ]=0.919, Diff=+0.033\n",
      "   marginal_P=1.85e-04\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ZERO ADJACENT REPEATS ONLY (Maximum variety)\n",
      "======================================================================\n",
      "\n",
      "Total sequences with 0 adjacent repeats and top 10% normalcy: 968\n",
      "\n",
      "Rank  JS       E[θ]Δ    Speaker  Sequence\n",
      "--------------------------------------------------------------------------------\n",
      "1     0.4582   0.2487   persm    mou,sou,sos,sou,sos\n",
      "2     0.4582   0.2487   persp    mos,sos,sou,sos,sou\n",
      "3     0.4479   0.2427   persp    mos,sou,sos,sou,sos\n",
      "4     0.4479   0.2427   persm    mou,sos,sou,sos,sou\n",
      "5     0.4422   0.0033   persm    sos,sou,sos,sou,sos\n",
      "6     0.4422   0.0033   persp    sou,sos,sou,sos,sou\n",
      "7     0.4396   0.2189   persp    sos,mos,sos,sou,sos\n",
      "8     0.4396   0.2189   persm    sou,mou,sou,sos,sou\n",
      "9     0.4368   0.2304   persm    sou,mou,sos,sou,sos\n",
      "10    0.4368   0.2304   persp    sos,mos,sou,sos,sou\n",
      "11    0.3901   0.1903   persp    sos,sou,mos,sos,sou\n",
      "12    0.3901   0.1903   persm    sou,sos,mou,sou,sos\n",
      "13    0.3804   0.1799   persm    sos,mou,sou,sos,sou\n",
      "14    0.3804   0.1799   persp    sou,mos,sos,sou,sos\n",
      "15    0.3793   0.1840   persp    sos,sou,mos,sou,sos\n",
      "\n",
      "======================================================================\n",
      "FINAL RECOMMENDATIONS FOR EXPERIMENT\n",
      "======================================================================\n",
      "\n",
      "Based on the analysis, here are the recommended sequences:\n",
      "\n",
      "CRITERIA USED:\n",
      "- Adjacent repeats ≤ 1 (not boring/repetitive)\n",
      "- Top 10% marginal probability (not weird)\n",
      "- Sorted by JS divergence (maximum discrimination)\n",
      "\n",
      "\n",
      "FINAL RECOMMENDED SEQUENCES:\n",
      "======================================================================\n",
      "\n",
      "--- PERSP-characteristic ---\n",
      "\n",
      "  Sequence: ('most,successful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,successful')\n",
      "  JS = 0.4713\n",
      "  E[θ|coop] = 0.684, E[θ|uncertain] = 0.446\n",
      "  Prediction: Coop > Uncertain (diff = 0.239)\n",
      "  Adjacent repeats: 1, Normalcy: 7.68e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'some,successful', 'some,successful', 'some,unsuccessful', 'some,successful')\n",
      "  JS = 0.4643\n",
      "  E[θ|coop] = 0.684, E[θ|uncertain] = 0.445\n",
      "  Prediction: Coop > Uncertain (diff = 0.239)\n",
      "  Adjacent repeats: 1, Normalcy: 8.63e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful')\n",
      "  JS = 0.4582\n",
      "  E[θ|coop] = 0.688, E[θ|uncertain] = 0.439\n",
      "  Prediction: Coop > Uncertain (diff = 0.249)\n",
      "  Adjacent repeats: 0, Normalcy: 4.50e-04\n",
      "\n",
      "--- PERSM-characteristic ---\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "  JS = 0.4713\n",
      "  E[θ|coop] = 0.316, E[θ|uncertain] = 0.554\n",
      "  Prediction: Coop < Uncertain (diff = 0.239)\n",
      "  Adjacent repeats: 1, Normalcy: 7.68e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful')\n",
      "  JS = 0.4643\n",
      "  E[θ|coop] = 0.316, E[θ|uncertain] = 0.555\n",
      "  Prediction: Coop < Uncertain (diff = 0.239)\n",
      "  Adjacent repeats: 1, Normalcy: 8.63e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful')\n",
      "  JS = 0.4582\n",
      "  E[θ|coop] = 0.312, E[θ|uncertain] = 0.561\n",
      "  Prediction: Coop < Uncertain (diff = 0.249)\n",
      "  Adjacent repeats: 0, Normalcy: 4.50e-04\n",
      "\n",
      "\n",
      "Saved: final_recommended_sequences.csv\n",
      "\n",
      "======================================================================\n",
      "DETAILED POSTERIOR ANALYSIS FOR TOP 2 CANDIDATES\n",
      "======================================================================\n",
      "\n",
      "--- BEST PERSP: ('most,successful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,successful') ---\n",
      "\n",
      "Posterior P(θ | sequence):\n",
      "θ      Coop       Uncertain    Diff      \n",
      "----------------------------------------\n",
      "0.0    0.0000     0.0000       +0.0000   \n",
      "0.1    0.0000     0.0061       -0.0061   \n",
      "0.2    0.0004     0.0961       -0.0956   \n",
      "0.3    0.0032     0.2359       -0.2327   \n",
      "0.4    0.0160     0.2568       -0.2409   \n",
      "0.5    0.0779     0.1786       -0.1007   \n",
      "0.6    0.2423     0.0958       +0.1465   \n",
      "0.7    0.3838     0.0450       +0.3387   \n",
      "0.8    0.2472     0.0297       +0.2175   \n",
      "0.9    0.0292     0.0559       -0.0267   \n",
      "1.0    0.0000     0.0000       +0.0000   \n",
      "\n",
      "--- BEST PERSM: ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful') ---\n",
      "\n",
      "Posterior P(θ | sequence):\n",
      "θ      Coop       Uncertain    Diff      \n",
      "----------------------------------------\n",
      "0.0    0.0000     0.0000       +0.0000   \n",
      "0.1    0.0292     0.0559       -0.0267   \n",
      "0.2    0.2472     0.0297       +0.2175   \n",
      "0.3    0.3838     0.0450       +0.3387   \n",
      "0.4    0.2423     0.0958       +0.1465   \n",
      "0.5    0.0779     0.1786       -0.1007   \n",
      "0.6    0.0160     0.2568       -0.2409   \n",
      "0.7    0.0032     0.2359       -0.2327   \n",
      "0.8    0.0004     0.0961       -0.0956   \n",
      "0.9    0.0000     0.0061       -0.0061   \n",
      "1.0    0.0000     0.0000       +0.0000   \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BEST NON-REPETITIVE (AdjRep ≤ 1), HIGH-JS, NON-WEIRD SEQUENCES\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BEST SEQUENCES: AdjRep ≤ 1, High JS, High Normalcy\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Filter criteria\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Adjacent repeats ≤ 1\n",
    "# High normalcy (top 10% by marginal_P)\n",
    "# Then sort by JS\n",
    "\n",
    "normalcy_threshold = np.percentile(results_discrimination['marginal_P'], 90)\n",
    "\n",
    "filtered = results_discrimination[\n",
    "    (results_discrimination['n_adjacent_repeats'] <= 1) &\n",
    "    (results_discrimination['marginal_P'] >= normalcy_threshold)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nFiltering criteria:\")\n",
    "print(f\"  - Adjacent repeats ≤ 1\")\n",
    "print(f\"  - Marginal P ≥ {normalcy_threshold:.2e} (top 10%)\")\n",
    "print(f\"  - Total sequences meeting criteria: {len(filtered)}\")\n",
    "\n",
    "# Sort by JS divergence\n",
    "filtered = filtered.sort_values('js_coop_vs_uncertain', ascending=False)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Table by dominant speaker\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP SEQUENCES BY DOMINANT SPEAKER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for speaker in ['persp', 'persm', 'inf']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TOP {speaker.upper()}-CHARACTERISTIC (AdjRep ≤ 1, Top 10% normalcy)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    subset = filtered[filtered['dominant_speaker'] == speaker].head(10)\n",
    "    \n",
    "    if len(subset) == 0:\n",
    "        print(\"  (none found)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'Rank':<5} {'JS':<8} {'E[θ]Δ':<8} {'Rep':<5} {'P(seq)':<12} {'E[θ]coop':<10} {'E[θ]unc':<10} Sequence\")\n",
    "    print(\"-\" * 110)\n",
    "    \n",
    "    for rank, (idx, row) in enumerate(subset.iterrows(), 1):\n",
    "        seq = row['sequence']\n",
    "        abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "        print(f\"{rank:<5} {row['js_coop_vs_uncertain']:<8.4f} {row['E_theta_diff']:<8.4f} \"\n",
    "              f\"{row['n_adjacent_repeats']:<5} {row['marginal_P']:<12.2e} \"\n",
    "              f\"{row['E_theta_coop']:<10.4f} {row['E_theta_uncertain']:<10.4f} {abbrev}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Overall top sequences (regardless of dominant speaker)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OVERALL TOP 20 SEQUENCES (AdjRep ≤ 1, Top 10% normalcy)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "top20 = filtered.head(20)\n",
    "\n",
    "print(f\"\\n{'Rank':<5} {'JS':<8} {'E[θ]Δ':<8} {'Rep':<5} {'Speaker':<8} {'P(seq)':<12} {'Sequence'}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for rank, (idx, row) in enumerate(top20.iterrows(), 1):\n",
    "    seq = row['sequence']\n",
    "    abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "    print(f\"{rank:<5} {row['js_coop_vs_uncertain']:<8.4f} {row['E_theta_diff']:<8.4f} \"\n",
    "          f\"{row['n_adjacent_repeats']:<5} {row['dominant_speaker']:<8} \"\n",
    "          f\"{row['marginal_P']:<12.2e} {abbrev}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Show full sequence names for top candidates\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP CANDIDATES - FULL SEQUENCE NAMES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n--- PERSP-characteristic (Coop estimates HIGHER θ) ---\\n\")\n",
    "persp_top = filtered[filtered['dominant_speaker'] == 'persp'].head(5)\n",
    "for rank, (idx, row) in enumerate(persp_top.iterrows(), 1):\n",
    "    print(f\"{rank}. {row['sequence']}\")\n",
    "    print(f\"   JS={row['js_coop_vs_uncertain']:.4f}, Coop E[θ]={row['E_theta_coop']:.3f}, \"\n",
    "          f\"Uncertain E[θ]={row['E_theta_uncertain']:.3f}, Diff={row['E_theta_diff']:+.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n--- PERSM-characteristic (Coop estimates LOWER θ) ---\\n\")\n",
    "persm_top = filtered[filtered['dominant_speaker'] == 'persm'].head(5)\n",
    "for rank, (idx, row) in enumerate(persm_top.iterrows(), 1):\n",
    "    print(f\"{rank}. {row['sequence']}\")\n",
    "    print(f\"   JS={row['js_coop_vs_uncertain']:.4f}, Coop E[θ]={row['E_theta_coop']:.3f}, \"\n",
    "          f\"Uncertain E[θ]={row['E_theta_uncertain']:.3f}, Diff={row['E_theta_diff']:+.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n--- INF-characteristic (Both estimate similar θ) ---\\n\")\n",
    "inf_top = filtered[filtered['dominant_speaker'] == 'inf'].head(5)\n",
    "if len(inf_top) == 0:\n",
    "    print(\"(none found with current criteria - relaxing normalcy)\")\n",
    "    inf_top = results_discrimination[\n",
    "        (results_discrimination['n_adjacent_repeats'] <= 1) &\n",
    "        (results_discrimination['dominant_speaker'] == 'inf')\n",
    "    ].sort_values('js_coop_vs_uncertain', ascending=False).head(5)\n",
    "\n",
    "for rank, (idx, row) in enumerate(inf_top.iterrows(), 1):\n",
    "    print(f\"{rank}. {row['sequence']}\")\n",
    "    print(f\"   JS={row['js_coop_vs_uncertain']:.4f}, Coop E[θ]={row['E_theta_coop']:.3f}, \"\n",
    "          f\"Uncertain E[θ]={row['E_theta_uncertain']:.3f}, Diff={row['E_theta_diff']:+.3f}\")\n",
    "    print(f\"   marginal_P={row['marginal_P']:.2e}\")\n",
    "    print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Zero adjacent repeats only\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ZERO ADJACENT REPEATS ONLY (Maximum variety)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "filtered_0rep = results_discrimination[\n",
    "    (results_discrimination['n_adjacent_repeats'] == 0) &\n",
    "    (results_discrimination['marginal_P'] >= normalcy_threshold)\n",
    "].sort_values('js_coop_vs_uncertain', ascending=False)\n",
    "\n",
    "print(f\"\\nTotal sequences with 0 adjacent repeats and top 10% normalcy: {len(filtered_0rep)}\")\n",
    "\n",
    "print(f\"\\n{'Rank':<5} {'JS':<8} {'E[θ]Δ':<8} {'Speaker':<8} {'Sequence'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for rank, (idx, row) in enumerate(filtered_0rep.head(15).iterrows(), 1):\n",
    "    seq = row['sequence']\n",
    "    abbrev = \",\".join([u.split(\",\")[0][:2] + u.split(\",\")[1][0] for u in seq])\n",
    "    print(f\"{rank:<5} {row['js_coop_vs_uncertain']:<8.4f} {row['E_theta_diff']:<8.4f} \"\n",
    "          f\"{row['dominant_speaker']:<8} {abbrev}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Summary table for experiment design\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RECOMMENDATIONS FOR EXPERIMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Based on the analysis, here are the recommended sequences:\n",
    "\n",
    "CRITERIA USED:\n",
    "- Adjacent repeats ≤ 1 (not boring/repetitive)\n",
    "- Top 10% marginal probability (not weird)\n",
    "- Sorted by JS divergence (maximum discrimination)\n",
    "\"\"\")\n",
    "\n",
    "# Collect final recommendations\n",
    "final_recs = []\n",
    "\n",
    "# Top 3 PERSP\n",
    "for idx, row in filtered[filtered['dominant_speaker'] == 'persp'].head(6).iterrows():\n",
    "    final_recs.append({\n",
    "        'category': 'PERSP',\n",
    "        'sequence': row['sequence'],\n",
    "        'js': row['js_coop_vs_uncertain'],\n",
    "        'E_theta_coop': row['E_theta_coop'],\n",
    "        'E_theta_uncertain': row['E_theta_uncertain'],\n",
    "        'E_theta_diff': row['E_theta_diff'],\n",
    "        'adj_rep': row['n_adjacent_repeats'],\n",
    "        'marginal_P': row['marginal_P'],\n",
    "        'prediction': 'Coop > Uncertain'\n",
    "    })\n",
    "\n",
    "# Top 3 PERSM\n",
    "for idx, row in filtered[filtered['dominant_speaker'] == 'persm'].head(6).iterrows():\n",
    "    final_recs.append({\n",
    "        'category': 'PERSM',\n",
    "        'sequence': row['sequence'],\n",
    "        'js': row['js_coop_vs_uncertain'],\n",
    "        'E_theta_coop': row['E_theta_coop'],\n",
    "        'E_theta_uncertain': row['E_theta_uncertain'],\n",
    "        'E_theta_diff': row['E_theta_diff'],\n",
    "        'adj_rep': row['n_adjacent_repeats'],\n",
    "        'marginal_P': row['marginal_P'],\n",
    "        'prediction': 'Coop < Uncertain'\n",
    "    })\n",
    "\n",
    "final_df = pd.DataFrame(final_recs)\n",
    "\n",
    "print(\"\\nFINAL RECOMMENDED SEQUENCES:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for cat in ['PERSP', 'PERSM']:\n",
    "    print(f\"\\n--- {cat}-characteristic ---\")\n",
    "    subset = final_df[final_df['category'] == cat]\n",
    "    for i, row in subset.iterrows():\n",
    "        seq = row['sequence']\n",
    "        print(f\"\\n  Sequence: {seq}\")\n",
    "        print(f\"  JS = {row['js']:.4f}\")\n",
    "        print(f\"  E[θ|coop] = {row['E_theta_coop']:.3f}, E[θ|uncertain] = {row['E_theta_uncertain']:.3f}\")\n",
    "        print(f\"  Prediction: {row['prediction']} (diff = {row['E_theta_diff']:.3f})\")\n",
    "        print(f\"  Adjacent repeats: {row['adj_rep']}, Normalcy: {row['marginal_P']:.2e}\")\n",
    "\n",
    "# Save final recommendations\n",
    "final_df.to_csv('final_recommended_sequences.csv', index=False)\n",
    "print(\"\\n\\nSaved: final_recommended_sequences.csv\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Detailed posterior analysis for top candidates\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED POSTERIOR ANALYSIS FOR TOP 2 CANDIDATES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Best PERSP\n",
    "best_persp_idx = filtered[filtered['dominant_speaker'] == 'persp'].index[0]\n",
    "best_persp = filtered.loc[best_persp_idx]\n",
    "\n",
    "print(f\"\\n--- BEST PERSP: {best_persp['sequence']} ---\")\n",
    "print(f\"\\nPosterior P(θ | sequence):\")\n",
    "print(f\"{'θ':<6} {'Coop':<10} {'Uncertain':<12} {'Diff':<10}\")\n",
    "print(\"-\"*40)\n",
    "for i, theta in enumerate(theta_values):\n",
    "    p_coop = P_theta_given_seq_coop[best_persp_idx, i]\n",
    "    p_unc = P_theta_given_seq_uncertain[best_persp_idx, i]\n",
    "    diff = p_coop - p_unc\n",
    "    print(f\"{theta:<6.1f} {p_coop:<10.4f} {p_unc:<12.4f} {diff:<+10.4f}\")\n",
    "\n",
    "# Best PERSM\n",
    "best_persm_idx = filtered[filtered['dominant_speaker'] == 'persm'].index[0]\n",
    "best_persm = filtered.loc[best_persm_idx]\n",
    "\n",
    "print(f\"\\n--- BEST PERSM: {best_persm['sequence']} ---\")\n",
    "print(f\"\\nPosterior P(θ | sequence):\")\n",
    "print(f\"{'θ':<6} {'Coop':<10} {'Uncertain':<12} {'Diff':<10}\")\n",
    "print(\"-\"*40)\n",
    "for i, theta in enumerate(theta_values):\n",
    "    p_coop = P_theta_given_seq_coop[best_persm_idx, i]\n",
    "    p_unc = P_theta_given_seq_uncertain[best_persm_idx, i]\n",
    "    diff = p_coop - p_unc\n",
    "    print(f\"{theta:<6.1f} {p_coop:<10.4f} {p_unc:<12.4f} {diff:<+10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2dc2b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPLETE FINAL RECOMMENDATIONS (including INF)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPLETE FINAL RECOMMENDED SEQUENCES\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "PERSP-CHARACTERISTIC\n",
      "============================================================\n",
      "\n",
      "  Sequence: ('most,successful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,successful')\n",
      "  JS = 0.4713\n",
      "  E[θ|coop] = 0.684, E[θ|uncertain] = 0.446\n",
      "  Prediction: Coop > Uncertain (diff = 0.239)\n",
      "  Adjacent repeats: 1, Normalcy: 7.68e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'some,successful', 'some,successful', 'some,unsuccessful', 'some,successful')\n",
      "  JS = 0.4643\n",
      "  E[θ|coop] = 0.684, E[θ|uncertain] = 0.445\n",
      "  Prediction: Coop > Uncertain (diff = 0.239)\n",
      "  Adjacent repeats: 1, Normalcy: 8.63e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful')\n",
      "  JS = 0.4582\n",
      "  E[θ|coop] = 0.688, E[θ|uncertain] = 0.439\n",
      "  Prediction: Coop > Uncertain (diff = 0.249)\n",
      "  Adjacent repeats: 0, Normalcy: 4.50e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful')\n",
      "  JS = 0.4547\n",
      "  E[θ|coop] = 0.687, E[θ|uncertain] = 0.439\n",
      "  Prediction: Coop > Uncertain (diff = 0.248)\n",
      "  Adjacent repeats: 1, Normalcy: 4.34e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'some,unsuccessful', 'some,successful', 'some,successful', 'some,unsuccessful')\n",
      "  JS = 0.4513\n",
      "  E[θ|coop] = 0.688, E[θ|uncertain] = 0.444\n",
      "  Prediction: Coop > Uncertain (diff = 0.244)\n",
      "  Adjacent repeats: 1, Normalcy: 3.87e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful')\n",
      "  JS = 0.4479\n",
      "  E[θ|coop] = 0.687, E[θ|uncertain] = 0.444\n",
      "  Prediction: Coop > Uncertain (diff = 0.243)\n",
      "  Adjacent repeats: 0, Normalcy: 3.75e-04\n",
      "\n",
      "============================================================\n",
      "PERSM-CHARACTERISTIC\n",
      "============================================================\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "  JS = 0.4713\n",
      "  E[θ|coop] = 0.316, E[θ|uncertain] = 0.554\n",
      "  Prediction: Coop < Uncertain (diff = 0.239)\n",
      "  Adjacent repeats: 1, Normalcy: 7.68e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful')\n",
      "  JS = 0.4643\n",
      "  E[θ|coop] = 0.316, E[θ|uncertain] = 0.555\n",
      "  Prediction: Coop < Uncertain (diff = 0.239)\n",
      "  Adjacent repeats: 1, Normalcy: 8.63e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful')\n",
      "  JS = 0.4582\n",
      "  E[θ|coop] = 0.312, E[θ|uncertain] = 0.561\n",
      "  Prediction: Coop < Uncertain (diff = 0.249)\n",
      "  Adjacent repeats: 0, Normalcy: 4.50e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'some,successful', 'some,unsuccessful')\n",
      "  JS = 0.4547\n",
      "  E[θ|coop] = 0.313, E[θ|uncertain] = 0.561\n",
      "  Prediction: Coop < Uncertain (diff = 0.248)\n",
      "  Adjacent repeats: 1, Normalcy: 4.34e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,unsuccessful', 'some,successful')\n",
      "  JS = 0.4513\n",
      "  E[θ|coop] = 0.312, E[θ|uncertain] = 0.556\n",
      "  Prediction: Coop < Uncertain (diff = 0.244)\n",
      "  Adjacent repeats: 1, Normalcy: 3.87e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,successful', 'some,unsuccessful', 'some,successful', 'some,unsuccessful')\n",
      "  JS = 0.4479\n",
      "  E[θ|coop] = 0.313, E[θ|uncertain] = 0.556\n",
      "  Prediction: Coop < Uncertain (diff = 0.243)\n",
      "  Adjacent repeats: 0, Normalcy: 3.75e-04\n",
      "\n",
      "============================================================\n",
      "INF-CHARACTERISTIC\n",
      "============================================================\n",
      "\n",
      "  Sequence: ('most,successful', 'no,unsuccessful', 'no,unsuccessful', 'all,successful', 'no,unsuccessful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.886, E[θ|uncertain] = 0.919\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'all,successful', 'no,unsuccessful', 'all,successful', 'all,successful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.886, E[θ|uncertain] = 0.919\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'no,unsuccessful', 'all,successful', 'no,unsuccessful', 'no,unsuccessful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.886, E[θ|uncertain] = 0.919\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'no,unsuccessful', 'all,successful', 'all,successful', 'no,unsuccessful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.886, E[θ|uncertain] = 0.919\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'all,successful', 'all,successful', 'no,unsuccessful', 'all,successful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.886, E[θ|uncertain] = 0.919\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'no,unsuccessful', 'all,successful', 'no,unsuccessful', 'all,successful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.886, E[θ|uncertain] = 0.919\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.033)\n",
      "  Adjacent repeats: 0, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'all,successful', 'no,unsuccessful', 'no,unsuccessful', 'all,successful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.886, E[θ|uncertain] = 0.919\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'all,successful', 'no,unsuccessful', 'all,successful', 'no,unsuccessful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.886, E[θ|uncertain] = 0.919\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.033)\n",
      "  Adjacent repeats: 0, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'no,successful', 'all,unsuccessful', 'no,successful', 'all,unsuccessful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.114, E[θ|uncertain] = 0.081\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.033)\n",
      "  Adjacent repeats: 0, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'no,successful', 'all,unsuccessful', 'no,successful', 'no,successful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.114, E[θ|uncertain] = 0.081\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'all,unsuccessful', 'no,successful', 'no,successful', 'all,unsuccessful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.114, E[θ|uncertain] = 0.081\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'all,unsuccessful', 'all,unsuccessful', 'no,successful', 'all,unsuccessful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.114, E[θ|uncertain] = 0.081\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'all,unsuccessful', 'no,successful', 'all,unsuccessful', 'all,unsuccessful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.114, E[θ|uncertain] = 0.081\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'no,successful', 'all,unsuccessful', 'all,unsuccessful', 'no,successful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.114, E[θ|uncertain] = 0.081\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'no,successful', 'no,successful', 'all,unsuccessful', 'no,successful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.114, E[θ|uncertain] = 0.081\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.033)\n",
      "  Adjacent repeats: 1, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'all,unsuccessful', 'no,successful', 'all,unsuccessful', 'no,successful')\n",
      "  JS = 0.1467\n",
      "  E[θ|coop] = 0.114, E[θ|uncertain] = 0.081\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.033)\n",
      "  Adjacent repeats: 0, Normalcy: 1.85e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,successful', 'some,successful', 'most,unsuccessful', 'some,successful')\n",
      "  JS = 0.1348\n",
      "  E[θ|coop] = 0.309, E[θ|uncertain] = 0.416\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.107)\n",
      "  Adjacent repeats: 1, Normalcy: 1.79e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'some,unsuccessful', 'some,unsuccessful', 'most,successful', 'some,unsuccessful')\n",
      "  JS = 0.1348\n",
      "  E[θ|coop] = 0.691, E[θ|uncertain] = 0.584\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.107)\n",
      "  Adjacent repeats: 1, Normalcy: 1.79e-04\n",
      "\n",
      "  Sequence: ('most,successful', 'some,unsuccessful', 'most,successful', 'some,unsuccessful', 'some,unsuccessful')\n",
      "  JS = 0.0767\n",
      "  E[θ|coop] = 0.692, E[θ|uncertain] = 0.620\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.071)\n",
      "  Adjacent repeats: 1, Normalcy: 2.83e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,successful', 'most,unsuccessful', 'some,successful', 'some,successful')\n",
      "  JS = 0.0767\n",
      "  E[θ|coop] = 0.308, E[θ|uncertain] = 0.380\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.071)\n",
      "  Adjacent repeats: 1, Normalcy: 2.83e-04\n",
      "\n",
      "  Sequence: ('no,unsuccessful', 'most,successful', 'most,successful', 'all,successful', 'no,unsuccessful')\n",
      "  JS = 0.0647\n",
      "  E[θ|coop] = 0.864, E[θ|uncertain] = 0.886\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 1, Normalcy: 1.95e-04\n",
      "\n",
      "  Sequence: ('all,successful', 'most,successful', 'most,successful', 'no,unsuccessful', 'all,successful')\n",
      "  JS = 0.0647\n",
      "  E[θ|coop] = 0.864, E[θ|uncertain] = 0.886\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 1, Normalcy: 1.95e-04\n",
      "\n",
      "  Sequence: ('all,successful', 'most,successful', 'most,successful', 'all,successful', 'no,unsuccessful')\n",
      "  JS = 0.0647\n",
      "  E[θ|coop] = 0.864, E[θ|uncertain] = 0.886\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 1, Normalcy: 1.95e-04\n",
      "\n",
      "  Sequence: ('no,unsuccessful', 'most,successful', 'most,successful', 'no,unsuccessful', 'all,successful')\n",
      "  JS = 0.0647\n",
      "  E[θ|coop] = 0.864, E[θ|uncertain] = 0.886\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 1, Normalcy: 1.95e-04\n",
      "\n",
      "  Sequence: ('all,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'no,successful', 'all,unsuccessful')\n",
      "  JS = 0.0647\n",
      "  E[θ|coop] = 0.136, E[θ|uncertain] = 0.114\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 1, Normalcy: 1.95e-04\n",
      "\n",
      "  Sequence: ('no,successful', 'most,unsuccessful', 'most,unsuccessful', 'all,unsuccessful', 'no,successful')\n",
      "  JS = 0.0647\n",
      "  E[θ|coop] = 0.136, E[θ|uncertain] = 0.114\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 1, Normalcy: 1.95e-04\n",
      "\n",
      "  Sequence: ('all,unsuccessful', 'most,unsuccessful', 'most,unsuccessful', 'all,unsuccessful', 'no,successful')\n",
      "  JS = 0.0647\n",
      "  E[θ|coop] = 0.136, E[θ|uncertain] = 0.114\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 1, Normalcy: 1.95e-04\n",
      "\n",
      "  Sequence: ('no,successful', 'most,unsuccessful', 'most,unsuccessful', 'no,successful', 'all,unsuccessful')\n",
      "  JS = 0.0647\n",
      "  E[θ|coop] = 0.136, E[θ|uncertain] = 0.114\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 1, Normalcy: 1.95e-04\n",
      "\n",
      "  Sequence: ('all,unsuccessful', 'most,unsuccessful', 'no,successful', 'most,unsuccessful', 'all,unsuccessful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.134, E[θ|uncertain] = 0.110\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('no,successful', 'most,unsuccessful', 'no,successful', 'most,unsuccessful', 'no,successful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.134, E[θ|uncertain] = 0.110\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('no,successful', 'most,unsuccessful', 'no,successful', 'most,unsuccessful', 'all,unsuccessful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.134, E[θ|uncertain] = 0.110\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('all,unsuccessful', 'most,unsuccessful', 'no,successful', 'most,unsuccessful', 'no,successful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.134, E[θ|uncertain] = 0.110\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('no,successful', 'most,unsuccessful', 'all,unsuccessful', 'most,unsuccessful', 'all,unsuccessful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.134, E[θ|uncertain] = 0.110\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('no,successful', 'most,unsuccessful', 'all,unsuccessful', 'most,unsuccessful', 'no,successful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.134, E[θ|uncertain] = 0.110\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('all,unsuccessful', 'most,unsuccessful', 'all,unsuccessful', 'most,unsuccessful', 'all,unsuccessful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.134, E[θ|uncertain] = 0.110\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('all,unsuccessful', 'most,unsuccessful', 'all,unsuccessful', 'most,unsuccessful', 'no,successful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.134, E[θ|uncertain] = 0.110\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('no,unsuccessful', 'most,successful', 'no,unsuccessful', 'most,successful', 'no,unsuccessful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.866, E[θ|uncertain] = 0.890\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('no,unsuccessful', 'most,successful', 'all,successful', 'most,successful', 'no,unsuccessful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.866, E[θ|uncertain] = 0.890\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('all,successful', 'most,successful', 'all,successful', 'most,successful', 'all,successful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.866, E[θ|uncertain] = 0.890\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('no,unsuccessful', 'most,successful', 'all,successful', 'most,successful', 'all,successful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.866, E[θ|uncertain] = 0.890\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('all,successful', 'most,successful', 'all,successful', 'most,successful', 'no,unsuccessful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.866, E[θ|uncertain] = 0.890\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('all,successful', 'most,successful', 'no,unsuccessful', 'most,successful', 'no,unsuccessful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.866, E[θ|uncertain] = 0.890\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('no,unsuccessful', 'most,successful', 'no,unsuccessful', 'most,successful', 'all,successful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.866, E[θ|uncertain] = 0.890\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('all,successful', 'most,successful', 'no,unsuccessful', 'most,successful', 'all,successful')\n",
      "  JS = 0.0535\n",
      "  E[θ|coop] = 0.866, E[θ|uncertain] = 0.890\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.01e-04\n",
      "\n",
      "  Sequence: ('most,unsuccessful', 'some,unsuccessful', 'some,successful', 'most,unsuccessful', 'most,successful')\n",
      "  JS = 0.0484\n",
      "  E[θ|coop] = 0.392, E[θ|uncertain] = 0.447\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.055)\n",
      "  Adjacent repeats: 0, Normalcy: 5.92e-05\n",
      "\n",
      "  Sequence: ('most,successful', 'some,successful', 'some,unsuccessful', 'most,successful', 'most,unsuccessful')\n",
      "  JS = 0.0484\n",
      "  E[θ|coop] = 0.608, E[θ|uncertain] = 0.553\n",
      "  Prediction: Coop > Uncertain (both high) (diff = 0.055)\n",
      "  Adjacent repeats: 0, Normalcy: 5.92e-05\n",
      "\n",
      "  Sequence: ('no,unsuccessful', 'most,successful', 'no,unsuccessful', 'no,unsuccessful', 'most,successful')\n",
      "  JS = 0.0445\n",
      "  E[θ|coop] = 0.868, E[θ|uncertain] = 0.891\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 1, Normalcy: 2.04e-04\n",
      "\n",
      "  Sequence: ('all,successful', 'most,successful', 'no,unsuccessful', 'all,successful', 'most,successful')\n",
      "  JS = 0.0445\n",
      "  E[θ|coop] = 0.868, E[θ|uncertain] = 0.891\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.04e-04\n",
      "\n",
      "  Sequence: ('no,unsuccessful', 'most,successful', 'all,successful', 'all,successful', 'most,successful')\n",
      "  JS = 0.0445\n",
      "  E[θ|coop] = 0.868, E[θ|uncertain] = 0.891\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 1, Normalcy: 2.04e-04\n",
      "\n",
      "  Sequence: ('no,unsuccessful', 'most,successful', 'no,unsuccessful', 'all,successful', 'most,successful')\n",
      "  JS = 0.0445\n",
      "  E[θ|coop] = 0.868, E[θ|uncertain] = 0.891\n",
      "  Prediction: Coop < Uncertain (both low) (diff = 0.023)\n",
      "  Adjacent repeats: 0, Normalcy: 2.04e-04\n",
      "\n",
      "\n",
      "Saved: final_recommended_sequences_complete.csv\n",
      "\n",
      "======================================================================\n",
      "SUMMARY COMPARISON TABLE\n",
      "======================================================================\n",
      "\n",
      "Category   JS       E[θ]coop   E[θ]unc    Diff     Interpretation\n",
      "--------------------------------------------------------------------------------\n",
      "PERSP      0.4713   0.684      0.446      0.239    Coop thinks θ HIGH, Uncertain thinks θ MODERATE\n",
      "PERSM      0.4713   0.316      0.554      0.239    Coop thinks θ LOW, Uncertain thinks θ MODERATE\n",
      "INF        0.1467   0.886      0.919      0.033    Both agree on θ (low discrimination)\n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHT: WHY INF HAS LOW DISCRIMINATION\n",
      "======================================================================\n",
      "\n",
      "INF-characteristic sequences have LOW JS divergence (0.15 vs 0.47 for PERSP/PERSM).\n",
      "\n",
      "WHY?\n",
      "- INF-characteristic sequences use strong quantifiers: \"all\", \"most\", \"no\"\n",
      "- These are only plausible at EXTREME θ values (very high or very low)\n",
      "- ALL speaker types agree that extreme quantifiers → extreme θ\n",
      "- Therefore, Coop and Uncertain listeners reach SIMILAR conclusions\n",
      "\n",
      "EXAMPLE: ('most,successful', 'all,successful', 'no,unsuccessful', 'all,successful', 'no,unsuccessful')\n",
      "- ALL speakers agree: this sequence requires θ ≈ 0.9\n",
      "- Coop listener: E[θ] = 0.886\n",
      "- Uncertain listener: E[θ] = 0.919\n",
      "- Difference: only 0.033\n",
      "\n",
      "IMPLICATION FOR EXPERIMENT:\n",
      "- INF-characteristic sequences can serve as CONTROL stimuli\n",
      "- Both conditions should show SIMILAR θ estimates\n",
      "- If they differ, it suggests the manipulation affected processing beyond the model\n",
      "\n",
      "\n",
      "======================================================================\n",
      "DETAILED POSTERIOR FOR BEST INF SEQUENCE\n",
      "======================================================================\n",
      "\n",
      "Sequence: ('most,successful', 'no,unsuccessful', 'no,unsuccessful', 'all,successful', 'no,unsuccessful')\n",
      "\n",
      "Posterior P(θ | sequence):\n",
      "θ      Coop       Uncertain    INF        PERSP      PERSM     \n",
      "------------------------------------------------------------\n",
      "0.0    0.0000     0.0000       0.0000     0.0000     0.0000    \n",
      "0.1    0.0000     0.0000       0.0000     0.0000     0.0000    \n",
      "0.2    0.0000     0.0000       0.0000     0.0000     0.0000    \n",
      "0.3    0.0000     0.0000       0.0000     0.0000     0.0000    \n",
      "0.4    0.0000     0.0000       0.0000     0.0000     0.0000    \n",
      "0.5    0.0000     0.0000       0.0000     0.0000     0.0000    \n",
      "0.6    0.0004     0.0003       0.0004     0.0002     0.0000    \n",
      "0.7    0.0094     0.0065       0.0094     0.0040     0.0002    \n",
      "0.8    0.1250     0.0875       0.1250     0.0544     0.0045    \n",
      "0.9    0.8602     0.6154       0.8602     0.3993     0.0733    \n",
      "1.0    0.0050     0.2902       0.0050     0.5421     0.9219    \n",
      "\n",
      "OBSERVATION:\n",
      "- All speaker-specific posteriors concentrate at high θ (0.8-1.0)\n",
      "- The slight difference comes from PERSM putting more weight on θ=1.0\n",
      "- This is why Uncertain (which includes PERSM) estimates slightly higher θ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FIX: Add INF-characteristic sequences to recommendations\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPLETE FINAL RECOMMENDATIONS (including INF)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Collect final recommendations - ALL THREE TYPES\n",
    "final_recs_complete = []\n",
    "\n",
    "# Top 3 PERSP\n",
    "for idx, row in filtered[filtered['dominant_speaker'] == 'persp'].head(6).iterrows():\n",
    "    final_recs_complete.append({\n",
    "        'category': 'PERSP',\n",
    "        'sequence': row['sequence'],\n",
    "        'js': row['js_coop_vs_uncertain'],\n",
    "        'E_theta_coop': row['E_theta_coop'],\n",
    "        'E_theta_uncertain': row['E_theta_uncertain'],\n",
    "        'E_theta_diff': row['E_theta_diff'],\n",
    "        'adj_rep': row['n_adjacent_repeats'],\n",
    "        'marginal_P': row['marginal_P'],\n",
    "        'prediction': 'Coop > Uncertain'\n",
    "    })\n",
    "\n",
    "# Top 3 PERSM\n",
    "for idx, row in filtered[filtered['dominant_speaker'] == 'persm'].head(6).iterrows():\n",
    "    final_recs_complete.append({\n",
    "        'category': 'PERSM',\n",
    "        'sequence': row['sequence'],\n",
    "        'js': row['js_coop_vs_uncertain'],\n",
    "        'E_theta_coop': row['E_theta_coop'],\n",
    "        'E_theta_uncertain': row['E_theta_uncertain'],\n",
    "        'E_theta_diff': row['E_theta_diff'],\n",
    "        'adj_rep': row['n_adjacent_repeats'],\n",
    "        'marginal_P': row['marginal_P'],\n",
    "        'prediction': 'Coop < Uncertain'\n",
    "    })\n",
    "\n",
    "# Top 3 INF\n",
    "inf_filtered = filtered[filtered['dominant_speaker'] == 'inf']\n",
    "if len(inf_filtered) == 0:\n",
    "    # Relax normalcy criteria for INF\n",
    "    print(\"No INF sequences meet strict criteria, relaxing normalcy threshold...\")\n",
    "    inf_filtered = results_discrimination[\n",
    "        (results_discrimination['n_adjacent_repeats'] <= 1) &\n",
    "        (results_discrimination['dominant_speaker'] == 'inf')\n",
    "    ].sort_values('js_coop_vs_uncertain', ascending=False)\n",
    "\n",
    "for idx, row in inf_filtered.head(50).iterrows():\n",
    "    # Determine direction\n",
    "    if row['E_theta_coop'] > row['E_theta_uncertain']:\n",
    "        prediction = 'Coop > Uncertain (both high)'\n",
    "    else:\n",
    "        prediction = 'Coop < Uncertain (both low)'\n",
    "    \n",
    "    final_recs_complete.append({\n",
    "        'category': 'INF',\n",
    "        'sequence': row['sequence'],\n",
    "        'js': row['js_coop_vs_uncertain'],\n",
    "        'E_theta_coop': row['E_theta_coop'],\n",
    "        'E_theta_uncertain': row['E_theta_uncertain'],\n",
    "        'E_theta_diff': row['E_theta_diff'],\n",
    "        'adj_rep': row['n_adjacent_repeats'],\n",
    "        'marginal_P': row['marginal_P'],\n",
    "        'prediction': prediction\n",
    "    })\n",
    "\n",
    "final_df_complete = pd.DataFrame(final_recs_complete)\n",
    "\n",
    "# Display all recommendations\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE FINAL RECOMMENDED SEQUENCES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for cat in ['PERSP', 'PERSM', 'INF']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{cat}-CHARACTERISTIC\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    subset = final_df_complete[final_df_complete['category'] == cat]\n",
    "    \n",
    "    for i, row in subset.iterrows():\n",
    "        seq = row['sequence']\n",
    "        print(f\"\\n  Sequence: {seq}\")\n",
    "        print(f\"  JS = {row['js']:.4f}\")\n",
    "        print(f\"  E[θ|coop] = {row['E_theta_coop']:.3f}, E[θ|uncertain] = {row['E_theta_uncertain']:.3f}\")\n",
    "        print(f\"  Prediction: {row['prediction']} (diff = {row['E_theta_diff']:.3f})\")\n",
    "        print(f\"  Adjacent repeats: {row['adj_rep']}, Normalcy: {row['marginal_P']:.2e}\")\n",
    "\n",
    "# Save complete recommendations\n",
    "final_df_complete.to_csv('final_recommended_sequences_complete.csv', index=False)\n",
    "print(\"\\n\\nSaved: final_recommended_sequences_complete.csv\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Summary comparison table\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY COMPARISON TABLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Category':<10} {'JS':<8} {'E[θ]coop':<10} {'E[θ]unc':<10} {'Diff':<8} {'Interpretation'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for cat in ['PERSP', 'PERSM', 'INF']:\n",
    "    subset = final_df_complete[final_df_complete['category'] == cat]\n",
    "    row = subset.iloc[0]  # Best one\n",
    "    \n",
    "    if cat == 'PERSP':\n",
    "        interp = \"Coop thinks θ HIGH, Uncertain thinks θ MODERATE\"\n",
    "    elif cat == 'PERSM':\n",
    "        interp = \"Coop thinks θ LOW, Uncertain thinks θ MODERATE\"\n",
    "    else:\n",
    "        interp = \"Both agree on θ (low discrimination)\"\n",
    "    \n",
    "    print(f\"{cat:<10} {row['js']:<8.4f} {row['E_theta_coop']:<10.3f} {row['E_theta_uncertain']:<10.3f} \"\n",
    "          f\"{row['E_theta_diff']:<8.3f} {interp}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Key insight about INF\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHT: WHY INF HAS LOW DISCRIMINATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "INF-characteristic sequences have LOW JS divergence (0.15 vs 0.47 for PERSP/PERSM).\n",
    "\n",
    "WHY?\n",
    "- INF-characteristic sequences use strong quantifiers: \"all\", \"most\", \"no\"\n",
    "- These are only plausible at EXTREME θ values (very high or very low)\n",
    "- ALL speaker types agree that extreme quantifiers → extreme θ\n",
    "- Therefore, Coop and Uncertain listeners reach SIMILAR conclusions\n",
    "\n",
    "EXAMPLE: ('most,successful', 'all,successful', 'no,unsuccessful', 'all,successful', 'no,unsuccessful')\n",
    "- ALL speakers agree: this sequence requires θ ≈ 0.9\n",
    "- Coop listener: E[θ] = 0.886\n",
    "- Uncertain listener: E[θ] = 0.919\n",
    "- Difference: only 0.033\n",
    "\n",
    "IMPLICATION FOR EXPERIMENT:\n",
    "- INF-characteristic sequences can serve as CONTROL stimuli\n",
    "- Both conditions should show SIMILAR θ estimates\n",
    "- If they differ, it suggests the manipulation affected processing beyond the model\n",
    "\"\"\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Detailed posterior for best INF sequence\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED POSTERIOR FOR BEST INF SEQUENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_inf_idx = inf_filtered.index[0]\n",
    "best_inf = inf_filtered.iloc[0]\n",
    "\n",
    "print(f\"\\nSequence: {best_inf['sequence']}\")\n",
    "print(f\"\\nPosterior P(θ | sequence):\")\n",
    "print(f\"{'θ':<6} {'Coop':<10} {'Uncertain':<12} {'INF':<10} {'PERSP':<10} {'PERSM':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, theta in enumerate(theta_values):\n",
    "    p_coop = P_theta_given_seq_coop[best_inf_idx, i]\n",
    "    p_unc = P_theta_given_seq_uncertain[best_inf_idx, i]\n",
    "    p_inf = P_theta_given_seq_inf[best_inf_idx, i]\n",
    "    p_persp = P_theta_given_seq_persp[best_inf_idx, i]\n",
    "    p_persm = P_theta_given_seq_persm[best_inf_idx, i]\n",
    "    print(f\"{theta:<6.1f} {p_coop:<10.4f} {p_unc:<12.4f} {p_inf:<10.4f} {p_persp:<10.4f} {p_persm:<10.4f}\")\n",
    "\n",
    "print(\"\"\"\n",
    "OBSERVATION:\n",
    "- All speaker-specific posteriors concentrate at high θ (0.8-1.0)\n",
    "- The slight difference comes from PERSM putting more weight on θ=1.0\n",
    "- This is why Uncertain (which includes PERSM) estimates slightly higher θ\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0916bedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('all,successful',\n",
       " 'all,successful',\n",
       " 'all,successful',\n",
       " 'all,successful',\n",
       " 'all,successful')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_discrimination[\"sequence\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4487808c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     18789\n",
      "sequence_idx                                                         18789\n",
      "sequence                 (some,successful, some,successful, some,unsucc...\n",
      "js_coop_vs_uncertain                                              0.438319\n",
      "E_theta_coop                                                      0.547124\n",
      "E_theta_uncertain                                                 0.479388\n",
      "E_theta_diff                                                      0.067736\n",
      "Var_theta_coop                                                    0.024447\n",
      "Var_theta_uncertain                                                0.09933\n",
      "max_P_overall                                                     0.024833\n",
      "marginal_P                                                        0.003303\n",
      "min_max_P                                                              0.0\n",
      "max_P_inf                                                              0.0\n",
      "max_P_persp                                                       0.024833\n",
      "max_P_persm                                                       0.024761\n",
      "js_inf_vs_persp                                                   0.561823\n",
      "js_inf_vs_persm                                                   0.616595\n",
      "js_persp_vs_persm                                                 0.966088\n",
      "n_all                                                                    0\n",
      "n_most                                                                   0\n",
      "n_some                                                                   5\n",
      "n_no                                                                     0\n",
      "n_successful                                                             3\n",
      "n_unsuccessful                                                           2\n",
      "n_unique_utterances                                                      2\n",
      "n_adjacent_repeats                                                       1\n",
      "n_total_repeats                                                          3\n",
      "dominant_quantifier                                                   some\n",
      "dominant_outcome                                                successful\n",
      "dominant_speaker                                                     persp\n",
      "speaker_dominance_ratio                                           1.002896\n"
     ]
    }
   ],
   "source": [
    "target = (\n",
    "    \"some,successful\",\n",
    "    \"some,successful\",\n",
    "    \"some,unsuccessful\",\n",
    "    \"some,successful\",\n",
    "    \"some,unsuccessful\",\n",
    ")\n",
    "\n",
    "print(results_discrimination[\n",
    "    results_discrimination[\"sequence\"] == target\n",
    "].T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programming-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
