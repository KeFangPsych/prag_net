{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64861efb",
   "metadata": {},
   "source": [
    "# RSA Model Fitting Notebook\n",
    "\n",
    "This notebook fits RSA speaker models to participant data from the N5M1 experiment.\n",
    "\n",
    "For each participant and each goal condition (inf, persp, persm), we fit **all 6 models**:\n",
    "1. **Literal** - Uniform distribution over true utterances\n",
    "2. **inf_T** - Informative pragmatic, dynamic (update_internal=True)\n",
    "3. **inf_F** - Informative pragmatic, static (update_internal=False)\n",
    "4. **persp_T** - Persuade+ pragmatic, dynamic\n",
    "5. **persp_F** - Persuade+ pragmatic, static\n",
    "6. **persm_T** - Persuade- pragmatic, dynamic\n",
    "7. **persm_F** - Persuade- pragmatic, static\n",
    "\n",
    "Output formats:\n",
    "- **Wide format**: One row per participant (3 conditions × 6 models = 18 fits per participant)\n",
    "- **Long format**: One row per participant × condition × model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19f36d",
   "metadata": {},
   "source": [
    "## Cell 1: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "500eaca6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Any, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import RSA modules (these should be in the same directory or in PYTHONPATH)\n",
    "import sys\n",
    "# Uncomment and modify if needed:\n",
    "# sys.path.append('/path/to/rsa_modules/')\n",
    "\n",
    "from rsa_optimal_exp_core import World, LiteralSpeaker, PragmaticSpeaker_obs\n",
    "from rsa_optimal_exp_fitting import log_likelihood_utt_seq, log_likelihood_alpha_opt_utt_seq\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a4054",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09714fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "# n=1: One group/experiment\n",
    "# m=5: 5 patients (Bernoulli trials) per group\n",
    "N_EXPERIMENTS = 1  # Number of independent experiments\n",
    "M_PATIENTS = 5     # Number of patients per experiment (Bernoulli trials)\n",
    "\n",
    "# Model fitting configuration\n",
    "ALPHA_BOUNDS = (0.001, 100.0)  # Bounds for alpha optimization\n",
    "GRID_SEARCH = False            # Use grid search (more robust)\n",
    "GRID_POINTS = 300             # Number of grid points\n",
    "GRID_SPACING = \"log\"          # Logarithmic spacing\n",
    "INCLUDE_DETERM = True         # Include deterministic alpha\n",
    "\n",
    "# Expected number of trials per condition\n",
    "EXPECTED_TRIALS = 10\n",
    "\n",
    "# Mapping from experiment data to RSA model\n",
    "PREDICATE_MAP = {'Effective': 'successful', 'Ineffective': 'unsuccessful'}\n",
    "QUANTIFIER_MAP = {'All': 'all', 'Most': 'most', 'Some': 'some', 'No': 'no'}\n",
    "\n",
    "# Goal conditions in the experiment\n",
    "GOAL_CONDITIONS = ['inf', 'persp', 'persm']\n",
    "\n",
    "# All models to fit for each condition\n",
    "# Format: (model_name, psi, update_internal)\n",
    "# psi: 'inf', 'pers+', 'pers-'\n",
    "# update_internal: True (dynamic), False (static)\n",
    "MODELS_TO_FIT = [\n",
    "    ('literal', None, None),           # Literal model (no psi/update)\n",
    "    ('inf_T', 'inf', True),            # Informative, dynamic\n",
    "    ('inf_F', 'inf', False),           # Informative, static\n",
    "    ('persp_T', 'pers+', True),        # Persuade+, dynamic\n",
    "    ('persp_F', 'pers+', False),       # Persuade+, static\n",
    "    ('persm_T', 'pers-', True),        # Persuade-, dynamic\n",
    "    ('persm_F', 'pers-', False),       # Persuade-, static\n",
    "]\n",
    "\n",
    "MODEL_NAMES = [m[0] for m in MODELS_TO_FIT]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638bfd0",
   "metadata": {},
   "source": [
    "## Cell 3: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5669b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_world(n: int = N_EXPERIMENTS, m: int = M_PATIENTS) -> World:\n",
    "    \"\"\"Create the RSA World object for the experiment.\"\"\"\n",
    "    return World(n=n, m=m)\n",
    "\n",
    "\n",
    "def num_effective_to_observation(num_effective: int, m: int = M_PATIENTS) -> Tuple[int, ...]:\n",
    "    \"\"\"\n",
    "    Convert num_effective (count of effective patients) to observation tuple.\n",
    "    \n",
    "    For n=1, m=5, observation is a one-hot encoding of length m+1=6:\n",
    "    - num_effective=0 -> (1, 0, 0, 0, 0, 0)\n",
    "    - num_effective=3 -> (0, 0, 0, 1, 0, 0)\n",
    "    - num_effective=5 -> (0, 0, 0, 0, 0, 1)\n",
    "    \"\"\"\n",
    "    n_effective = int(num_effective)\n",
    "    return tuple(1 if i == n_effective else 0 for i in range(m + 1))\n",
    "\n",
    "\n",
    "def format_utterance(predicate: str, quantifier: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert experiment predicate/quantifier to RSA utterance format.\n",
    "    \n",
    "    RSA uses comma-separated format: \"quantifier,predicate\"\n",
    "    Example: ('Effective', 'Most') -> 'most,successful'\n",
    "    \"\"\"\n",
    "    pred = PREDICATE_MAP.get(predicate, predicate.lower())\n",
    "    quant = QUANTIFIER_MAP.get(quantifier, quantifier.lower())\n",
    "    return f\"{quant},{pred}\"\n",
    "\n",
    "\n",
    "def extract_trials_for_condition(df_row: pd.Series, condition: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract observation and utterance sequences for a specific condition.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_row : pd.Series\n",
    "        A row from the processed data (one participant)\n",
    "    condition : str\n",
    "        Condition prefix: 'inf', 'persp', or 'persm'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict with:\n",
    "        - obs_seq: List of observation tuples\n",
    "        - utt_seq: List of utterance strings\n",
    "        - n_trials: Number of valid trials\n",
    "        - is_complete: Whether all expected trials are present\n",
    "    \"\"\"\n",
    "    obs_seq = []\n",
    "    utt_seq = []\n",
    "    \n",
    "    for r in range(1, 11):  # Rounds 1-10\n",
    "        num_eff_col = f'{condition}_r{r}_num_effective'\n",
    "        pred_col = f'{condition}_r{r}_predicate'\n",
    "        quant_col = f'{condition}_r{r}_quantifier'\n",
    "        \n",
    "        # Check if columns exist and have valid values\n",
    "        if num_eff_col not in df_row.index:\n",
    "            continue\n",
    "            \n",
    "        num_eff = df_row.get(num_eff_col)\n",
    "        pred = df_row.get(pred_col)\n",
    "        quant = df_row.get(quant_col)\n",
    "        \n",
    "        # Skip if any value is missing\n",
    "        if pd.isna(num_eff) or pd.isna(pred) or pd.isna(quant):\n",
    "            continue\n",
    "        if pred == '' or quant == '':\n",
    "            continue\n",
    "            \n",
    "        obs = num_effective_to_observation(int(num_eff))\n",
    "        utt = format_utterance(pred, quant)\n",
    "        \n",
    "        obs_seq.append(obs)\n",
    "        utt_seq.append(utt)\n",
    "    \n",
    "    n_trials = len(obs_seq)\n",
    "    is_complete = (n_trials == EXPECTED_TRIALS)\n",
    "    \n",
    "    return {\n",
    "        'obs_seq': obs_seq,\n",
    "        'utt_seq': utt_seq,\n",
    "        'n_trials': n_trials,\n",
    "        'is_complete': is_complete\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c513dd",
   "metadata": {},
   "source": [
    "## Cell 4: Model Fitting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fa5d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_literal_model(\n",
    "    world: World,\n",
    "    obs_seq: List[Tuple[int, ...]],\n",
    "    utt_seq: List[str]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fit literal speaker model (no alpha optimization needed).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict with:\n",
    "        - ll: float (log-likelihood)\n",
    "        - alpha: None (literal has no alpha)\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        'speaker_type': 'literal',\n",
    "        'initial_beliefs_theta': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        ll = log_likelihood_utt_seq(world, obs_seq, utt_seq, config)\n",
    "    except Exception as e:\n",
    "        ll = np.nan\n",
    "    \n",
    "    return {\n",
    "        'll': ll,\n",
    "        'alpha': None\n",
    "    }\n",
    "\n",
    "\n",
    "def fit_pragmatic_model(\n",
    "    world: World,\n",
    "    obs_seq: List[Tuple[int, ...]],\n",
    "    utt_seq: List[str],\n",
    "    psi: str,\n",
    "    update_internal: bool,\n",
    "    alpha_bounds: Tuple[float, float] = ALPHA_BOUNDS,\n",
    "    grid_search: bool = GRID_SEARCH,\n",
    "    grid_points: int = GRID_POINTS,\n",
    "    grid_spacing: str = GRID_SPACING,\n",
    "    include_determ: bool = INCLUDE_DETERM\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fit pragmatic speaker model with alpha optimization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    world : World\n",
    "        RSA World object\n",
    "    obs_seq : List of observation tuples\n",
    "    utt_seq : List of utterance strings\n",
    "    psi : str\n",
    "        Speaker goal: 'inf', 'pers+', or 'pers-'\n",
    "    update_internal : bool\n",
    "        True for dynamic model, False for static model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict with:\n",
    "        - ll: float (log-likelihood at optimal alpha)\n",
    "        - alpha: float or 'determ' or None\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        'speaker_type': 'pragmatic',\n",
    "        'omega': 'strat',  # Strategic speaker\n",
    "        'psi': psi,\n",
    "        'update_internal': update_internal,\n",
    "        'beta': 0.0,  # Pure goal (no informativeness mixing)\n",
    "        'initial_beliefs_theta': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        result = log_likelihood_alpha_opt_utt_seq(\n",
    "            world=world,\n",
    "            obs_seq=obs_seq,\n",
    "            utt_seq=utt_seq,\n",
    "            speaker_config=config,\n",
    "            alpha_bounds=alpha_bounds,\n",
    "            grid_search=grid_search,\n",
    "            grid_points=grid_points,\n",
    "            grid_spacing=grid_spacing,\n",
    "            include_determ=include_determ\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'll': result['max_log_likelihood'],\n",
    "            'alpha': result['optimal_alpha']\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'll': np.nan,\n",
    "            'alpha': None\n",
    "        }\n",
    "\n",
    "\n",
    "def fit_all_models_for_sequence(\n",
    "    world: World,\n",
    "    obs_seq: List[Tuple[int, ...]],\n",
    "    utt_seq: List[str]\n",
    ") -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fit all 6 models for one observation-utterance sequence.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict with model names as keys, each containing {'ll': float, 'alpha': value}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_name, psi, update_internal in MODELS_TO_FIT:\n",
    "        if model_name == 'literal':\n",
    "            results[model_name] = fit_literal_model(world, obs_seq, utt_seq)\n",
    "        else:\n",
    "            results[model_name] = fit_pragmatic_model(\n",
    "                world, obs_seq, utt_seq, psi, update_internal\n",
    "            )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840ed3e",
   "metadata": {},
   "source": [
    "## Cell 5: Main Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3a9fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_participant_wide(\n",
    "    df_row: pd.Series,\n",
    "    world: World\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process all conditions for a single participant (wide format).\n",
    "    \n",
    "    Returns dict with one entry per condition-model combination.\n",
    "    \"\"\"\n",
    "    participant_id = df_row.get('participant_id', df_row.name)\n",
    "    result = {'participant_id': participant_id}\n",
    "    \n",
    "    for condition in GOAL_CONDITIONS:\n",
    "        # Extract trial data\n",
    "        trial_data = extract_trials_for_condition(df_row, condition)\n",
    "        \n",
    "        # Store trial info\n",
    "        result[f'{condition}_n_trials'] = trial_data['n_trials']\n",
    "        result[f'{condition}_is_complete'] = trial_data['is_complete']\n",
    "        \n",
    "        # Fit all models if we have any trials\n",
    "        if trial_data['n_trials'] > 0:\n",
    "            model_results = fit_all_models_for_sequence(\n",
    "                world,\n",
    "                trial_data['obs_seq'],\n",
    "                trial_data['utt_seq']\n",
    "            )\n",
    "            \n",
    "            # Store results for each model\n",
    "            for model_name in MODEL_NAMES:\n",
    "                mr = model_results[model_name]\n",
    "                result[f'{condition}_{model_name}_ll'] = mr['ll']\n",
    "                result[f'{condition}_{model_name}_alpha'] = mr['alpha']\n",
    "        else:\n",
    "            # No trials - fill with NaN\n",
    "            for model_name in MODEL_NAMES:\n",
    "                result[f'{condition}_{model_name}_ll'] = np.nan\n",
    "                result[f'{condition}_{model_name}_alpha'] = None\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def fit_all_participants_wide(\n",
    "    df: pd.DataFrame,\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fit all models for all participants (wide format).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Processed data with one row per participant\n",
    "    verbose : bool\n",
    "        Whether to show progress\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Wide-format results with one row per participant\n",
    "        Columns: participant_id, {condition}_{model}_ll, {condition}_{model}_alpha\n",
    "    \"\"\"\n",
    "    # Create world\n",
    "    world = create_world(n=N_EXPERIMENTS, m=M_PATIENTS)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"World created: n={N_EXPERIMENTS}, m={M_PATIENTS}\")\n",
    "        print(f\"  Utterances: {world.utterances}\")\n",
    "        print(f\"  Possible outcomes: {len(world.possible_outcomes)}\")\n",
    "        print(f\"\\nFitting {len(MODEL_NAMES)} models × {len(GOAL_CONDITIONS)} conditions = {len(MODEL_NAMES) * len(GOAL_CONDITIONS)} fits per participant\")\n",
    "    \n",
    "    # Process all participants\n",
    "    all_results = []\n",
    "    \n",
    "    iterator = df.iterrows()\n",
    "    if verbose:\n",
    "        iterator = tqdm(list(iterator), desc=\"Fitting models\")\n",
    "    \n",
    "    for idx, row in iterator:\n",
    "        result = process_participant_wide(row, world)\n",
    "        all_results.append(result)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Reorder columns\n",
    "    cols = ['participant_id']\n",
    "    for condition in GOAL_CONDITIONS:\n",
    "        cols.extend([f'{condition}_n_trials', f'{condition}_is_complete'])\n",
    "        for model in MODEL_NAMES:\n",
    "            cols.extend([f'{condition}_{model}_ll', f'{condition}_{model}_alpha'])\n",
    "    \n",
    "    # Only include columns that exist\n",
    "    cols = [c for c in cols if c in results_df.columns]\n",
    "    results_df = results_df[cols]\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d39f8",
   "metadata": {},
   "source": [
    "## Cell 6: Create Anonymized Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b45d8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_anonymized_version(df):\n",
    "    \"\"\"\n",
    "    Create anonymized version by removing identifying columns.\n",
    "    Keeps participant_id as the only identifier.\n",
    "    \"\"\"\n",
    "    # Columns to remove for anonymization\n",
    "    id_columns = ['subject_id', 'prolific_pid', 'study_id', 'session_id', \n",
    "                  'start_time', 'completion_time', 'source_file']\n",
    "    \n",
    "    df_anon = df.copy()\n",
    "    for col in id_columns:\n",
    "        if col in df_anon.columns:\n",
    "            df_anon = df_anon.drop(columns=[col])\n",
    "    \n",
    "    return df_anon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0c7b5",
   "metadata": {},
   "source": [
    "## Cell 7: Run Model Fitting\n",
    "\n",
    "Edit `INPUT_PATH` to point to your processed data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8cb715b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 111 participants from ./processed_speaker_n1_full.csv\n",
      "Filtering 111 to 109 completed participants\n",
      "\n",
      "======================================================================\n",
      "FITTING MODELS\n",
      "======================================================================\n",
      "World created: n=1, m=5\n",
      "  Utterances: ['all,successful', 'all,unsuccessful', 'most,successful', 'most,unsuccessful', 'some,successful', 'some,unsuccessful', 'no,successful', 'no,unsuccessful']\n",
      "  Possible outcomes: 6\n",
      "\n",
      "Fitting 7 models × 3 conditions = 21 fits per participant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting models: 100%|██████████| 109/109 [04:28<00:00,  2.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          109\n",
       "left_only       0\n",
       "right_only      0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_PATH_FULL = './processed_speaker_n1_full.csv'  \n",
    "\n",
    "# Load data\n",
    "df_raw = pd.read_csv(INPUT_PATH_FULL)\n",
    "print(f\"Loaded {len(df_raw)} participants from {INPUT_PATH_FULL}\")\n",
    "\n",
    "# Filter to completed participants only\n",
    "df = df_raw[df_raw['completion_status'] == 'completed'].copy()\n",
    "print(f\"Filtering {len(df_raw)} to {len(df)} completed participants\")\n",
    "\n",
    "# Run model fitting (wide format)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FITTING MODELS\")\n",
    "print(f\"{'='*70}\")\n",
    "fitted_result = fit_all_participants_wide(df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb28a39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlapping columns to drop before merge: ['inf_n_trials', 'persm_n_trials', 'persp_n_trials']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          109\n",
       "left_only       0\n",
       "right_only      0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = \"participant_id\"\n",
    "overlap = df.columns.intersection(fitted_result.columns).difference([key])\n",
    "print(\"Overlapping columns to drop before merge:\", overlap.tolist())\n",
    "df_fitted = df.merge(\n",
    "    fitted_result.drop(columns=overlap),\n",
    "    on=key,\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\",\n",
    "    indicator=True \n",
    ")\n",
    "\n",
    "df_fitted[\"_merge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1449c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anonymized version\n",
    "df_fitted_anon = create_anonymized_version(df_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e80642a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['participant_id',\n",
       " 'study',\n",
       " 'subject_id',\n",
       " 'prolific_pid',\n",
       " 'study_id',\n",
       " 'session_id',\n",
       " 'experiment_version',\n",
       " 'start_time',\n",
       " 'completion_status',\n",
       " 'completion_time',\n",
       " 'terminated_early',\n",
       " 'termination_reason',\n",
       " 'duration_minutes',\n",
       " 'total_time_elapsed_ms',\n",
       " 'block_1_scenario',\n",
       " 'block_2_scenario',\n",
       " 'block_3_scenario',\n",
       " 'block_order',\n",
       " 'attention_total_failures',\n",
       " 'attention_block_1_passed',\n",
       " 'attention_block_1_round',\n",
       " 'attention_block_1_time_elapsed',\n",
       " 'attention_block_1_num_effective',\n",
       " 'attention_block_1_stimulus_variant',\n",
       " 'attention_block_1_required_description',\n",
       " 'attention_block_2_passed',\n",
       " 'attention_block_2_round',\n",
       " 'attention_block_2_time_elapsed',\n",
       " 'attention_block_2_num_effective',\n",
       " 'attention_block_2_stimulus_variant',\n",
       " 'attention_block_2_required_description',\n",
       " 'attention_block_3_passed',\n",
       " 'attention_block_3_round',\n",
       " 'attention_block_3_time_elapsed',\n",
       " 'attention_block_3_num_effective',\n",
       " 'attention_block_3_stimulus_variant',\n",
       " 'attention_block_3_required_description',\n",
       " 'comp1_some_correct',\n",
       " 'comp1_some_rt',\n",
       " 'comp1_some_response',\n",
       " 'comp1_most_correct',\n",
       " 'comp1_most_rt',\n",
       " 'comp1_most_response',\n",
       " 'comp2_1_correct',\n",
       " 'comp2_1_time_elapsed',\n",
       " 'comp2_1_num_effective',\n",
       " 'comp2_1_statement',\n",
       " 'comp2_2_correct',\n",
       " 'comp2_2_time_elapsed',\n",
       " 'comp2_2_num_effective',\n",
       " 'comp2_2_statement',\n",
       " 'comp3_correct',\n",
       " 'comp3_time_elapsed',\n",
       " 'comp3_selected',\n",
       " 'inf_role_comp_correct',\n",
       " 'inf_role_comp_selected',\n",
       " 'inf_role_comp_time_elapsed',\n",
       " 'persp_role_comp_correct',\n",
       " 'persp_role_comp_selected',\n",
       " 'persp_role_comp_time_elapsed',\n",
       " 'persm_role_comp_correct',\n",
       " 'persm_role_comp_selected',\n",
       " 'persm_role_comp_time_elapsed',\n",
       " 'n_speaker_trials',\n",
       " 'inf_n_trials',\n",
       " 'inf_r1_num_effective',\n",
       " 'inf_r1_variant',\n",
       " 'inf_r1_positions',\n",
       " 'inf_r1_predicate',\n",
       " 'inf_r1_quantifier',\n",
       " 'inf_r1_time_elapsed',\n",
       " 'inf_r1_rt_approx',\n",
       " 'inf_r2_num_effective',\n",
       " 'inf_r2_variant',\n",
       " 'inf_r2_positions',\n",
       " 'inf_r2_predicate',\n",
       " 'inf_r2_quantifier',\n",
       " 'inf_r2_time_elapsed',\n",
       " 'inf_r2_rt_approx',\n",
       " 'inf_r3_num_effective',\n",
       " 'inf_r3_variant',\n",
       " 'inf_r3_positions',\n",
       " 'inf_r3_predicate',\n",
       " 'inf_r3_quantifier',\n",
       " 'inf_r3_time_elapsed',\n",
       " 'inf_r3_rt_approx',\n",
       " 'inf_r4_num_effective',\n",
       " 'inf_r4_variant',\n",
       " 'inf_r4_positions',\n",
       " 'inf_r4_predicate',\n",
       " 'inf_r4_quantifier',\n",
       " 'inf_r4_time_elapsed',\n",
       " 'inf_r4_rt_approx',\n",
       " 'inf_r5_num_effective',\n",
       " 'inf_r5_variant',\n",
       " 'inf_r5_positions',\n",
       " 'inf_r5_predicate',\n",
       " 'inf_r5_quantifier',\n",
       " 'inf_r5_time_elapsed',\n",
       " 'inf_r5_rt_approx',\n",
       " 'inf_r6_num_effective',\n",
       " 'inf_r6_variant',\n",
       " 'inf_r6_positions',\n",
       " 'inf_r6_predicate',\n",
       " 'inf_r6_quantifier',\n",
       " 'inf_r6_time_elapsed',\n",
       " 'inf_r6_rt_approx',\n",
       " 'inf_r7_num_effective',\n",
       " 'inf_r7_variant',\n",
       " 'inf_r7_positions',\n",
       " 'inf_r7_predicate',\n",
       " 'inf_r7_quantifier',\n",
       " 'inf_r7_time_elapsed',\n",
       " 'inf_r7_rt_approx',\n",
       " 'inf_r8_num_effective',\n",
       " 'inf_r8_variant',\n",
       " 'inf_r8_positions',\n",
       " 'inf_r8_predicate',\n",
       " 'inf_r8_quantifier',\n",
       " 'inf_r8_time_elapsed',\n",
       " 'inf_r8_rt_approx',\n",
       " 'inf_r9_num_effective',\n",
       " 'inf_r9_variant',\n",
       " 'inf_r9_positions',\n",
       " 'inf_r9_predicate',\n",
       " 'inf_r9_quantifier',\n",
       " 'inf_r9_time_elapsed',\n",
       " 'inf_r9_rt_approx',\n",
       " 'inf_r10_num_effective',\n",
       " 'inf_r10_variant',\n",
       " 'inf_r10_positions',\n",
       " 'inf_r10_predicate',\n",
       " 'inf_r10_quantifier',\n",
       " 'inf_r10_time_elapsed',\n",
       " 'inf_r10_rt_approx',\n",
       " 'persp_n_trials',\n",
       " 'persp_r1_num_effective',\n",
       " 'persp_r1_variant',\n",
       " 'persp_r1_positions',\n",
       " 'persp_r1_predicate',\n",
       " 'persp_r1_quantifier',\n",
       " 'persp_r1_time_elapsed',\n",
       " 'persp_r1_rt_approx',\n",
       " 'persp_r2_num_effective',\n",
       " 'persp_r2_variant',\n",
       " 'persp_r2_positions',\n",
       " 'persp_r2_predicate',\n",
       " 'persp_r2_quantifier',\n",
       " 'persp_r2_time_elapsed',\n",
       " 'persp_r2_rt_approx',\n",
       " 'persp_r3_num_effective',\n",
       " 'persp_r3_variant',\n",
       " 'persp_r3_positions',\n",
       " 'persp_r3_predicate',\n",
       " 'persp_r3_quantifier',\n",
       " 'persp_r3_time_elapsed',\n",
       " 'persp_r3_rt_approx',\n",
       " 'persp_r4_num_effective',\n",
       " 'persp_r4_variant',\n",
       " 'persp_r4_positions',\n",
       " 'persp_r4_predicate',\n",
       " 'persp_r4_quantifier',\n",
       " 'persp_r4_time_elapsed',\n",
       " 'persp_r4_rt_approx',\n",
       " 'persp_r5_num_effective',\n",
       " 'persp_r5_variant',\n",
       " 'persp_r5_positions',\n",
       " 'persp_r5_predicate',\n",
       " 'persp_r5_quantifier',\n",
       " 'persp_r5_time_elapsed',\n",
       " 'persp_r5_rt_approx',\n",
       " 'persp_r6_num_effective',\n",
       " 'persp_r6_variant',\n",
       " 'persp_r6_positions',\n",
       " 'persp_r6_predicate',\n",
       " 'persp_r6_quantifier',\n",
       " 'persp_r6_time_elapsed',\n",
       " 'persp_r6_rt_approx',\n",
       " 'persp_r7_num_effective',\n",
       " 'persp_r7_variant',\n",
       " 'persp_r7_positions',\n",
       " 'persp_r7_predicate',\n",
       " 'persp_r7_quantifier',\n",
       " 'persp_r7_time_elapsed',\n",
       " 'persp_r7_rt_approx',\n",
       " 'persp_r8_num_effective',\n",
       " 'persp_r8_variant',\n",
       " 'persp_r8_positions',\n",
       " 'persp_r8_predicate',\n",
       " 'persp_r8_quantifier',\n",
       " 'persp_r8_time_elapsed',\n",
       " 'persp_r8_rt_approx',\n",
       " 'persp_r9_num_effective',\n",
       " 'persp_r9_variant',\n",
       " 'persp_r9_positions',\n",
       " 'persp_r9_predicate',\n",
       " 'persp_r9_quantifier',\n",
       " 'persp_r9_time_elapsed',\n",
       " 'persp_r9_rt_approx',\n",
       " 'persp_r10_num_effective',\n",
       " 'persp_r10_variant',\n",
       " 'persp_r10_positions',\n",
       " 'persp_r10_predicate',\n",
       " 'persp_r10_quantifier',\n",
       " 'persp_r10_time_elapsed',\n",
       " 'persp_r10_rt_approx',\n",
       " 'persm_n_trials',\n",
       " 'persm_r1_num_effective',\n",
       " 'persm_r1_variant',\n",
       " 'persm_r1_positions',\n",
       " 'persm_r1_predicate',\n",
       " 'persm_r1_quantifier',\n",
       " 'persm_r1_time_elapsed',\n",
       " 'persm_r1_rt_approx',\n",
       " 'persm_r2_num_effective',\n",
       " 'persm_r2_variant',\n",
       " 'persm_r2_positions',\n",
       " 'persm_r2_predicate',\n",
       " 'persm_r2_quantifier',\n",
       " 'persm_r2_time_elapsed',\n",
       " 'persm_r2_rt_approx',\n",
       " 'persm_r3_num_effective',\n",
       " 'persm_r3_variant',\n",
       " 'persm_r3_positions',\n",
       " 'persm_r3_predicate',\n",
       " 'persm_r3_quantifier',\n",
       " 'persm_r3_time_elapsed',\n",
       " 'persm_r3_rt_approx',\n",
       " 'persm_r4_num_effective',\n",
       " 'persm_r4_variant',\n",
       " 'persm_r4_positions',\n",
       " 'persm_r4_predicate',\n",
       " 'persm_r4_quantifier',\n",
       " 'persm_r4_time_elapsed',\n",
       " 'persm_r4_rt_approx',\n",
       " 'persm_r5_num_effective',\n",
       " 'persm_r5_variant',\n",
       " 'persm_r5_positions',\n",
       " 'persm_r5_predicate',\n",
       " 'persm_r5_quantifier',\n",
       " 'persm_r5_time_elapsed',\n",
       " 'persm_r5_rt_approx',\n",
       " 'persm_r6_num_effective',\n",
       " 'persm_r6_variant',\n",
       " 'persm_r6_positions',\n",
       " 'persm_r6_predicate',\n",
       " 'persm_r6_quantifier',\n",
       " 'persm_r6_time_elapsed',\n",
       " 'persm_r6_rt_approx',\n",
       " 'persm_r7_num_effective',\n",
       " 'persm_r7_variant',\n",
       " 'persm_r7_positions',\n",
       " 'persm_r7_predicate',\n",
       " 'persm_r7_quantifier',\n",
       " 'persm_r7_time_elapsed',\n",
       " 'persm_r7_rt_approx',\n",
       " 'persm_r8_num_effective',\n",
       " 'persm_r8_variant',\n",
       " 'persm_r8_positions',\n",
       " 'persm_r8_predicate',\n",
       " 'persm_r8_quantifier',\n",
       " 'persm_r8_time_elapsed',\n",
       " 'persm_r8_rt_approx',\n",
       " 'persm_r9_num_effective',\n",
       " 'persm_r9_variant',\n",
       " 'persm_r9_positions',\n",
       " 'persm_r9_predicate',\n",
       " 'persm_r9_quantifier',\n",
       " 'persm_r9_time_elapsed',\n",
       " 'persm_r9_rt_approx',\n",
       " 'persm_r10_num_effective',\n",
       " 'persm_r10_variant',\n",
       " 'persm_r10_positions',\n",
       " 'persm_r10_predicate',\n",
       " 'persm_r10_quantifier',\n",
       " 'persm_r10_time_elapsed',\n",
       " 'persm_r10_rt_approx',\n",
       " 'feedback_text',\n",
       " 'source_file']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4baadd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>study</th>\n",
       "      <th>experiment_version</th>\n",
       "      <th>completion_status</th>\n",
       "      <th>terminated_early</th>\n",
       "      <th>termination_reason</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>total_time_elapsed_ms</th>\n",
       "      <th>block_1_scenario</th>\n",
       "      <th>block_2_scenario</th>\n",
       "      <th>...</th>\n",
       "      <th>persm_inf_F_alpha</th>\n",
       "      <th>persm_persp_T_ll</th>\n",
       "      <th>persm_persp_T_alpha</th>\n",
       "      <th>persm_persp_F_ll</th>\n",
       "      <th>persm_persp_F_alpha</th>\n",
       "      <th>persm_persm_T_ll</th>\n",
       "      <th>persm_persm_T_alpha</th>\n",
       "      <th>persm_persm_F_ll</th>\n",
       "      <th>persm_persm_F_alpha</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P002</td>\n",
       "      <td>pilot</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>completed</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.804617</td>\n",
       "      <td>708246</td>\n",
       "      <td>pers_minus</td>\n",
       "      <td>pers_plus</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-11.850625</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-11.852123</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>determ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>determ</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P003</td>\n",
       "      <td>pilot</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>completed</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.860350</td>\n",
       "      <td>471616</td>\n",
       "      <td>informative</td>\n",
       "      <td>pers_minus</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-11.850625</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-11.852123</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>determ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>determ</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P004</td>\n",
       "      <td>pilot</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>completed</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.351267</td>\n",
       "      <td>741064</td>\n",
       "      <td>pers_minus</td>\n",
       "      <td>informative</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-11.850625</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-11.852123</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>determ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>determ</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  study experiment_version completion_status  \\\n",
       "0           P002  pilot              1.0.0         completed   \n",
       "1           P003  pilot              1.0.0         completed   \n",
       "2           P004  pilot              1.0.0         completed   \n",
       "\n",
       "   terminated_early termination_reason  duration_minutes  \\\n",
       "0             False                NaN         11.804617   \n",
       "1             False                NaN          7.860350   \n",
       "2             False                NaN         12.351267   \n",
       "\n",
       "   total_time_elapsed_ms block_1_scenario block_2_scenario  ...  \\\n",
       "0                 708246       pers_minus        pers_plus  ...   \n",
       "1                 471616      informative       pers_minus  ...   \n",
       "2                 741064       pers_minus      informative  ...   \n",
       "\n",
       "  persm_inf_F_alpha persm_persp_T_ll  persm_persp_T_alpha persm_persp_F_ll  \\\n",
       "0          0.001005       -11.850625             0.001005       -11.852123   \n",
       "1          0.001005       -11.850625             0.001005       -11.852123   \n",
       "2          0.001005       -11.850625             0.001005       -11.852123   \n",
       "\n",
       "   persm_persp_F_alpha  persm_persm_T_ll  persm_persm_T_alpha  \\\n",
       "0             0.001005               0.0               determ   \n",
       "1             0.001005               0.0               determ   \n",
       "2             0.001005               0.0               determ   \n",
       "\n",
       "   persm_persm_F_ll persm_persm_F_alpha _merge  \n",
       "0               0.0              determ   both  \n",
       "1               0.0              determ   both  \n",
       "2               0.0              determ   both  \n",
       "\n",
       "[3 rows x 318 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fitted_anon.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b698079",
   "metadata": {},
   "source": [
    "## Cell 8: View Wide Format Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e090be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide format (first 3 rows, selected columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>inf_n_trials</th>\n",
       "      <th>inf_is_complete</th>\n",
       "      <th>inf_literal_ll</th>\n",
       "      <th>inf_inf_T_ll</th>\n",
       "      <th>inf_inf_F_ll</th>\n",
       "      <th>inf_persp_T_ll</th>\n",
       "      <th>inf_persp_F_ll</th>\n",
       "      <th>inf_persm_T_ll</th>\n",
       "      <th>inf_persm_F_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P002</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>-11.273805</td>\n",
       "      <td>-11.275500</td>\n",
       "      <td>-10.550514</td>\n",
       "      <td>-11.275738</td>\n",
       "      <td>-11.275794</td>\n",
       "      <td>-8.567772</td>\n",
       "      <td>-9.346416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P003</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>-11.273805</td>\n",
       "      <td>-11.276538</td>\n",
       "      <td>-4.527161</td>\n",
       "      <td>-11.276544</td>\n",
       "      <td>-11.277816</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P004</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>-11.561487</td>\n",
       "      <td>-11.311724</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>-9.209576</td>\n",
       "      <td>-8.041613</td>\n",
       "      <td>-11.563691</td>\n",
       "      <td>-11.565156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  inf_n_trials  inf_is_complete  inf_literal_ll  inf_inf_T_ll  \\\n",
       "0           P002            10             True      -11.273805    -11.275500   \n",
       "1           P003            10             True      -11.273805    -11.276538   \n",
       "2           P004            10             True      -11.561487    -11.311724   \n",
       "\n",
       "   inf_inf_F_ll  inf_persp_T_ll  inf_persp_F_ll  inf_persm_T_ll  \\\n",
       "0    -10.550514      -11.275738      -11.275794       -8.567772   \n",
       "1     -4.527161      -11.276544      -11.277816       -0.693147   \n",
       "2     -1.386294       -9.209576       -8.041613      -11.563691   \n",
       "\n",
       "   inf_persm_F_ll  \n",
       "0       -9.346416  \n",
       "1       -0.693147  \n",
       "2      -11.565156  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first few rows (wide format)\n",
    "print(\"Wide format (first 3 rows, selected columns):\")\n",
    "display_cols = ['participant_id']\n",
    "for cond in GOAL_CONDITIONS[:1]:  # Just show first condition\n",
    "    display_cols.extend([f'{cond}_n_trials', f'{cond}_is_complete'])\n",
    "    display_cols.extend([f'{cond}_{m}_ll' for m in MODEL_NAMES])\n",
    "df_fitted_anon[display_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b3b8ac1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All log-likelihoods for first participant:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <td>P002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf_literal_ll</th>\n",
       "      <td>-11.273805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf_inf_T_ll</th>\n",
       "      <td>-11.2755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf_inf_F_ll</th>\n",
       "      <td>-10.550514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf_persp_T_ll</th>\n",
       "      <td>-11.275738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf_persp_F_ll</th>\n",
       "      <td>-11.275794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf_persm_T_ll</th>\n",
       "      <td>-8.567772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf_persm_F_ll</th>\n",
       "      <td>-9.346416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persp_literal_ll</th>\n",
       "      <td>-11.849169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persp_inf_T_ll</th>\n",
       "      <td>-11.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persp_inf_F_ll</th>\n",
       "      <td>-11.851043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persp_persp_T_ll</th>\n",
       "      <td>-9.676287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persp_persp_F_ll</th>\n",
       "      <td>-7.919062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persp_persm_T_ll</th>\n",
       "      <td>-11.849846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persp_persm_F_ll</th>\n",
       "      <td>-11.851686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persm_literal_ll</th>\n",
       "      <td>-11.849169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persm_inf_T_ll</th>\n",
       "      <td>-11.854022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persm_inf_F_ll</th>\n",
       "      <td>-11.852655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persm_persp_T_ll</th>\n",
       "      <td>-11.850625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persm_persp_F_ll</th>\n",
       "      <td>-11.852123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persm_persm_T_ll</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persm_persm_F_ll</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "participant_id         P002\n",
       "inf_literal_ll   -11.273805\n",
       "inf_inf_T_ll       -11.2755\n",
       "inf_inf_F_ll     -10.550514\n",
       "inf_persp_T_ll   -11.275738\n",
       "inf_persp_F_ll   -11.275794\n",
       "inf_persm_T_ll    -8.567772\n",
       "inf_persm_F_ll    -9.346416\n",
       "persp_literal_ll -11.849169\n",
       "persp_inf_T_ll     -11.8496\n",
       "persp_inf_F_ll   -11.851043\n",
       "persp_persp_T_ll  -9.676287\n",
       "persp_persp_F_ll  -7.919062\n",
       "persp_persm_T_ll -11.849846\n",
       "persp_persm_F_ll -11.851686\n",
       "persm_literal_ll -11.849169\n",
       "persm_inf_T_ll   -11.854022\n",
       "persm_inf_F_ll   -11.852655\n",
       "persm_persp_T_ll -11.850625\n",
       "persm_persp_F_ll -11.852123\n",
       "persm_persm_T_ll        0.0\n",
       "persm_persm_F_ll        0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all LL columns for one participant\n",
    "print(\"All log-likelihoods for first participant:\")\n",
    "ll_cols = ['participant_id'] + [c for c in df_fitted.columns if '_ll' in c]\n",
    "df_fitted[ll_cols].head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6aa46",
   "metadata": {},
   "source": [
    "## Cell 13: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e1981a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fitted data (109 rows, 325 columns) to: ./raw_do_not_track/speaker_n1_fitted.csv\n"
     ]
    }
   ],
   "source": [
    "# === EDIT THESE PATHS ===\n",
    "OUTPUT_WIDE = './raw_do_not_track/speaker_n1_fitted.csv'\n",
    "\n",
    "# Save wide format\n",
    "df_fitted.to_csv(OUTPUT_WIDE, index=False)\n",
    "print(f\"Saved fitted data ({len(df_fitted)} rows, {len(df_fitted.columns)} columns) to: {OUTPUT_WIDE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4796a48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved anonymized fitted data (109 rows, 318 columns) to: ./speaker_n1_fitted_anonymized.csv\n"
     ]
    }
   ],
   "source": [
    "# === EDIT THESE PATHS ===\n",
    "OUTPUT_WIDE = './speaker_n1_fitted_anonymized.csv'\n",
    "\n",
    "# Save wide format\n",
    "df_fitted_anon.to_csv(OUTPUT_WIDE, index=False)\n",
    "print(f\"Saved anonymized fitted data ({len(df_fitted_anon)} rows, {len(df_fitted_anon.columns)} columns) to: {OUTPUT_WIDE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854cd858",
   "metadata": {},
   "source": [
    "# Cell 14: Generate Code Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KEY CHECK] participant_id: unique=True, duplicates=0, missing=0\n",
      "                                 column    dtype  n_rows  n_missing  \\\n",
      "0                        participant_id   object     109          0   \n",
      "5                    termination_reason   object     109        109   \n",
      "65                     inf_r1_rt_approx  float64     109        109   \n",
      "136                  persp_r1_rt_approx  float64     109        109   \n",
      "207                  persm_r1_rt_approx  float64     109        109   \n",
      "274                   inf_literal_alpha   object     109        109   \n",
      "289                 persp_literal_alpha   object     109        109   \n",
      "304                 persm_literal_alpha   object     109        109   \n",
      "17   attention_block_1_stimulus_variant  float64     109        100   \n",
      "28      attention_block_3_num_effective  float64     109        100   \n",
      "16      attention_block_1_num_effective  float64     109        100   \n",
      "23   attention_block_2_stimulus_variant  float64     109        100   \n",
      "22      attention_block_2_num_effective  float64     109        100   \n",
      "29   attention_block_3_stimulus_variant  float64     109        100   \n",
      "271                       feedback_text   object     109         35   \n",
      "2                    experiment_version   object     109          0   \n",
      "3                     completion_status   object     109          0   \n",
      "4                      terminated_early     bool     109          0   \n",
      "57                     n_speaker_trials    int64     109          0   \n",
      "58                         inf_n_trials    int64     109          0   \n",
      "129                      persp_n_trials    int64     109          0   \n",
      "130              persp_r1_num_effective  float64     109          0   \n",
      "131                    persp_r1_variant  float64     109          0   \n",
      "132                  persp_r1_positions   object     109          0   \n",
      "158              persp_r5_num_effective  float64     109          0   \n",
      "172              persp_r7_num_effective  float64     109          0   \n",
      "179              persp_r8_num_effective  float64     109          0   \n",
      "200                      persm_n_trials    int64     109          0   \n",
      "201              persm_r1_num_effective  float64     109          0   \n",
      "202                    persm_r1_variant  float64     109          0   \n",
      "\n",
      "     pct_missing  n_unique  is_key   min   max      mean  \\\n",
      "0       0.000000       109    True                         \n",
      "5       1.000000         0   False                         \n",
      "65      1.000000         0   False   NaN   NaN       NaN   \n",
      "136     1.000000         0   False   NaN   NaN       NaN   \n",
      "207     1.000000         0   False   NaN   NaN       NaN   \n",
      "274     1.000000         0   False                         \n",
      "289     1.000000         0   False                         \n",
      "304     1.000000         0   False                         \n",
      "17      0.917431         4   False   0.0   4.0  2.111111   \n",
      "28      0.917431         4   False   0.0   5.0  2.333333   \n",
      "16      0.917431         5   False   0.0   5.0  3.222222   \n",
      "23      0.917431         5   False   0.0   9.0  2.333333   \n",
      "22      0.917431         6   False   0.0   5.0  2.444444   \n",
      "29      0.917431         6   False   0.0   8.0  3.222222   \n",
      "271     0.321101        64   False                         \n",
      "2       0.000000         1   False                         \n",
      "3       0.000000         1   False                         \n",
      "4       0.000000         1   False   0.0   0.0       0.0   \n",
      "57      0.000000         1   False  30.0  30.0      30.0   \n",
      "58      0.000000         1   False  10.0  10.0      10.0   \n",
      "129     0.000000         1   False  10.0  10.0      10.0   \n",
      "130     0.000000         1   False   0.0   0.0       0.0   \n",
      "131     0.000000         1   False   0.0   0.0       0.0   \n",
      "132     0.000000         1   False                         \n",
      "158     0.000000         1   False   1.0   1.0       1.0   \n",
      "172     0.000000         1   False   1.0   1.0       1.0   \n",
      "179     0.000000         1   False   2.0   2.0       2.0   \n",
      "200     0.000000         1   False  10.0  10.0      10.0   \n",
      "201     0.000000         1   False   5.0   5.0       5.0   \n",
      "202     0.000000         1   False   0.0   0.0       0.0   \n",
      "\n",
      "                                        example_values  \n",
      "0                         P002; P003; P004; P005; P006  \n",
      "5                                                       \n",
      "65                                                      \n",
      "136                                                     \n",
      "207                                                     \n",
      "274                                                     \n",
      "289                                                     \n",
      "304                                                     \n",
      "17                                                      \n",
      "28                                                      \n",
      "16                                                      \n",
      "23                                                      \n",
      "22                                                      \n",
      "29                                                      \n",
      "271  The attention checks were very hard to disting...  \n",
      "2                                                1.0.0  \n",
      "3                                            completed  \n",
      "4                                                       \n",
      "57                                                      \n",
      "58                                                      \n",
      "129                                                     \n",
      "130                                                     \n",
      "131                                                     \n",
      "132                                                 []  \n",
      "158                                                     \n",
      "172                                                     \n",
      "179                                                     \n",
      "200                                                     \n",
      "201                                                     \n",
      "202                                                     \n"
     ]
    }
   ],
   "source": [
    "def profile_dataframe(df: pd.DataFrame, key_cols=None, max_levels=25) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a \"data dictionary\" style profile of df:\n",
    "    - dtype, missingness, unique counts\n",
    "    - numeric stats (min/max/mean)\n",
    "    - sample levels for low-cardinality columns\n",
    "    \"\"\"\n",
    "    if key_cols is None:\n",
    "        key_cols = []\n",
    "\n",
    "    rows = []\n",
    "    n = len(df)\n",
    "\n",
    "    for col in df.columns:\n",
    "        s = df[col]\n",
    "        dtype = str(s.dtype)\n",
    "\n",
    "        n_missing = int(s.isna().sum())\n",
    "        pct_missing = (n_missing / n) if n else np.nan\n",
    "        n_unique = int(s.nunique(dropna=True))\n",
    "\n",
    "        info = {\n",
    "            \"column\": col,\n",
    "            \"dtype\": dtype,\n",
    "            \"n_rows\": n,\n",
    "            \"n_missing\": n_missing,\n",
    "            \"pct_missing\": pct_missing,\n",
    "            \"n_unique\": n_unique,\n",
    "            \"is_key\": col in set(key_cols),\n",
    "        }\n",
    "\n",
    "        # Numeric summary\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            info.update({\n",
    "                \"min\": float(np.nanmin(s)) if n_missing < n else np.nan,\n",
    "                \"max\": float(np.nanmax(s)) if n_missing < n else np.nan,\n",
    "                \"mean\": float(np.nanmean(s)) if n_missing < n else np.nan,\n",
    "                \"example_values\": \"\"\n",
    "            })\n",
    "\n",
    "        # Datetime-like (try parse)\n",
    "        elif pd.api.types.is_datetime64_any_dtype(s):\n",
    "            info.update({\n",
    "                \"min\": str(s.min()) if n_missing < n else \"\",\n",
    "                \"max\": str(s.max()) if n_missing < n else \"\",\n",
    "                \"mean\": \"\",\n",
    "                \"example_values\": \"\"\n",
    "            })\n",
    "\n",
    "        # Object / categorical: show levels if small\n",
    "        else:\n",
    "            info.update({\"min\": \"\", \"max\": \"\", \"mean\": \"\"})\n",
    "            if n_unique <= max_levels:\n",
    "                levels = s.dropna().astype(str).unique().tolist()\n",
    "                info[\"example_values\"] = \"; \".join(levels[:max_levels])\n",
    "            else:\n",
    "                # show a few examples\n",
    "                examples = s.dropna().astype(str).head(5).tolist()\n",
    "                info[\"example_values\"] = \"; \".join(examples)\n",
    "\n",
    "        rows.append(info)\n",
    "\n",
    "    profile = pd.DataFrame(rows).sort_values(\n",
    "        by=[\"is_key\", \"pct_missing\", \"n_unique\"],\n",
    "        ascending=[False, False, True]\n",
    "    )\n",
    "\n",
    "    # Key checks (if provided)\n",
    "    for k in key_cols:\n",
    "        if k in df.columns:\n",
    "            dup_count = int(df[k].duplicated().sum())\n",
    "            print(f\"[KEY CHECK] {k}: unique={df[k].is_unique}, duplicates={dup_count}, missing={df[k].isna().sum()}\")\n",
    "        else:\n",
    "            print(f\"[KEY CHECK] {k}: column not found in df\")\n",
    "\n",
    "    return profile\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "profile = profile_dataframe(df_fitted_anon, key_cols=[\"participant_id\"])\n",
    "print(profile.head(30))\n",
    "profile.to_csv(\"data_dictionary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "programming-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
